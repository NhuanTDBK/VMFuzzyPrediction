{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapped name None to device cuda: GeForce GT 630M\n",
      "Using cuDNN version 5103 on context None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from estimators.NeuralFlow import *\n",
    "from utils.SlidingWindowUtil import SlidingWindow\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from utils.GraphUtil import *\n",
    "from estimators.GAEstimator import GAEstimator\n",
    "from estimators.OptimizerNNEstimator import OptimizerNNEstimator\n",
    "from io_utils.NumLoad import *\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from estimators.FuzzyFlow import FuzzyFlow\n",
    "from utils.TrainingTestMaker import TrainingTestMaker\n",
    "from scaling.ProactiveSLA import ProactiveSLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_holder = []\n",
    "trainee_holder = {}\n",
    "metrics = [\"cpu_rate\",\"mem_usage\",\"disk_io_time\"]\n",
    "arr_desk = ['X_train','y_train','X_test']\n",
    "sliding_number = 3\n",
    "data = pd.read_csv('sampling_617685_metric_10min_datetime_origin.csv',parse_dates=True,index_col=0)[:3000]\n",
    "data.interpolate(inplace=True)\n",
    "for metric in metrics:\n",
    "    dat = pd.Series(data[metric].round(5))\n",
    "    fuzzy_engine = FuzzyFlow()\n",
    "    data_maker = TrainingTestMaker()\n",
    "    fuzzy_engine.fit_transform(dat)\n",
    "    sliding = np.array(list(SlidingWindow(fuzzy_engine.u_class_transform, sliding_number)))\n",
    "    X_train, y_train, X_test, y_test = data_maker.make_fuzzy_test(sliding, fuzzy_engine.u_class_transform, dat)\n",
    "    dataset_holder.append(fuzzy_engine)\n",
    "#     if(metric==\"cpu_rate\"):\n",
    "    trainee_holder[metric]={\n",
    "        'X_train':X_train,\n",
    "        \"y_train\":y_train,\n",
    "        \"X_test\":X_test,\n",
    "        \"y_test\":y_test\n",
    "    }\n",
    "#     else:\n",
    "#         trainee_holder[metric]={\n",
    "#             'X_train':np.array(X_train)*100+1,\n",
    "#             \"y_train\":np.array(y_train)*100+1,\n",
    "#             \"X_test\":np.array(X_test)*100+1,\n",
    "#             \"y_test\":np.array(y_test)\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train = zip(trainee_holder['cpu_rate']['X_train'],trainee_holder['mem_usage']['X_train'])\n",
    "y_train = np.asarray(zip(*[trainee_holder[metric]['y_train'] for metric in metrics]))\n",
    "# X_test = zip(trainee_holder['cpu_rate']['X_test'],trainee_holder['mem_usage']['X_test'])\n",
    "X_train = []\n",
    "X_test = []\n",
    "# y_train = []\n",
    "for i in np.arange(len(trainee_holder['cpu_rate']['X_train'])):\n",
    "#     tmp = zip(trainee_holder['cpu_rate']['X_train'][i],trainee_holder['mem_usage']['X_train'][i])\n",
    "    tmp = zip(*[trainee_holder[metric]['X_train'][i] for metric in metrics])\n",
    "    X_train.append(np.ravel(tmp))\n",
    "for i in np.arange(len(trainee_holder['cpu_rate']['X_test'])):\n",
    "    tmp = zip(*[trainee_holder[metric]['X_test'][i] for metric in metrics])\n",
    "    X_test.append(np.ravel(tmp))\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "#     y_train.append(np.ravel(zip(trainee_holder['cpu_rate']['y_train'][i],trainee_holder['mem_usage']['y_train'][i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from estimators.KerasRegressor import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(128,input_dim=X_train.shape[1],activation='relu'),\n",
    "        Dense(12,activation='relu'),\n",
    "        Dense(y_train.shape[1],activation='relu')\n",
    "    ])\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4b40022ed0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "pd.Series(dataset_holder[0].u_class_transform).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization\n"
     ]
    }
   ],
   "source": [
    "model = KerasRegressor(hidden_nodes=[64,16],steps=15000,batch_size=32, activation='sigmoid',verbose=2, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_5 (Dense)                  (None, 64)            640         dense_input_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 16)            1040        dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 3)             51          dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1731\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Train on 1890 samples, validate on 210 samples\n",
      "Epoch 1/15000\n",
      "0s - loss: 6.0376 - val_loss: 64.3686\n",
      "Epoch 2/15000\n",
      "0s - loss: 4.8844 - val_loss: 62.1669\n",
      "Epoch 3/15000\n",
      "0s - loss: 4.7557 - val_loss: 61.5365\n",
      "Epoch 4/15000\n",
      "0s - loss: 4.7326 - val_loss: 61.1696\n",
      "Epoch 5/15000\n",
      "0s - loss: 4.7259 - val_loss: 61.1875\n",
      "Epoch 6/15000\n",
      "0s - loss: 4.7176 - val_loss: 61.1625\n",
      "Epoch 7/15000\n",
      "0s - loss: 4.7082 - val_loss: 61.0121\n",
      "Epoch 8/15000\n",
      "0s - loss: 4.6981 - val_loss: 60.9072\n",
      "Epoch 9/15000\n",
      "0s - loss: 4.6808 - val_loss: 60.5836\n",
      "Epoch 10/15000\n",
      "0s - loss: 4.6602 - val_loss: 60.6896\n",
      "Epoch 11/15000\n",
      "0s - loss: 4.6462 - val_loss: 60.0462\n",
      "Epoch 12/15000\n",
      "0s - loss: 4.6176 - val_loss: 59.7802\n",
      "Epoch 13/15000\n",
      "0s - loss: 4.5942 - val_loss: 59.6965\n",
      "Epoch 14/15000\n",
      "0s - loss: 4.5731 - val_loss: 59.0404\n",
      "Epoch 15/15000\n",
      "0s - loss: 4.5470 - val_loss: 58.6131\n",
      "Epoch 16/15000\n",
      "0s - loss: 4.5247 - val_loss: 58.4582\n",
      "Epoch 17/15000\n",
      "0s - loss: 4.5110 - val_loss: 57.7955\n",
      "Epoch 18/15000\n",
      "0s - loss: 4.5096 - val_loss: 57.8081\n",
      "Epoch 19/15000\n",
      "0s - loss: 4.4921 - val_loss: 57.5319\n",
      "Epoch 20/15000\n",
      "0s - loss: 4.4770 - val_loss: 57.5587\n",
      "Epoch 21/15000\n",
      "0s - loss: 4.4755 - val_loss: 57.0319\n",
      "Epoch 22/15000\n",
      "0s - loss: 4.4651 - val_loss: 56.6801\n",
      "Epoch 23/15000\n",
      "0s - loss: 4.4565 - val_loss: 56.5281\n",
      "Epoch 24/15000\n",
      "0s - loss: 4.4584 - val_loss: 56.1539\n",
      "Epoch 25/15000\n",
      "0s - loss: 4.4541 - val_loss: 56.1107\n",
      "Epoch 26/15000\n",
      "0s - loss: 4.4834 - val_loss: 56.5782\n",
      "Epoch 27/15000\n",
      "0s - loss: 4.4364 - val_loss: 56.1468\n",
      "Epoch 28/15000\n",
      "0s - loss: 4.4498 - val_loss: 56.2571\n",
      "Epoch 29/15000\n",
      "0s - loss: 4.4301 - val_loss: 55.7628\n",
      "Epoch 30/15000\n",
      "0s - loss: 4.4278 - val_loss: 55.6978\n",
      "Epoch 31/15000\n",
      "0s - loss: 4.4254 - val_loss: 56.0249\n",
      "Epoch 32/15000\n",
      "0s - loss: 4.4328 - val_loss: 55.7749\n",
      "Epoch 33/15000\n",
      "0s - loss: 4.4278 - val_loss: 55.7468\n",
      "Epoch 34/15000\n",
      "0s - loss: 4.4240 - val_loss: 55.6256\n",
      "Epoch 35/15000\n",
      "0s - loss: 4.4105 - val_loss: 55.9061\n",
      "Epoch 36/15000\n",
      "0s - loss: 4.4085 - val_loss: 55.2669\n",
      "Epoch 37/15000\n",
      "0s - loss: 4.4056 - val_loss: 55.3485\n",
      "Epoch 38/15000\n",
      "0s - loss: 4.4033 - val_loss: 55.3612\n",
      "Epoch 39/15000\n",
      "0s - loss: 4.4156 - val_loss: 55.2150\n",
      "Epoch 40/15000\n",
      "0s - loss: 4.3950 - val_loss: 55.2416\n",
      "Epoch 41/15000\n",
      "0s - loss: 4.3961 - val_loss: 55.0844\n",
      "Epoch 42/15000\n",
      "0s - loss: 4.3947 - val_loss: 54.6961\n",
      "Epoch 43/15000\n",
      "0s - loss: 4.3966 - val_loss: 55.0975\n",
      "Epoch 44/15000\n",
      "0s - loss: 4.3892 - val_loss: 55.0496\n",
      "Epoch 45/15000\n",
      "0s - loss: 4.3848 - val_loss: 54.7521\n",
      "Epoch 46/15000\n",
      "0s - loss: 4.3934 - val_loss: 54.6447\n",
      "Epoch 47/15000\n",
      "0s - loss: 4.3823 - val_loss: 54.7183\n",
      "Epoch 48/15000\n",
      "0s - loss: 4.3789 - val_loss: 55.0900\n",
      "Epoch 49/15000\n",
      "0s - loss: 4.3787 - val_loss: 55.0799\n",
      "Epoch 50/15000\n",
      "0s - loss: 4.3792 - val_loss: 54.9427\n",
      "Epoch 51/15000\n",
      "0s - loss: 4.3694 - val_loss: 54.3998\n",
      "Epoch 52/15000\n",
      "0s - loss: 4.3958 - val_loss: 54.6531\n",
      "Epoch 53/15000\n",
      "0s - loss: 4.3734 - val_loss: 54.6009\n",
      "Epoch 54/15000\n",
      "0s - loss: 4.3640 - val_loss: 54.3917\n",
      "Epoch 55/15000\n",
      "0s - loss: 4.3622 - val_loss: 54.2570\n",
      "Epoch 56/15000\n",
      "0s - loss: 4.3613 - val_loss: 54.2777\n",
      "Epoch 57/15000\n",
      "0s - loss: 4.3634 - val_loss: 54.2726\n",
      "Epoch 58/15000\n",
      "0s - loss: 4.3492 - val_loss: 54.6199\n",
      "Epoch 59/15000\n",
      "0s - loss: 4.3474 - val_loss: 54.2740\n",
      "Epoch 60/15000\n",
      "0s - loss: 4.3521 - val_loss: 54.3476\n",
      "Epoch 61/15000\n",
      "0s - loss: 4.3468 - val_loss: 54.1273\n",
      "Epoch 62/15000\n",
      "0s - loss: 4.3429 - val_loss: 53.9866\n",
      "Epoch 63/15000\n",
      "0s - loss: 4.3422 - val_loss: 54.5640\n",
      "Epoch 64/15000\n",
      "0s - loss: 4.3411 - val_loss: 54.3623\n",
      "Epoch 65/15000\n",
      "0s - loss: 4.3391 - val_loss: 54.4143\n",
      "Epoch 66/15000\n",
      "0s - loss: 4.3368 - val_loss: 54.0029\n",
      "Epoch 67/15000\n",
      "0s - loss: 4.3451 - val_loss: 54.0689\n",
      "Epoch 68/15000\n",
      "0s - loss: 4.3378 - val_loss: 53.6994\n",
      "Epoch 69/15000\n",
      "0s - loss: 4.3444 - val_loss: 53.8482\n",
      "Epoch 70/15000\n",
      "0s - loss: 4.3648 - val_loss: 53.9515\n",
      "Epoch 71/15000\n",
      "0s - loss: 4.3228 - val_loss: 54.6021\n",
      "Epoch 72/15000\n",
      "0s - loss: 4.3186 - val_loss: 52.9752\n",
      "Epoch 73/15000\n",
      "0s - loss: 4.3501 - val_loss: 53.9088\n",
      "Epoch 74/15000\n",
      "0s - loss: 4.3215 - val_loss: 54.6853\n",
      "Epoch 75/15000\n",
      "0s - loss: 4.3234 - val_loss: 53.4039\n",
      "Epoch 76/15000\n",
      "0s - loss: 4.3195 - val_loss: 55.0631\n",
      "Epoch 77/15000\n",
      "0s - loss: 4.3253 - val_loss: 53.6980\n",
      "Epoch 78/15000\n",
      "0s - loss: 4.3185 - val_loss: 54.0150\n",
      "Epoch 79/15000\n",
      "0s - loss: 4.3137 - val_loss: 53.6649\n",
      "Epoch 80/15000\n",
      "0s - loss: 4.3115 - val_loss: 53.9406\n",
      "Epoch 81/15000\n",
      "0s - loss: 4.3201 - val_loss: 53.5868\n",
      "Epoch 82/15000\n",
      "0s - loss: 4.3178 - val_loss: 54.2863\n",
      "Epoch 83/15000\n",
      "0s - loss: 4.3214 - val_loss: 54.4722\n",
      "Epoch 84/15000\n",
      "0s - loss: 4.3039 - val_loss: 53.4476\n",
      "Epoch 85/15000\n",
      "0s - loss: 4.3171 - val_loss: 53.8972\n",
      "Epoch 86/15000\n",
      "0s - loss: 4.3019 - val_loss: 53.2292\n",
      "Epoch 87/15000\n",
      "0s - loss: 4.3116 - val_loss: 54.1390\n",
      "Epoch 88/15000\n",
      "0s - loss: 4.3000 - val_loss: 54.3061\n",
      "Epoch 89/15000\n",
      "0s - loss: 4.3099 - val_loss: 53.6285\n",
      "Epoch 90/15000\n",
      "0s - loss: 4.3033 - val_loss: 53.2666\n",
      "Epoch 91/15000\n",
      "0s - loss: 4.3097 - val_loss: 54.2743\n",
      "Epoch 92/15000\n",
      "0s - loss: 4.3055 - val_loss: 53.5935\n",
      "Epoch 93/15000\n",
      "0s - loss: 4.3051 - val_loss: 54.1435\n",
      "Epoch 94/15000\n",
      "0s - loss: 4.2884 - val_loss: 54.0668\n",
      "Epoch 95/15000\n",
      "0s - loss: 4.2978 - val_loss: 54.5840\n",
      "Epoch 96/15000\n",
      "0s - loss: 4.2951 - val_loss: 54.6597\n",
      "Epoch 97/15000\n",
      "0s - loss: 4.2918 - val_loss: 54.1870\n",
      "Epoch 98/15000\n",
      "0s - loss: 4.2969 - val_loss: 53.9898\n",
      "Epoch 99/15000\n",
      "0s - loss: 4.2816 - val_loss: 53.7426\n",
      "Epoch 100/15000\n",
      "0s - loss: 4.2834 - val_loss: 53.8602\n",
      "Epoch 101/15000\n",
      "0s - loss: 4.2910 - val_loss: 53.6935\n",
      "Epoch 102/15000\n",
      "0s - loss: 4.2907 - val_loss: 53.9182\n",
      "Epoch 103/15000\n",
      "0s - loss: 4.2786 - val_loss: 53.4715\n",
      "Epoch 104/15000\n",
      "0s - loss: 4.2852 - val_loss: 53.7579\n",
      "Epoch 105/15000\n",
      "0s - loss: 4.2807 - val_loss: 54.3988\n",
      "Epoch 106/15000\n",
      "0s - loss: 4.2834 - val_loss: 53.9165\n",
      "Epoch 107/15000\n",
      "0s - loss: 4.2729 - val_loss: 54.2378\n",
      "Epoch 108/15000\n",
      "0s - loss: 4.2867 - val_loss: 54.2438\n",
      "Epoch 109/15000\n",
      "0s - loss: 4.2729 - val_loss: 53.8921\n",
      "Epoch 110/15000\n",
      "0s - loss: 4.2694 - val_loss: 53.7051\n",
      "Epoch 111/15000\n",
      "0s - loss: 4.2708 - val_loss: 53.5181\n",
      "Epoch 112/15000\n",
      "0s - loss: 4.2755 - val_loss: 53.8211\n",
      "Epoch 113/15000\n",
      "0s - loss: 4.2646 - val_loss: 54.2194\n",
      "Epoch 114/15000\n",
      "0s - loss: 4.2660 - val_loss: 53.4679\n",
      "Epoch 115/15000\n",
      "0s - loss: 4.2760 - val_loss: 54.0595\n",
      "Epoch 116/15000\n",
      "0s - loss: 4.2574 - val_loss: 55.0108\n",
      "Epoch 117/15000\n",
      "0s - loss: 4.2647 - val_loss: 53.2394\n",
      "Epoch 118/15000\n",
      "0s - loss: 4.2912 - val_loss: 53.4548\n",
      "Epoch 119/15000\n",
      "0s - loss: 4.2634 - val_loss: 54.3881\n",
      "Epoch 120/15000\n",
      "0s - loss: 4.2731 - val_loss: 54.4896\n",
      "Epoch 121/15000\n",
      "0s - loss: 4.2552 - val_loss: 54.4539\n",
      "Epoch 122/15000\n",
      "0s - loss: 4.2586 - val_loss: 54.3298\n",
      "Epoch 123/15000\n",
      "0s - loss: 4.2504 - val_loss: 54.9089\n",
      "Epoch 124/15000\n",
      "0s - loss: 4.2487 - val_loss: 55.2783\n",
      "Epoch 125/15000\n",
      "0s - loss: 4.2749 - val_loss: 54.3411\n",
      "Epoch 126/15000\n",
      "0s - loss: 4.2509 - val_loss: 54.1806\n",
      "Epoch 127/15000\n",
      "0s - loss: 4.2522 - val_loss: 54.3442\n",
      "Epoch 128/15000\n",
      "0s - loss: 4.2598 - val_loss: 54.0799\n",
      "Epoch 129/15000\n",
      "0s - loss: 4.2531 - val_loss: 54.2784\n",
      "Epoch 130/15000\n",
      "0s - loss: 4.2452 - val_loss: 55.1260\n",
      "Epoch 131/15000\n",
      "0s - loss: 4.2464 - val_loss: 54.9001\n",
      "Epoch 132/15000\n",
      "0s - loss: 4.2433 - val_loss: 54.5104\n",
      "Epoch 133/15000\n",
      "0s - loss: 4.2427 - val_loss: 53.6854\n",
      "Epoch 134/15000\n",
      "0s - loss: 4.2490 - val_loss: 53.7932\n",
      "Epoch 135/15000\n",
      "0s - loss: 4.2376 - val_loss: 54.3461\n",
      "Epoch 136/15000\n",
      "0s - loss: 4.2521 - val_loss: 54.8470\n",
      "Epoch 137/15000\n",
      "0s - loss: 4.2408 - val_loss: 54.1904\n",
      "Epoch 138/15000\n",
      "0s - loss: 4.2332 - val_loss: 54.6750\n",
      "Epoch 139/15000\n",
      "0s - loss: 4.2282 - val_loss: 54.1714\n",
      "Epoch 140/15000\n",
      "0s - loss: 4.2232 - val_loss: 53.3103\n",
      "Epoch 141/15000\n",
      "0s - loss: 4.2374 - val_loss: 53.6681\n",
      "Epoch 142/15000\n",
      "0s - loss: 4.2290 - val_loss: 54.8330\n",
      "Epoch 143/15000\n",
      "0s - loss: 4.2217 - val_loss: 54.7374\n",
      "Epoch 144/15000\n",
      "0s - loss: 4.2174 - val_loss: 53.8927\n",
      "Epoch 145/15000\n",
      "0s - loss: 4.2090 - val_loss: 55.5705\n",
      "Epoch 146/15000\n",
      "0s - loss: 4.2228 - val_loss: 55.2275\n",
      "Epoch 147/15000\n",
      "0s - loss: 4.2207 - val_loss: 54.1453\n",
      "Epoch 148/15000\n",
      "0s - loss: 4.2236 - val_loss: 54.7808\n",
      "Epoch 149/15000\n",
      "0s - loss: 4.2230 - val_loss: 54.6485\n",
      "Epoch 150/15000\n",
      "0s - loss: 4.2165 - val_loss: 53.7093\n",
      "Epoch 151/15000\n",
      "0s - loss: 4.2123 - val_loss: 53.6950\n",
      "Epoch 152/15000\n",
      "0s - loss: 4.2339 - val_loss: 54.2438\n",
      "Epoch 153/15000\n",
      "0s - loss: 4.2144 - val_loss: 55.4793\n",
      "Epoch 154/15000\n",
      "0s - loss: 4.2107 - val_loss: 54.1049\n",
      "Epoch 155/15000\n",
      "0s - loss: 4.2106 - val_loss: 55.1571\n",
      "Epoch 156/15000\n",
      "0s - loss: 4.2135 - val_loss: 56.0946\n",
      "Epoch 157/15000\n",
      "0s - loss: 4.1883 - val_loss: 53.7567\n",
      "Epoch 158/15000\n",
      "0s - loss: 4.1981 - val_loss: 54.8947\n",
      "Epoch 159/15000\n",
      "0s - loss: 4.1973 - val_loss: 54.5553\n",
      "Epoch 160/15000\n",
      "0s - loss: 4.1963 - val_loss: 54.5935\n",
      "Epoch 161/15000\n",
      "0s - loss: 4.2005 - val_loss: 54.7739\n",
      "Epoch 162/15000\n",
      "0s - loss: 4.2015 - val_loss: 54.3652\n",
      "Epoch 163/15000\n",
      "0s - loss: 4.2069 - val_loss: 53.8246\n",
      "Epoch 164/15000\n",
      "0s - loss: 4.2142 - val_loss: 55.1533\n",
      "Epoch 165/15000\n",
      "0s - loss: 4.1923 - val_loss: 54.4335\n",
      "Epoch 166/15000\n",
      "0s - loss: 4.1844 - val_loss: 56.1402\n",
      "Epoch 167/15000\n",
      "0s - loss: 4.1948 - val_loss: 55.1548\n",
      "Epoch 168/15000\n",
      "0s - loss: 4.2143 - val_loss: 54.8602\n",
      "Epoch 169/15000\n",
      "0s - loss: 4.1977 - val_loss: 55.1134\n",
      "Epoch 170/15000\n",
      "0s - loss: 4.1983 - val_loss: 54.8010\n",
      "Epoch 171/15000\n",
      "0s - loss: 4.1814 - val_loss: 55.9866\n",
      "Epoch 172/15000\n",
      "0s - loss: 4.1940 - val_loss: 55.8535\n",
      "Epoch 173/15000\n",
      "0s - loss: 4.1915 - val_loss: 55.0694\n",
      "Epoch 174/15000\n",
      "0s - loss: 4.1972 - val_loss: 54.4153\n",
      "Epoch 175/15000\n",
      "0s - loss: 4.1882 - val_loss: 55.1969\n",
      "Epoch 176/15000\n",
      "0s - loss: 4.1784 - val_loss: 55.0024\n",
      "Epoch 177/15000\n",
      "0s - loss: 4.1757 - val_loss: 54.4344\n",
      "Epoch 178/15000\n",
      "0s - loss: 4.1795 - val_loss: 54.2882\n",
      "Epoch 179/15000\n",
      "0s - loss: 4.1834 - val_loss: 53.7993\n",
      "Epoch 180/15000\n",
      "0s - loss: 4.1846 - val_loss: 53.9531\n",
      "Epoch 181/15000\n",
      "0s - loss: 4.1772 - val_loss: 54.8383\n",
      "Epoch 182/15000\n",
      "0s - loss: 4.1755 - val_loss: 54.6060\n",
      "Epoch 183/15000\n",
      "0s - loss: 4.1821 - val_loss: 55.5221\n",
      "Epoch 184/15000\n",
      "0s - loss: 4.1731 - val_loss: 56.0727\n",
      "Epoch 185/15000\n",
      "0s - loss: 4.1767 - val_loss: 55.6234\n",
      "Epoch 186/15000\n",
      "0s - loss: 4.1694 - val_loss: 53.9427\n",
      "Epoch 187/15000\n",
      "0s - loss: 4.1692 - val_loss: 55.1858\n",
      "Epoch 188/15000\n",
      "0s - loss: 4.1663 - val_loss: 55.2634\n",
      "Epoch 189/15000\n",
      "0s - loss: 4.1690 - val_loss: 55.1592\n",
      "Epoch 190/15000\n",
      "0s - loss: 4.1634 - val_loss: 54.5402\n",
      "Epoch 191/15000\n",
      "0s - loss: 4.1587 - val_loss: 55.2005\n",
      "Epoch 192/15000\n",
      "0s - loss: 4.1577 - val_loss: 55.0410\n",
      "Epoch 193/15000\n",
      "0s - loss: 4.1744 - val_loss: 54.7041\n",
      "Epoch 194/15000\n",
      "0s - loss: 4.1634 - val_loss: 55.3561\n",
      "Epoch 195/15000\n",
      "0s - loss: 4.1677 - val_loss: 54.8059\n",
      "Epoch 196/15000\n",
      "0s - loss: 4.1500 - val_loss: 54.0880\n",
      "Epoch 197/15000\n",
      "0s - loss: 4.3191 - val_loss: 55.7222\n",
      "Epoch 198/15000\n",
      "0s - loss: 4.1536 - val_loss: 55.6294\n",
      "Epoch 199/15000\n",
      "0s - loss: 4.1568 - val_loss: 55.9006\n",
      "Epoch 200/15000\n",
      "0s - loss: 4.1575 - val_loss: 55.4376\n",
      "Epoch 201/15000\n",
      "0s - loss: 4.1490 - val_loss: 55.4997\n",
      "Epoch 202/15000\n",
      "0s - loss: 4.1494 - val_loss: 55.3962\n",
      "Epoch 203/15000\n",
      "0s - loss: 4.1479 - val_loss: 55.1637\n",
      "Epoch 204/15000\n",
      "0s - loss: 4.1463 - val_loss: 56.0080\n",
      "Epoch 205/15000\n",
      "0s - loss: 4.1503 - val_loss: 55.3833\n",
      "Epoch 206/15000\n",
      "0s - loss: 4.1509 - val_loss: 55.3517\n",
      "Epoch 207/15000\n",
      "0s - loss: 4.1445 - val_loss: 55.7666\n",
      "Epoch 208/15000\n",
      "0s - loss: 4.1500 - val_loss: 55.3050\n",
      "Epoch 209/15000\n",
      "0s - loss: 4.1392 - val_loss: 54.3900\n",
      "Epoch 210/15000\n",
      "0s - loss: 4.2317 - val_loss: 55.7663\n",
      "Epoch 211/15000\n",
      "0s - loss: 4.2010 - val_loss: 56.0486\n",
      "Epoch 212/15000\n",
      "0s - loss: 4.1485 - val_loss: 55.9987\n",
      "Epoch 213/15000\n",
      "0s - loss: 4.1426 - val_loss: 55.5188\n",
      "Epoch 214/15000\n",
      "0s - loss: 4.1483 - val_loss: 55.7627\n",
      "Epoch 215/15000\n",
      "0s - loss: 4.1355 - val_loss: 55.8111\n",
      "Epoch 216/15000\n",
      "0s - loss: 4.1417 - val_loss: 55.2976\n",
      "Epoch 217/15000\n",
      "0s - loss: 4.1307 - val_loss: 55.8828\n",
      "Epoch 218/15000\n",
      "0s - loss: 4.1367 - val_loss: 55.4997\n",
      "Epoch 219/15000\n",
      "0s - loss: 4.2442 - val_loss: 56.7403\n",
      "Epoch 220/15000\n",
      "0s - loss: 4.1400 - val_loss: 55.9691\n",
      "Epoch 221/15000\n",
      "0s - loss: 4.1265 - val_loss: 55.2355\n",
      "Epoch 222/15000\n",
      "0s - loss: 4.1315 - val_loss: 55.8588\n",
      "Epoch 223/15000\n",
      "0s - loss: 4.1325 - val_loss: 55.0059\n",
      "Epoch 224/15000\n",
      "0s - loss: 4.1313 - val_loss: 55.5859\n",
      "Epoch 225/15000\n",
      "0s - loss: 4.1239 - val_loss: 55.9092\n",
      "Epoch 226/15000\n",
      "0s - loss: 4.1290 - val_loss: 55.1767\n",
      "Epoch 227/15000\n",
      "0s - loss: 4.2306 - val_loss: 56.2323\n",
      "Epoch 228/15000\n",
      "0s - loss: 4.1280 - val_loss: 56.6403\n",
      "Epoch 229/15000\n",
      "0s - loss: 4.1301 - val_loss: 55.5545\n",
      "Epoch 230/15000\n",
      "0s - loss: 4.1303 - val_loss: 55.6290\n",
      "Epoch 231/15000\n",
      "0s - loss: 4.1247 - val_loss: 55.3994\n",
      "Epoch 232/15000\n",
      "0s - loss: 4.1249 - val_loss: 55.3108\n",
      "Epoch 233/15000\n",
      "0s - loss: 4.1247 - val_loss: 55.5541\n",
      "Epoch 234/15000\n",
      "0s - loss: 4.1216 - val_loss: 55.7159\n",
      "Epoch 235/15000\n",
      "0s - loss: 4.1174 - val_loss: 55.9850\n",
      "Epoch 236/15000\n",
      "0s - loss: 4.1233 - val_loss: 55.8574\n",
      "Epoch 237/15000\n",
      "0s - loss: 4.1213 - val_loss: 55.2339\n",
      "Epoch 238/15000\n",
      "0s - loss: 4.1183 - val_loss: 55.4472\n",
      "Epoch 239/15000\n",
      "0s - loss: 4.1185 - val_loss: 55.9919\n",
      "Epoch 240/15000\n",
      "0s - loss: 4.1200 - val_loss: 56.3486\n",
      "Epoch 241/15000\n",
      "0s - loss: 4.1174 - val_loss: 54.9390\n",
      "Epoch 242/15000\n",
      "0s - loss: 4.1145 - val_loss: 56.3891\n",
      "Epoch 243/15000\n",
      "0s - loss: 4.1409 - val_loss: 56.2911\n",
      "Epoch 244/15000\n",
      "0s - loss: 4.1172 - val_loss: 55.6415\n",
      "Epoch 245/15000\n",
      "0s - loss: 4.1146 - val_loss: 56.2906\n",
      "Epoch 246/15000\n",
      "0s - loss: 4.1349 - val_loss: 56.2416\n",
      "Epoch 247/15000\n",
      "0s - loss: 4.1147 - val_loss: 54.9791\n",
      "Epoch 248/15000\n",
      "0s - loss: 4.1065 - val_loss: 56.0273\n",
      "Epoch 249/15000\n",
      "0s - loss: 4.1242 - val_loss: 55.8176\n",
      "Epoch 250/15000\n",
      "0s - loss: 4.1081 - val_loss: 55.8865\n",
      "Epoch 251/15000\n",
      "0s - loss: 4.1124 - val_loss: 55.0578\n",
      "Epoch 252/15000\n",
      "0s - loss: 4.1115 - val_loss: 55.4038\n",
      "Epoch 253/15000\n",
      "0s - loss: 4.1147 - val_loss: 55.7503\n",
      "Epoch 254/15000\n",
      "0s - loss: 4.1067 - val_loss: 55.0702\n",
      "Epoch 255/15000\n",
      "0s - loss: 4.1017 - val_loss: 55.8606\n",
      "Epoch 256/15000\n",
      "0s - loss: 4.1242 - val_loss: 54.8517\n",
      "Epoch 257/15000\n",
      "0s - loss: 4.1152 - val_loss: 55.6796\n",
      "Epoch 258/15000\n",
      "0s - loss: 4.1021 - val_loss: 55.9664\n",
      "Epoch 259/15000\n",
      "0s - loss: 4.1084 - val_loss: 55.8796\n",
      "Epoch 260/15000\n",
      "0s - loss: 4.1094 - val_loss: 56.3308\n",
      "Epoch 261/15000\n",
      "0s - loss: 4.1051 - val_loss: 55.2566\n",
      "Epoch 262/15000\n",
      "0s - loss: 4.1047 - val_loss: 56.0538\n",
      "Epoch 263/15000\n",
      "0s - loss: 4.1025 - val_loss: 55.9093\n",
      "Epoch 264/15000\n",
      "0s - loss: 4.0912 - val_loss: 56.4858\n",
      "Epoch 265/15000\n",
      "0s - loss: 4.1224 - val_loss: 56.3302\n",
      "Epoch 266/15000\n",
      "0s - loss: 4.1092 - val_loss: 56.3842\n",
      "Epoch 267/15000\n",
      "0s - loss: 4.1079 - val_loss: 55.5479\n",
      "Epoch 268/15000\n",
      "0s - loss: 4.1000 - val_loss: 56.6136\n",
      "Epoch 269/15000\n",
      "0s - loss: 4.1060 - val_loss: 55.8325\n",
      "Epoch 270/15000\n",
      "0s - loss: 4.0929 - val_loss: 55.2597\n",
      "Epoch 271/15000\n",
      "0s - loss: 4.1002 - val_loss: 54.8119\n",
      "Epoch 272/15000\n",
      "0s - loss: 4.1828 - val_loss: 55.9255\n",
      "Epoch 273/15000\n",
      "0s - loss: 4.0975 - val_loss: 55.5244\n",
      "Epoch 274/15000\n",
      "0s - loss: 4.0920 - val_loss: 55.9217\n",
      "Epoch 275/15000\n",
      "0s - loss: 4.0954 - val_loss: 55.6737\n",
      "Epoch 276/15000\n",
      "0s - loss: 4.0854 - val_loss: 55.6782\n",
      "Epoch 277/15000\n",
      "0s - loss: 4.0962 - val_loss: 55.2663\n",
      "Epoch 278/15000\n",
      "0s - loss: 4.0885 - val_loss: 55.5137\n",
      "Epoch 279/15000\n",
      "0s - loss: 4.0869 - val_loss: 55.9968\n",
      "Epoch 280/15000\n",
      "0s - loss: 4.0938 - val_loss: 55.2026\n",
      "Epoch 281/15000\n",
      "0s - loss: 4.0828 - val_loss: 55.5445\n",
      "Epoch 282/15000\n",
      "0s - loss: 4.0834 - val_loss: 55.4927\n",
      "Epoch 283/15000\n",
      "0s - loss: 4.0787 - val_loss: 56.1508\n",
      "Epoch 284/15000\n",
      "0s - loss: 4.0843 - val_loss: 55.6104\n",
      "Epoch 285/15000\n",
      "0s - loss: 4.0814 - val_loss: 55.1685\n",
      "Epoch 286/15000\n",
      "0s - loss: 4.0780 - val_loss: 56.1068\n",
      "Epoch 287/15000\n",
      "0s - loss: 4.0984 - val_loss: 56.0340\n",
      "Epoch 288/15000\n",
      "0s - loss: 4.0801 - val_loss: 55.2166\n",
      "Epoch 289/15000\n",
      "0s - loss: 4.0809 - val_loss: 55.6460\n",
      "Epoch 290/15000\n",
      "0s - loss: 4.0775 - val_loss: 56.1879\n",
      "Epoch 291/15000\n",
      "0s - loss: 4.0770 - val_loss: 55.6225\n",
      "Epoch 292/15000\n",
      "0s - loss: 4.0888 - val_loss: 56.2300\n",
      "Epoch 293/15000\n",
      "0s - loss: 4.0816 - val_loss: 55.8873\n",
      "Epoch 294/15000\n",
      "0s - loss: 4.0734 - val_loss: 56.0644\n",
      "Epoch 295/15000\n",
      "0s - loss: 4.0794 - val_loss: 55.5115\n",
      "Epoch 296/15000\n",
      "0s - loss: 4.0765 - val_loss: 55.3605\n",
      "Epoch 297/15000\n",
      "0s - loss: 4.0898 - val_loss: 55.4289\n",
      "Epoch 298/15000\n",
      "0s - loss: 4.0699 - val_loss: 55.8302\n",
      "Epoch 299/15000\n",
      "0s - loss: 4.0787 - val_loss: 56.2819\n",
      "Epoch 300/15000\n",
      "0s - loss: 4.0793 - val_loss: 55.6856\n",
      "Epoch 301/15000\n",
      "0s - loss: 4.0664 - val_loss: 55.5636\n",
      "Epoch 302/15000\n",
      "0s - loss: 4.0682 - val_loss: 56.0364\n",
      "Epoch 303/15000\n",
      "0s - loss: 4.0665 - val_loss: 56.1230\n",
      "Epoch 304/15000\n",
      "0s - loss: 4.0624 - val_loss: 55.7736\n",
      "Epoch 305/15000\n",
      "0s - loss: 4.0639 - val_loss: 55.9965\n",
      "Epoch 306/15000\n",
      "0s - loss: 4.0894 - val_loss: 55.3671\n",
      "Epoch 307/15000\n",
      "0s - loss: 4.0737 - val_loss: 56.1374\n",
      "Epoch 308/15000\n",
      "0s - loss: 4.0717 - val_loss: 56.0671\n",
      "Epoch 309/15000\n",
      "0s - loss: 4.0635 - val_loss: 56.3069\n",
      "Epoch 310/15000\n",
      "0s - loss: 4.0728 - val_loss: 55.7354\n",
      "Epoch 311/15000\n",
      "0s - loss: 4.0647 - val_loss: 56.0680\n",
      "Epoch 312/15000\n",
      "0s - loss: 4.0699 - val_loss: 55.2771\n",
      "Epoch 313/15000\n",
      "0s - loss: 4.0598 - val_loss: 55.5335\n",
      "Epoch 314/15000\n",
      "0s - loss: 4.0685 - val_loss: 55.5119\n",
      "Epoch 315/15000\n",
      "0s - loss: 4.0679 - val_loss: 55.6181\n",
      "Epoch 316/15000\n",
      "0s - loss: 4.0763 - val_loss: 56.2685\n",
      "Epoch 317/15000\n",
      "0s - loss: 4.0858 - val_loss: 56.1070\n",
      "Epoch 318/15000\n",
      "0s - loss: 4.0554 - val_loss: 55.4928\n",
      "Epoch 319/15000\n",
      "0s - loss: 4.0585 - val_loss: 55.6449\n",
      "Epoch 320/15000\n",
      "0s - loss: 4.0585 - val_loss: 56.1909\n",
      "Epoch 321/15000\n",
      "0s - loss: 4.0558 - val_loss: 55.4149\n",
      "Epoch 322/15000\n",
      "0s - loss: 4.0621 - val_loss: 55.4001\n",
      "Epoch 323/15000\n",
      "0s - loss: 4.0709 - val_loss: 55.6442\n",
      "Epoch 324/15000\n",
      "0s - loss: 4.0636 - val_loss: 55.6268\n",
      "Epoch 325/15000\n",
      "0s - loss: 4.0448 - val_loss: 56.2199\n",
      "Epoch 326/15000\n",
      "0s - loss: 4.0492 - val_loss: 55.4015\n",
      "Epoch 327/15000\n",
      "0s - loss: 4.0735 - val_loss: 55.4399\n",
      "Epoch 328/15000\n",
      "0s - loss: 4.0511 - val_loss: 55.8180\n",
      "Epoch 329/15000\n",
      "0s - loss: 4.0505 - val_loss: 56.6514\n",
      "Epoch 330/15000\n",
      "0s - loss: 4.0733 - val_loss: 56.0957\n",
      "Epoch 331/15000\n",
      "0s - loss: 4.0569 - val_loss: 56.4863\n",
      "Epoch 332/15000\n",
      "0s - loss: 4.0430 - val_loss: 56.0386\n",
      "Epoch 333/15000\n",
      "0s - loss: 4.0441 - val_loss: 55.6896\n",
      "Epoch 334/15000\n",
      "0s - loss: 4.0505 - val_loss: 55.2219\n",
      "Epoch 335/15000\n",
      "0s - loss: 4.0482 - val_loss: 55.2166\n",
      "Epoch 336/15000\n",
      "0s - loss: 4.0595 - val_loss: 55.8358\n",
      "Epoch 337/15000\n",
      "0s - loss: 4.0520 - val_loss: 56.8736\n",
      "Epoch 338/15000\n",
      "0s - loss: 4.0413 - val_loss: 55.9194\n",
      "Epoch 339/15000\n",
      "0s - loss: 4.0461 - val_loss: 56.2971\n",
      "Epoch 340/15000\n",
      "0s - loss: 4.0394 - val_loss: 56.2298\n",
      "Epoch 341/15000\n",
      "0s - loss: 4.0313 - val_loss: 55.0846\n",
      "Epoch 342/15000\n",
      "0s - loss: 4.0584 - val_loss: 56.2128\n",
      "Epoch 343/15000\n",
      "0s - loss: 4.0415 - val_loss: 56.1997\n",
      "Epoch 344/15000\n",
      "0s - loss: 4.0404 - val_loss: 56.4160\n",
      "Epoch 345/15000\n",
      "0s - loss: 4.0524 - val_loss: 55.8370\n",
      "Epoch 346/15000\n",
      "0s - loss: 4.0286 - val_loss: 56.8256\n",
      "Epoch 347/15000\n",
      "0s - loss: 4.0463 - val_loss: 56.5298\n",
      "Epoch 348/15000\n",
      "0s - loss: 4.0396 - val_loss: 55.9872\n",
      "Epoch 349/15000\n",
      "0s - loss: 4.0407 - val_loss: 55.7186\n",
      "Epoch 350/15000\n",
      "0s - loss: 4.0272 - val_loss: 55.1319\n",
      "Epoch 351/15000\n",
      "0s - loss: 4.0334 - val_loss: 55.8062\n",
      "Epoch 352/15000\n",
      "0s - loss: 4.0328 - val_loss: 56.0099\n",
      "Epoch 353/15000\n",
      "0s - loss: 4.0244 - val_loss: 56.2247\n",
      "Epoch 354/15000\n",
      "0s - loss: 4.0345 - val_loss: 56.4587\n",
      "Epoch 355/15000\n",
      "0s - loss: 4.0304 - val_loss: 56.1455\n",
      "Epoch 356/15000\n",
      "0s - loss: 4.0226 - val_loss: 55.7503\n",
      "Epoch 357/15000\n",
      "0s - loss: 4.0259 - val_loss: 56.7030\n",
      "Epoch 358/15000\n",
      "0s - loss: 4.0369 - val_loss: 56.3078\n",
      "Epoch 359/15000\n",
      "0s - loss: 4.0193 - val_loss: 56.2328\n",
      "Epoch 360/15000\n",
      "0s - loss: 4.0566 - val_loss: 56.6058\n",
      "Epoch 361/15000\n",
      "0s - loss: 4.0327 - val_loss: 56.5941\n",
      "Epoch 362/15000\n",
      "0s - loss: 4.0316 - val_loss: 56.3047\n",
      "Epoch 363/15000\n",
      "0s - loss: 4.0267 - val_loss: 56.3647\n",
      "Epoch 364/15000\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = np.round(abs(classifier.predict(X_test)))\n",
    "y_cpu = dataset_holder[0].inverse_transform(abs(y_pred[:,0]))\n",
    "y_ram = dataset_holder[1].inverse_transform(abs(y_pred[:,1]))\n",
    "score_mae_CPU = mean_absolute_error(y_cpu, trainee_holder['cpu_rate']['y_test'])\n",
    "print score_mae_CPU\n",
    "score_mae_RAM = mean_absolute_error(y_ram, trainee_holder['mem_usage']['y_test'])\n",
    "print score_mae_RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe6e4911e10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "plot_figure_with_label(y_pred=y_cpu[100:200], y_test=trainee_holder['cpu_rate']['y_test'][100:200], \n",
    "                       title='Fuzzy BPNN Multi Dimension (Sliding Window Size = 3)', metric='CPU Utilization (%)')\n",
    "# plot_figure_with_label(y_pred=y_ram[100:200], y_test=trainee_holder['mem_usage']['y_test'][100:200], \n",
    "#                        title='Fuzzy BPNN Multi Dimension (Sliding Window Size = 3)', metric='Memory Usage (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savez('model_saved/CPU_BPNNM_%s_%s' % (sliding_number, score_mae_CPU), y_pred=y_cpu, \n",
    "         y_true=trainee_holder['cpu_rate']['y_test'])\n",
    "np.savez('model_saved/RAM_BPNNM_%s_%s' % (sliding_number, score_mae_RAM), \n",
    "         y_pred=y_ram, y_test=trainee_holder['mem_usage']['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy GABPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_hidden = 7\n",
    "fit_params = {\n",
    "    'neural_shape': [len(X_train[0]), n_hidden, 2]\n",
    "}\n",
    "ga_estimator = GAEstimator(cross_rate=0.5, mutation_rate=0.02, gen_size=100, pop_size=30)\n",
    "nn = NeuralFlowRegressor(hidden_nodes=[n_hidden], optimize='Adam',activation='sigmoid'\n",
    "                         , steps=7000, learning_rate=1E-02)\n",
    "classifier = OptimizerNNEstimator(ga_estimator, nn)\n",
    "classifier.fit(X_train,y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.785109242762\n",
      "0.11264298441\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.round(abs(classifier.predict(X_test)))\n",
    "y_cpu = dataset_holder[0].inverse_transform(abs(y_pred[:,0]))\n",
    "y_ram = dataset_holder[1].inverse_transform(abs(y_pred[:,1]))\n",
    "score_mae_CPU = mean_absolute_error(y_cpu, trainee_holder['cpu_rate']['y_test'])\n",
    "print score_mae_CPU\n",
    "score_mae_RAM = mean_absolute_error(y_ram, trainee_holder['mem_usage']['y_test'])\n",
    "print score_mae_RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7faea01a5450>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "# plot_figure_with_label(y_pred=y_cpu[100:200], y_test=trainee_holder['cpu_rate']['y_test'][100:200], \n",
    "#                        title='Fuzzy GABPNN Multi Dimension (Sliding Window Size = 3)', metric='CPU Utilization (%)')\n",
    "plot_figure_with_label(y_pred=y_ram[100:200], y_test=trainee_holder['mem_usage']['y_test'][100:200], \n",
    "                       title='Fuzzy GABPNN Multi Dimension (Sliding Window Size = 3)', metric='Memory Usage (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savez('model_saved/CPU_FGABPNNM_%s_%s' % (sliding_number, score_mae_CPU), y_pred=y_cpu, \n",
    "         y_true=trainee_holder['cpu_rate']['y_test'])\n",
    "np.savez('model_saved/RAM_FGABPNNM_%s_%s' % (sliding_number, score_mae_RAM), \n",
    "         y_pred=y_ram, y_test=trainee_holder['mem_usage']['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Multilayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Merge\n",
    "from keras.utils.visualize_util import plot\n",
    "from keras.callbacks import EarlyStopping\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_train = X_train[:,:3]\n",
    "ram_train = X_train[:,3:]\n",
    "cpu_test = X_test[:,:3]\n",
    "ram_test = X_test[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cpu_target = trainee_holder['cpu_rate']['y_test']\n",
    "ram_target = trainee_holder['mem_usage']['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_cpu = Sequential([Dense(3, input_dim=cpu_train.shape[1],activation='relu')])\n",
    "model_ram = Sequential([Dense(3, input_dim=ram_train.shape[1],activation='relu')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_model = Sequential()\n",
    "merged_model.add(Merge([model_cpu, model_ram], mode='ave', concat_axis=1))\n",
    "infer_model = Sequential([\n",
    "        merged_model,\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(512,activation='relu'),\n",
    "        Dense(256,activation='relu'),\n",
    "        Dense(32,activation='relu'),\n",
    "        Dense(output_dim=2,activation='relu')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infer_model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "earlyStop = EarlyStopping(monitor='val_loss',patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1890 samples, validate on 210 samples\n",
      "Epoch 1/5000\n",
      "0s - loss: 10.6999 - val_loss: 64.7213\n",
      "Epoch 2/5000\n",
      "0s - loss: 7.2567 - val_loss: 63.8412\n",
      "Epoch 3/5000\n",
      "0s - loss: 7.1655 - val_loss: 63.4482\n",
      "Epoch 4/5000\n",
      "0s - loss: 7.1745 - val_loss: 63.4283\n",
      "Epoch 5/5000\n",
      "0s - loss: 7.1396 - val_loss: 63.7168\n",
      "Epoch 6/5000\n",
      "0s - loss: 7.1425 - val_loss: 63.7338\n",
      "Epoch 7/5000\n",
      "0s - loss: 7.1477 - val_loss: 65.2760\n",
      "Epoch 8/5000\n",
      "0s - loss: 7.1754 - val_loss: 63.7664\n",
      "Epoch 9/5000\n",
      "0s - loss: 7.1487 - val_loss: 64.4669\n",
      "Epoch 10/5000\n",
      "0s - loss: 7.1682 - val_loss: 64.3312\n",
      "Epoch 11/5000\n",
      "0s - loss: 7.1363 - val_loss: 63.5353\n",
      "Epoch 12/5000\n",
      "0s - loss: 7.1573 - val_loss: 64.8231\n",
      "Epoch 13/5000\n",
      "0s - loss: 7.1606 - val_loss: 64.3240\n",
      "Epoch 14/5000\n",
      "0s - loss: 7.1400 - val_loss: 64.1241\n",
      "Epoch 15/5000\n",
      "0s - loss: 7.1415 - val_loss: 63.8108\n",
      "Epoch 16/5000\n",
      "0s - loss: 7.2563 - val_loss: 64.2214\n",
      "Epoch 17/5000\n",
      "0s - loss: 7.2512 - val_loss: 64.3820\n",
      "Epoch 18/5000\n",
      "0s - loss: 7.1624 - val_loss: 63.4711\n",
      "Epoch 19/5000\n",
      "0s - loss: 7.1666 - val_loss: 63.2462\n",
      "Epoch 20/5000\n",
      "0s - loss: 7.1731 - val_loss: 63.7189\n",
      "Epoch 21/5000\n",
      "0s - loss: 7.1421 - val_loss: 62.8445\n",
      "Epoch 22/5000\n",
      "0s - loss: 7.1311 - val_loss: 64.2256\n",
      "Epoch 23/5000\n",
      "0s - loss: 7.1592 - val_loss: 63.4262\n",
      "Epoch 24/5000\n",
      "0s - loss: 7.1684 - val_loss: 63.3440\n",
      "Epoch 25/5000\n",
      "0s - loss: 7.1257 - val_loss: 62.9395\n",
      "Epoch 26/5000\n",
      "0s - loss: 7.1665 - val_loss: 63.7107\n",
      "Epoch 27/5000\n",
      "0s - loss: 7.2009 - val_loss: 63.5948\n",
      "Epoch 28/5000\n",
      "0s - loss: 7.1734 - val_loss: 63.2689\n",
      "Epoch 29/5000\n",
      "0s - loss: 7.1997 - val_loss: 63.3134\n",
      "Epoch 30/5000\n",
      "0s - loss: 7.1824 - val_loss: 63.4316\n",
      "Epoch 31/5000\n",
      "0s - loss: 7.1559 - val_loss: 63.0163\n",
      "Epoch 32/5000\n",
      "0s - loss: 7.2199 - val_loss: 63.3279\n",
      "Epoch 33/5000\n",
      "0s - loss: 7.1958 - val_loss: 63.4301\n",
      "Epoch 34/5000\n",
      "0s - loss: 7.1732 - val_loss: 63.2633\n",
      "Epoch 35/5000\n",
      "0s - loss: 7.1569 - val_loss: 63.4777\n",
      "Epoch 36/5000\n",
      "0s - loss: 7.1359 - val_loss: 63.5510\n",
      "Epoch 37/5000\n",
      "0s - loss: 7.1953 - val_loss: 63.7322\n",
      "Epoch 38/5000\n",
      "0s - loss: 7.1771 - val_loss: 63.6133\n",
      "Epoch 39/5000\n",
      "0s - loss: 7.1326 - val_loss: 63.3644\n",
      "Epoch 40/5000\n",
      "0s - loss: 7.2012 - val_loss: 63.6704\n",
      "Epoch 41/5000\n",
      "0s - loss: 7.1545 - val_loss: 63.1678\n",
      "Epoch 42/5000\n",
      "0s - loss: 7.1505 - val_loss: 63.0226\n"
     ]
    }
   ],
   "source": [
    "history = infer_model.fit([cpu_train,ram_train],y_train,nb_epoch=5000,batch_size=64,verbose=2,validation_split=0.1,\n",
    "                callbacks=[earlyStop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1ac5ef13d0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = history.history\n",
    "df = pd.DataFrame.from_dict(log)\n",
    "%matplotlib\n",
    "df.plot(kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955596659243\n",
      "0.21644766147\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.round(abs(infer_model.predict([cpu_test,ram_test])))\n",
    "y_cpu = dataset_holder[0].inverse_transform(abs(y_pred[:,0]))\n",
    "y_ram = dataset_holder[1].inverse_transform(abs(y_pred[:,1]))\n",
    "score_mae_CPU = mean_absolute_error(y_cpu, trainee_holder['cpu_rate']['y_test'])\n",
    "print score_mae_CPU\n",
    "score_mae_RAM = mean_absolute_error(y_ram, trainee_holder['mem_usage']['y_test'])\n",
    "print score_mae_RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/cbook.py:137: MatplotlibDeprecationWarning: The set_color_cycle attribute was deprecated in version 1.5. Use set_prop_cycle instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1af8fed4d0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "# plot_figure_with_label(y_pred=y_cpu[100:200], y_test=trainee_holder['cpu_rate']['y_test'][100:200], \n",
    "#                        title='Fuzzy GABPNN Multi Dimension (Sliding Window Size = 3)', metric='CPU Utilization (%)')\n",
    "plot_figure_with_label(y_pred=y_ram[100:200], y_test=trainee_holder['mem_usage']['y_test'][100:200], \n",
    "                       title='Fuzzy GABPNN Multi Dimension (Sliding Window Size = 3)', metric='Memory Usage (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
