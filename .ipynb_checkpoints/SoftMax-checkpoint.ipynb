{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "import math\n",
      "from estimators.NeuralFlow import *\n",
      "from utils.SlidingWindowUtil import SlidingWindow\n",
      "import skflow as sf\n",
      "from sklearn import datasets, metrics\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "from utils.GraphUtil import *\n",
      "from sklearn.preprocessing import OneHotEncoder\n",
      "\n",
      "scaler = MinMaxScaler()\n",
      "dat = scaler.fit_transform(pd.read_csv('sample_610_10min_unnormalize.csv',parse_dates=True,index_col=0,names=['cpu_rate'])['cpu_rate'][:3000])\n",
      "dat = pd.Series(dat.round(4))\n",
      "\n",
      "partition_size = 0.001\n",
      "umin = math.floor(min(dat));\n",
      "umax = math.ceil(max(dat));\n",
      "# 2: Partition of universe\n",
      "# Method: Dividing in the half-thousands\n",
      "def get_midpoint(ptuple):\n",
      "    return 0.5*(ptuple[0]+ptuple[1])\n",
      "def get_midpoint_vector(tuple_vector):\n",
      "    return [get_midpoint(x) for x in tuple_vector];\n",
      "def get_fuzzy_class(point, partition_size):\n",
      "    return int(math.floor(point / partition_size))\n",
      "def get_fuzzy_dataset(data):\n",
      "    u_class = []\n",
      "    for item in data:\n",
      "        u_class.append(get_fuzzy_class(item,partition_size))\n",
      "    return u_class\n",
      "def mapping_class(u_class):\n",
      "    unique_class = np.unique(u_class)\n",
      "    index = np.arange(unique_class.shape[0])\n",
      "    inverted = {}\n",
      "    mapping = {}\n",
      "    for idx,val in enumerate(unique_class):\n",
      "        mapping[val] = idx\n",
      "        inverted[idx] = val\n",
      "    return mapping, inverted\n",
      "def defuzzy(index, inverted,midpoints):\n",
      "    f_class = inverted[index]\n",
      "    return midpoints[f_class]\n",
      "\n",
      "sliding_number = 3\n",
      "# result = []\n",
      "\n",
      "nIter = int((umax-umin)/partition_size)\n",
      "u_vectorized = []\n",
      "\n",
      "for i in range(nIter) :\n",
      "    u_vectorized.append((umin + i*partition_size,umin + (i+1)*partition_size));\n",
      "\n",
      "u_midpoints = get_midpoint_vector(u_vectorized)\n",
      "u_class = np.array(get_fuzzy_dataset(dat),dtype=np.int32)\n",
      "\n",
      "onehotEncoder = OneHotEncoder()\n",
      "features = onehotEncoder.fit_transform(u_class_transform).toarray()\n",
      "\n",
      "u_unique_inverted, u_unique_mapping = mapping_class(u_class)\n",
      "u_class_transform = [u_unique_inverted[item] for item in u_class]\n",
      "\n",
      "X_train_size = int(len(u_class_transform)*0.7)\n",
      "sliding = np.array(list(SlidingWindow(u_class_transform, sliding_number)))\n",
      "sliding = np.array(sliding, dtype=np.int32)\n",
      "X_train = sliding[:X_train_size]\n",
      "y_train = features[sliding_number:X_train_size+sliding_number]\n",
      "X_test = sliding[X_train_size:]\n",
      "y_test = features[X_train_size+sliding_number-1:]\n",
      "y_actual_test = dat[X_train_size+sliding_number-1:].tolist()\n",
      "# # Define classifier\n",
      "n_hidden = len(u_unique_inverted) + sliding_number"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = tf.placeholder(tf.float32, shape=[None, len(X_train[0])])\n",
      "y_ = tf.placeholder(tf.float32, shape=[None, features.shape[1]])\n",
      "\n",
      "W = tf.Variable(tf.zeros([len(X_train[0]),features.shape[1]]))\n",
      "b = tf.Variable(tf.zeros([features.shape[1]]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sess = tf.InteractiveSession()\n",
      "sess.run(tf.initialize_all_variables())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Exception AssertionError: AssertionError() in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f33a7c62a50>> ignored\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
      "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
      "train_step = tf.train.AdamOptimizer(1E-02).minimize(cross_entropy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with tf.Session() as sess:\n",
      "    sess.run(tf.initialize_all_variables())\n",
      "    # Training cycle\n",
      "    for epoch in range(training_epochs):\n",
      "        avg_cost = 0.\n",
      "        total_batch = int(X_train.shape[0]/batch_size)\n",
      "        # Loop over all batches\n",
      "#         for i in range(total_batch):\n",
      "#             batch_x, batch_y = X_train[i%\n",
      "            # Run optimization op (backprop) and cost op (to get loss value)\n",
      "        _, c = train_step.run(feed_dict={x: X_train,y: y_train})\n",
      "        # Compute average loss\n",
      "#         avg_cost += c\n",
      "#         # Display logs per epoch step\n",
      "#         if epoch % display_step == 0:\n",
      "#             print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
      "#                 \"{:.9f}\".format(avg_cost)\n",
      "    print \"Optimization Finished!\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'init' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-17-03059a016e53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Training cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'init' is not defined"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Exception AssertionError: AssertionError() in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f33a7c60e90>> ignored\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}