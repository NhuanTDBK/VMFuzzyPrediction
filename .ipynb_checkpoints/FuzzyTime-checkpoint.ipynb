{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "import math\n",
      "from estimators.NeuralFlow import *\n",
      "from utils.SlidingWindowUtil import SlidingWindow\n",
      "\n",
      "from sklearn import datasets, metrics\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "from utils.GraphUtil import *\n",
      "from estimators.GAEstimator import GAEstimator\n",
      "from estimators.OptimizerNNEstimator import OptimizerNNEstimator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
        "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Import Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaler = MinMaxScaler()\n",
      "dat = pd.read_csv('sampling_617685_metric_10min_datetime.csv',parse_dates=True,index_col=0)[:3000]\n",
      "dat = pd.Series(dat['cpu_rate'].round(3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distance = round(dat.max() / (dat.max() / 0.25 + 1),4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "0.2489"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Preprocessing Fuzzy Time Series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "partition_size = 0.2489\n",
      "umin = math.floor(min(dat));\n",
      "umax = math.ceil(max(dat));\n",
      "# 2: Partition of universe\n",
      "# Method: Dividing in the half-thousands\n",
      "def get_midpoint(ptuple):\n",
      "    return 0.5*(ptuple[0]+ptuple[1])\n",
      "def get_midpoint_vector(tuple_vector):\n",
      "    return [get_midpoint(x) for x in tuple_vector];\n",
      "def get_fuzzy_class(point, partition_size):\n",
      "    return int(math.floor(point / partition_size))\n",
      "def get_fuzzy_dataset(data):\n",
      "    u_class = []\n",
      "    for item in data:\n",
      "        u_class.append(get_fuzzy_class(item,partition_size))\n",
      "    return u_class\n",
      "def mapping_class(u_class):\n",
      "    unique_class = np.unique(u_class)\n",
      "    index = np.arange(unique_class.shape[0])\n",
      "    inverted = {}\n",
      "    mapping = {}\n",
      "    for idx,val in enumerate(unique_class):\n",
      "        mapping[val] = idx\n",
      "        inverted[idx] = val\n",
      "    return mapping, inverted\n",
      "def defuzzy(index, inverted,midpoints):\n",
      "    f_class = inverted[index]\n",
      "    return midpoints[f_class]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sliding_number = 3\n",
      "# result = []\n",
      "\n",
      "nIter = int((umax-umin)/partition_size)\n",
      "u_vectorized = []\n",
      "\n",
      "for i in range(nIter) :\n",
      "    u_vectorized.append((umin + i*partition_size,umin + (i+1)*partition_size));\n",
      "\n",
      "u_midpoints = get_midpoint_vector(u_vectorized)\n",
      "u_class = np.array(get_fuzzy_dataset(dat),dtype=np.int32)\n",
      "\n",
      "u_unique_inverted, u_unique_mapping = mapping_class(u_class)\n",
      "u_class_transform = [u_unique_inverted[item] for item in u_class]\n",
      "\n",
      "X_train_size = int(len(u_class_transform)*0.7)\n",
      "sliding = np.array(list(SlidingWindow(u_class_transform, sliding_number)))\n",
      "sliding = np.array(sliding, dtype=np.int32)\n",
      "X_train = sliding[:X_train_size]\n",
      "y_train = u_class_transform[sliding_number:X_train_size+sliding_number]\n",
      "X_test = sliding[X_train_size:]\n",
      "y_test = u_class_transform[X_train_size+sliding_number-1:]\n",
      "y_actual_test = dat[X_train_size+sliding_number-1:].tolist()\n",
      "# # Define classifier\n",
      "n_hidden = len(X_train[0]) + sliding_number\n",
      "# "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savez(\"fuzzy_train_direct\",X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# classifier = skflow.TensorFlowDNNClassifier(hidden_units=[n_hidden], n_classes=len(u_unique_inverted),steps=10000, \n",
      "#                                             learning_rate= 0.0001, optimizer='Adam', verbose=0)\n",
      "# fit_params = {\n",
      "#     'neural_shape':[len(X_train[0]),n_hidden,1]\n",
      "#     }\n",
      "# ga_estimator = GAEstimator(cross_rate=0.5, mutation_rate=0.02, gen_size=50)\n",
      "# nn = NeuralFlowRegressor(hidden_nodes=[n_hidden],optimize='Adam'\n",
      "#                                  ,steps=7000,learning_rate=1E-03)\n",
      "# classifier = OptimizerNNEstimator(ga_estimator, nn)\n",
      "classifier = NeuralFlowRegressor(hidden_nodes=[15],optimize='Adam'\n",
      "                                 ,steps=7000,learning_rate=1E-03)\n",
      "a = classifier.fit(X_train, y_train, **fit_params)\n",
      "ypred = np.round(classifier.predict(X_test)).flatten()\n",
      "ypred_defuzzy = [defuzzy(item,u_unique_mapping,u_midpoints) for item in ypred]\n",
      "score = mean_absolute_error(ypred_defuzzy,y_actual_test)\n",
      "# result.append((sliding_number,score))\n",
      "print score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialization\n",
        "Step #100, epoch #4, avg. train loss: 28.65909"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #200, epoch #9, avg. train loss: 25.77788"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #300, epoch #14, avg. train loss: 23.09423"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #400, epoch #19, avg. train loss: 24.67438"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #500, epoch #23, avg. train loss: 24.37910"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #600, epoch #28, avg. train loss: 23.47868"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #700, epoch #33, avg. train loss: 24.11923"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #800, epoch #38, avg. train loss: 23.26619"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #900, epoch #42, avg. train loss: 23.73113"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1000, epoch #47, avg. train loss: 23.78783"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1100, epoch #52, avg. train loss: 23.36085"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1200, epoch #57, avg. train loss: 23.67108"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1300, epoch #61, avg. train loss: 23.81437"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1400, epoch #66, avg. train loss: 23.63163"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1500, epoch #71, avg. train loss: 23.28213"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1600, epoch #76, avg. train loss: 23.64065"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1700, epoch #80, avg. train loss: 23.67986"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1800, epoch #85, avg. train loss: 23.22242"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1900, epoch #90, avg. train loss: 23.19531"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2000, epoch #95, avg. train loss: 23.86158"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2100, epoch #100, avg. train loss: 23.55283"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2200, epoch #104, avg. train loss: 23.22653"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2300, epoch #109, avg. train loss: 23.93130"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2400, epoch #114, avg. train loss: 24.05480"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2500, epoch #119, avg. train loss: 22.55437"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2600, epoch #123, avg. train loss: 23.24754"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2700, epoch #128, avg. train loss: 24.54140"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2800, epoch #133, avg. train loss: 22.56003"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2900, epoch #138, avg. train loss: 23.30151"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3000, epoch #142, avg. train loss: 23.90436"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3100, epoch #147, avg. train loss: 22.61931"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3200, epoch #152, avg. train loss: 24.58755"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3300, epoch #157, avg. train loss: 23.00775"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3400, epoch #161, avg. train loss: 23.39388"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3500, epoch #166, avg. train loss: 23.18199"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3600, epoch #171, avg. train loss: 23.74033"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3700, epoch #176, avg. train loss: 23.27876"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3800, epoch #180, avg. train loss: 23.98353"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3900, epoch #185, avg. train loss: 22.94267"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4000, epoch #190, avg. train loss: 24.15025"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4100, epoch #195, avg. train loss: 23.23432"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4200, epoch #200, avg. train loss: 23.39559"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4300, epoch #204, avg. train loss: 23.86746"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4400, epoch #209, avg. train loss: 22.87125"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4500, epoch #214, avg. train loss: 24.13094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4600, epoch #219, avg. train loss: 22.83821"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4700, epoch #223, avg. train loss: 23.85011"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4800, epoch #228, avg. train loss: 23.16613"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4900, epoch #233, avg. train loss: 23.44091"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5000, epoch #238, avg. train loss: 23.45718"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5100, epoch #242, avg. train loss: 22.92166"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5200, epoch #247, avg. train loss: 24.02486"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5300, epoch #252, avg. train loss: 22.95442"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5400, epoch #257, avg. train loss: 24.05753"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5500, epoch #261, avg. train loss: 23.56180"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5600, epoch #266, avg. train loss: 23.32282"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5700, epoch #271, avg. train loss: 24.06981"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5800, epoch #276, avg. train loss: 23.04200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5900, epoch #280, avg. train loss: 23.02863"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6000, epoch #285, avg. train loss: 23.78203"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6100, epoch #290, avg. train loss: 23.55656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6200, epoch #295, avg. train loss: 22.81688"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6300, epoch #300, avg. train loss: 23.70283"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6400, epoch #304, avg. train loss: 23.95191"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6500, epoch #309, avg. train loss: 22.70976"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6600, epoch #314, avg. train loss: 23.16494"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6700, epoch #319, avg. train loss: 23.76873"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6800, epoch #323, avg. train loss: 23.21026"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6900, epoch #328, avg. train loss: 24.42373"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #7000, epoch #333, avg. train loss: 23.00323"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.753409131403\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib\n",
      "plot_figure(y_pred=ypred_defuzzy[:200],y_true=y_actual_test[:200], title='High Order Time Series with order %s, hidden nodes = %s: %s'%(sliding_number,n_hidden,score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: Qt4Agg\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savez('fuzzy_neuro_%s_%s'%(sliding_number,score),y_pred=ypred_defuzzy,y_true=y_actual_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "BPNN Experiment with data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dat_nn = np.asarray(scaler.fit_transform(dat))\n",
      "X_train_size = int(len(dat_nn)*0.7)\n",
      "sliding = np.array(list(SlidingWindow(dat_nn, sliding_number)))\n",
      "X_train_nn = sliding[:X_train_size]\n",
      "y_train_nn = dat_nn[sliding_number:X_train_size+sliding_number].reshape(-1,1)\n",
      "X_test_nn = sliding[X_train_size:]\n",
      "y_test_nn = dat_nn[X_train_size+sliding_number-1:].reshape(-1,1)\n",
      "y_actual_test = dat[X_train_size+sliding_number-1:].tolist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimator = NeuralFlowRegressor(learning_rate=0.001, hidden_nodes=[15], steps=5000,optimize='Adam')\n",
      "estimator.fit(X_train_nn,y_train_nn)\n",
      "y_pred = scaler.inverse_transform(estimator.predict(X_test_nn))\n",
      "score_nn = mean_absolute_error(y_pred,y_actual_test)\n",
      "print score_nn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib\n",
      "plot_figure(y_pred=y_pred,y_true=y_actual_test, title='BPNN with sliding window = %s: %s'%(sliding_number,score_nn))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: Qt4Agg\n"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savez('neuro_%s_%s'%(sliding_number,score_nn),y_pred=y_pred,y_true=y_actual_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    }
   ],
   "metadata": {}
  }
 ]
}