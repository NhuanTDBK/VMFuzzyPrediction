{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "import math\n",
      "from estimators.NeuralFlow import *\n",
      "from utils.SlidingWindowUtil import SlidingWindow\n",
      "import skflow as sf\n",
      "from sklearn import datasets, metrics\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "from utils.GraphUtil import *\n",
      "from sklearn.preprocessing import OneHotEncoder"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Import Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaler = MinMaxScaler()\n",
      "dat = scaler.fit_transform(pd.read_csv('sample_610_10min_unnormalize.csv',parse_dates=True,index_col=0,names=['cpu_rate'])['cpu_rate'][:3000])\n",
      "dat = pd.Series(dat.round(4))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = dat.sort_values().unique()\n",
      "for i in a:\n",
      "    print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0\n",
        "0.0001\n",
        "0.0009\n",
        "0.0014\n",
        "0.0016\n",
        "0.0017\n",
        "0.0019\n",
        "0.0021\n",
        "0.0022\n",
        "0.0023\n",
        "0.0024\n",
        "0.0025\n",
        "0.0026\n",
        "0.0027\n",
        "0.0028\n",
        "0.0029\n",
        "0.003\n",
        "0.0031\n",
        "0.0032\n",
        "0.0033\n",
        "0.0034\n",
        "0.0035\n",
        "0.0036\n",
        "0.0037\n",
        "0.0038\n",
        "0.0039\n",
        "0.004\n",
        "0.0041\n",
        "0.0042\n",
        "0.0043\n",
        "0.0044\n",
        "0.0045\n",
        "0.0046\n",
        "0.0047\n",
        "0.0048\n",
        "0.0049\n",
        "0.005\n",
        "0.0051\n",
        "0.0052\n",
        "0.0053\n",
        "0.0054\n",
        "0.0055\n",
        "0.0056\n",
        "0.0057\n",
        "0.0058\n",
        "0.0059\n",
        "0.006\n",
        "0.0061\n",
        "0.0062\n",
        "0.0063\n",
        "0.0064\n",
        "0.0065\n",
        "0.0066\n",
        "0.0067\n",
        "0.0068\n",
        "0.0069\n",
        "0.007\n",
        "0.0071\n",
        "0.0072\n",
        "0.0073\n",
        "0.0074\n",
        "0.0075\n",
        "0.0076\n",
        "0.0077\n",
        "0.0078\n",
        "0.0079\n",
        "0.008\n",
        "0.0081\n",
        "0.0082\n",
        "0.0083\n",
        "0.0084\n",
        "0.0085\n",
        "0.0086\n",
        "0.0087\n",
        "0.0088\n",
        "0.0089\n",
        "0.009\n",
        "0.0091\n",
        "0.0092\n",
        "0.0093\n",
        "0.0094\n",
        "0.0095\n",
        "0.0096\n",
        "0.0097\n",
        "0.0098\n",
        "0.0099\n",
        "0.01\n",
        "0.0101\n",
        "0.0102\n",
        "0.0103\n",
        "0.0104\n",
        "0.0105\n",
        "0.0106\n",
        "0.0107\n",
        "0.0108\n",
        "0.0109\n",
        "0.011\n",
        "0.0111\n",
        "0.0112\n",
        "0.0113\n",
        "0.0114\n",
        "0.0115\n",
        "0.0116\n",
        "0.0117\n",
        "0.0118\n",
        "0.0119\n",
        "0.012\n",
        "0.0121\n",
        "0.0122\n",
        "0.0123\n",
        "0.0124\n",
        "0.0125\n",
        "0.0126\n",
        "0.0127\n",
        "0.0128\n",
        "0.0129\n",
        "0.013\n",
        "0.0131\n",
        "0.0132\n",
        "0.0133\n",
        "0.0134\n",
        "0.0135\n",
        "0.0136\n",
        "0.0137\n",
        "0.0138\n",
        "0.0139\n",
        "0.014\n",
        "0.0141\n",
        "0.0142\n",
        "0.0143\n",
        "0.0144\n",
        "0.0145\n",
        "0.0146\n",
        "0.0147\n",
        "0.0148\n",
        "0.0149\n",
        "0.015\n",
        "0.0151\n",
        "0.0152\n",
        "0.0153\n",
        "0.0154\n",
        "0.0155\n",
        "0.0156\n",
        "0.0157\n",
        "0.0158\n",
        "0.0159\n",
        "0.016\n",
        "0.0161\n",
        "0.0162\n",
        "0.0163\n",
        "0.0164\n",
        "0.0165\n",
        "0.0166\n",
        "0.0167\n",
        "0.0168\n",
        "0.0169\n",
        "0.017\n",
        "0.0171\n",
        "0.0172\n",
        "0.0173\n",
        "0.0174\n",
        "0.0175\n",
        "0.0176\n",
        "0.0177\n",
        "0.0178\n",
        "0.0179\n",
        "0.018\n",
        "0.0181\n",
        "0.0182\n",
        "0.0183\n",
        "0.0184\n",
        "0.0185\n",
        "0.0186\n",
        "0.0187\n",
        "0.0188\n",
        "0.0189\n",
        "0.019\n",
        "0.0191\n",
        "0.0192\n",
        "0.0193\n",
        "0.0194\n",
        "0.0195\n",
        "0.0196\n",
        "0.0197\n",
        "0.0198\n",
        "0.0199\n",
        "0.02\n",
        "0.0201\n",
        "0.0202\n",
        "0.0203\n",
        "0.0204\n",
        "0.0205\n",
        "0.0206\n",
        "0.0207\n",
        "0.0208\n",
        "0.0209\n",
        "0.021\n",
        "0.0211\n",
        "0.0212\n",
        "0.0213\n",
        "0.0214\n",
        "0.0215\n",
        "0.0216\n",
        "0.0217\n",
        "0.0218\n",
        "0.0219\n",
        "0.022\n",
        "0.0221\n",
        "0.0222\n",
        "0.0223\n",
        "0.0224\n",
        "0.0225\n",
        "0.0226\n",
        "0.0227\n",
        "0.0228\n",
        "0.0229\n",
        "0.023\n",
        "0.0231\n",
        "0.0232\n",
        "0.0233\n",
        "0.0234\n",
        "0.0235\n",
        "0.0236\n",
        "0.0237\n",
        "0.0238\n",
        "0.0239\n",
        "0.024\n",
        "0.0241\n",
        "0.0242\n",
        "0.0243\n",
        "0.0244\n",
        "0.0245\n",
        "0.0246\n",
        "0.0247\n",
        "0.0248\n",
        "0.0249\n",
        "0.025\n",
        "0.0251\n",
        "0.0252\n",
        "0.0253\n",
        "0.0254\n",
        "0.0255\n",
        "0.0256\n",
        "0.0257\n",
        "0.0258\n",
        "0.0259\n",
        "0.026\n",
        "0.0261\n",
        "0.0262\n",
        "0.0263\n",
        "0.0264\n",
        "0.0265\n",
        "0.0266\n",
        "0.0268\n",
        "0.0269\n",
        "0.027\n",
        "0.0272\n",
        "0.0273\n",
        "0.0274\n",
        "0.0275\n",
        "0.0276\n",
        "0.0277\n",
        "0.0278\n",
        "0.0279\n",
        "0.0282\n",
        "0.0283\n",
        "0.0284\n",
        "0.0285\n",
        "0.0286\n",
        "0.0287\n",
        "0.0288\n",
        "0.0289\n",
        "0.029\n",
        "0.0291\n",
        "0.0292\n",
        "0.0293\n",
        "0.0295\n",
        "0.0299\n",
        "0.03\n",
        "0.0301\n",
        "0.0302\n",
        "0.0304\n",
        "0.0305\n",
        "0.0307\n",
        "0.0308\n",
        "0.0309\n",
        "0.031\n",
        "0.0311\n",
        "0.0312\n",
        "0.0313\n",
        "0.0314\n",
        "0.0315\n",
        "0.0316\n",
        "0.0317\n",
        "0.0318\n",
        "0.0319\n",
        "0.0322\n",
        "0.0324\n",
        "0.0325\n",
        "0.0326\n",
        "0.0327\n",
        "0.0329\n",
        "0.0331\n",
        "0.0333\n",
        "0.0335\n",
        "0.0336\n",
        "0.0337\n",
        "0.0338\n",
        "0.0339\n",
        "0.034\n",
        "0.0341\n",
        "0.0343\n",
        "0.0345\n",
        "0.0346\n",
        "0.0347\n",
        "0.0348\n",
        "0.0349\n",
        "0.0352\n",
        "0.0353\n",
        "0.0354\n",
        "0.0356\n",
        "0.0357\n",
        "0.0359\n",
        "0.0361\n",
        "0.0362\n",
        "0.0364\n",
        "0.0365\n",
        "0.0367\n",
        "0.0368\n",
        "0.0369\n",
        "0.037\n",
        "0.0372\n",
        "0.0373\n",
        "0.0375\n",
        "0.0377\n",
        "0.0378\n",
        "0.0379\n",
        "0.038\n",
        "0.0381\n",
        "0.0382\n",
        "0.0383\n",
        "0.0384\n",
        "0.0385\n",
        "0.0386\n",
        "0.0387\n",
        "0.0388\n",
        "0.0389\n",
        "0.0391\n",
        "0.0392\n",
        "0.0396\n",
        "0.0398\n",
        "0.0403\n",
        "0.0404\n",
        "0.0406\n",
        "0.0407\n",
        "0.0409\n",
        "0.0412\n",
        "0.0413\n",
        "0.0418\n",
        "0.042\n",
        "0.0422\n",
        "0.0423\n",
        "0.0427\n",
        "0.0428\n",
        "0.0429\n",
        "0.0431\n",
        "0.0434\n",
        "0.0436\n",
        "0.0437\n",
        "0.0439\n",
        "0.044\n",
        "0.0441\n",
        "0.0442\n",
        "0.0443\n",
        "0.0444\n",
        "0.0445\n",
        "0.0446\n",
        "0.0447\n",
        "0.0449\n",
        "0.0453\n",
        "0.0454\n",
        "0.0457\n",
        "0.0458\n",
        "0.0463\n",
        "0.0467\n",
        "0.0468\n",
        "0.0472\n",
        "0.0475\n",
        "0.0476\n",
        "0.0477\n",
        "0.0478\n",
        "0.0479\n",
        "0.0481\n",
        "0.0482\n",
        "0.0484\n",
        "0.0487\n",
        "0.0489\n",
        "0.0492\n",
        "0.0494\n",
        "0.0495\n",
        "0.0497\n",
        "0.0499\n",
        "0.05\n",
        "0.0503\n",
        "0.0515\n",
        "0.0516\n",
        "0.052\n",
        "0.0521\n",
        "0.0522\n",
        "0.0529\n",
        "0.0535\n",
        "0.0541\n",
        "0.0544\n",
        "0.0548\n",
        "0.056\n",
        "0.0565\n",
        "0.0566\n",
        "0.0567\n",
        "0.0568\n",
        "0.057\n",
        "0.0577\n",
        "0.0578\n",
        "0.058\n",
        "0.0581\n",
        "0.0589\n",
        "0.0591\n",
        "0.0595\n",
        "0.0609\n",
        "0.061\n",
        "0.0616\n",
        "0.0617\n",
        "0.0618\n",
        "0.0622\n",
        "0.0623\n",
        "0.0632\n",
        "0.0646\n",
        "0.0662\n",
        "0.0664\n",
        "0.0667\n",
        "0.067\n",
        "0.0671\n",
        "0.0685\n",
        "0.0693\n",
        "0.0701\n",
        "0.0717\n",
        "0.072\n",
        "0.0723\n",
        "0.0734\n",
        "0.0755\n",
        "0.0764\n",
        "0.0809\n",
        "0.0829\n",
        "0.0842\n",
        "0.0868\n",
        "0.0872\n",
        "0.0878\n",
        "0.0881\n",
        "0.0892\n",
        "0.0898\n",
        "0.0899\n",
        "0.0938\n",
        "0.0949\n",
        "0.0952\n",
        "0.0975\n",
        "0.1008\n",
        "0.1015\n",
        "0.1026\n",
        "0.1038\n",
        "0.1043\n",
        "0.1066\n",
        "0.108\n",
        "0.1081\n",
        "0.1105\n",
        "0.1113\n",
        "0.1126\n",
        "0.113\n",
        "0.1139\n",
        "0.1151\n",
        "0.1176\n",
        "0.1188\n",
        "0.1193\n",
        "0.1226\n",
        "0.1235\n",
        "0.1236\n",
        "0.124\n",
        "0.1244\n",
        "0.1248\n",
        "0.1256\n",
        "0.1259\n",
        "0.1273\n",
        "0.1293\n",
        "0.1322\n",
        "0.1341\n",
        "0.1357\n",
        "0.1389\n",
        "0.1406\n",
        "0.1415\n",
        "0.1429\n",
        "0.1432\n",
        "0.1464\n",
        "0.1573\n",
        "0.1633\n",
        "0.1672\n",
        "0.1742\n",
        "0.1804\n",
        "0.1861\n",
        "0.1892\n",
        "0.1942\n",
        "0.195\n",
        "0.1975\n",
        "0.2073\n",
        "0.208\n",
        "0.2095\n",
        "0.2152\n",
        "0.22\n",
        "0.2215\n",
        "0.2267\n",
        "0.2294\n",
        "0.235\n",
        "0.2354\n",
        "0.2395\n",
        "0.2433\n",
        "0.2448\n",
        "0.2467\n",
        "0.2477\n",
        "0.2545\n",
        "0.2557\n",
        "0.2569\n",
        "0.2614\n",
        "0.2664\n",
        "0.2742\n",
        "0.2759\n",
        "0.2871\n",
        "0.2874\n",
        "0.3163\n",
        "0.3224\n",
        "0.3387\n",
        "0.3855\n",
        "0.3918\n",
        "0.4444\n",
        "0.4491\n",
        "0.457\n",
        "0.473\n",
        "0.4756\n",
        "0.5523\n",
        "0.6062\n",
        "0.6569\n",
        "0.7513\n",
        "0.8011\n",
        "1.0\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Preprocessing Fuzzy Time Series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "partition_size = 0.001\n",
      "umin = math.floor(min(dat));\n",
      "umax = math.ceil(max(dat));\n",
      "# 2: Partition of universe\n",
      "# Method: Dividing in the half-thousands\n",
      "def get_midpoint(ptuple):\n",
      "    return 0.5*(ptuple[0]+ptuple[1])\n",
      "def get_midpoint_vector(tuple_vector):\n",
      "    return [get_midpoint(x) for x in tuple_vector];\n",
      "def get_fuzzy_class(point, partition_size):\n",
      "    return int(math.floor(point / partition_size))\n",
      "def get_fuzzy_dataset(data):\n",
      "    u_class = []\n",
      "    for item in data:\n",
      "        u_class.append(get_fuzzy_class(item,partition_size))\n",
      "    return u_class\n",
      "def mapping_class(u_class):\n",
      "    unique_class = np.unique(u_class)\n",
      "    index = np.arange(unique_class.shape[0])\n",
      "    inverted = {}\n",
      "    mapping = {}\n",
      "    for idx,val in enumerate(unique_class):\n",
      "        mapping[val] = idx\n",
      "        inverted[idx] = val\n",
      "    return mapping, inverted\n",
      "def defuzzy(index, inverted,midpoints):\n",
      "    f_class = inverted[index]\n",
      "    return midpoints[f_class]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sliding_number = 2\n",
      "# result = []\n",
      "\n",
      "nIter = int((umax-umin)/partition_size)\n",
      "u_vectorized = []\n",
      "\n",
      "for i in range(nIter) :\n",
      "    u_vectorized.append((umin + i*partition_size,umin + (i+1)*partition_size));\n",
      "\n",
      "u_midpoints = get_midpoint_vector(u_vectorized)\n",
      "u_class = np.array(get_fuzzy_dataset(dat),dtype=np.int32)\n",
      "\n",
      "u_unique_inverted, u_unique_mapping = mapping_class(u_class)\n",
      "u_class_transform = [u_unique_inverted[item] for item in u_class]\n",
      "\n",
      "X_train_size = int(len(u_class_transform)*0.7)\n",
      "sliding = np.array(list(SlidingWindow(u_class_transform, sliding_number)))\n",
      "sliding = np.array(sliding, dtype=np.int32)\n",
      "X_train = sliding[:X_train_size]\n",
      "y_train = u_class_transform[sliding_number:X_train_size+sliding_number]\n",
      "X_test = sliding[X_train_size:]\n",
      "y_test = u_class_transform[X_train_size+sliding_number-1:]\n",
      "y_actual_test = dat[X_train_size+sliding_number-1:].tolist()\n",
      "# # Define classifier\n",
      "n_hidden = len(u_unique_inverted) + sliding_number\n",
      "# "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# classifier = skflow.TensorFlowDNNClassifier(hidden_units=[n_hidden], n_classes=len(u_unique_inverted),steps=10000, \n",
      "#                                             learning_rate= 0.0001, optimizer='Adam', verbose=0)\n",
      "classifier = NeuralFlowRegressor(hidden_nodes=[n_hidden], n_classes=len(u_unique_inverted),optimize='Adam'\n",
      "                                 ,steps=10000,learning_rate=1E-02, activation='relu')\n",
      "a = classifier.fit(X_train, y_train)\n",
      "ypred = classifier.predict(X_test)\n",
      "ypred_defuzzy = [defuzzy(item,u_unique_mapping,u_midpoints) for item in ypred]\n",
      "score = mean_absolute_error(ypred_defuzzy,y_actual_test)\n",
      "# result.append((sliding_number,score))\n",
      "print score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialization\n",
        "Step #100, epoch #4, avg. train loss: 1.26270"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #200, epoch #9, avg. train loss: 0.03306"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #300, epoch #14, avg. train loss: 0.01663"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #400, epoch #19, avg. train loss: 0.00589"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #500, epoch #23, avg. train loss: 0.00592"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #600, epoch #28, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #700, epoch #33, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #800, epoch #38, avg. train loss: 0.00593"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #900, epoch #42, avg. train loss: 0.00593"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1000, epoch #47, avg. train loss: 0.00589"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1100, epoch #52, avg. train loss: 0.00601"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1200, epoch #57, avg. train loss: 0.00740"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1300, epoch #61, avg. train loss: 0.00641"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1400, epoch #66, avg. train loss: 0.00588"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1500, epoch #71, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1600, epoch #76, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1700, epoch #80, avg. train loss: 0.00593"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1800, epoch #85, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1900, epoch #90, avg. train loss: 0.00588"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2000, epoch #95, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2100, epoch #100, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2200, epoch #104, avg. train loss: 0.00593"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2300, epoch #109, avg. train loss: 0.00623"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2400, epoch #114, avg. train loss: 0.00646"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2500, epoch #119, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2600, epoch #123, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2700, epoch #128, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2800, epoch #133, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2900, epoch #138, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3000, epoch #142, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3100, epoch #147, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3200, epoch #152, avg. train loss: 0.00600"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3300, epoch #157, avg. train loss: 0.00597"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3400, epoch #161, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3500, epoch #166, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3600, epoch #171, avg. train loss: 0.00588"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3700, epoch #176, avg. train loss: 0.00588"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3800, epoch #180, avg. train loss: 0.00622"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3900, epoch #185, avg. train loss: 0.00608"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4000, epoch #190, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4100, epoch #195, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4200, epoch #200, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4300, epoch #204, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4400, epoch #209, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4500, epoch #214, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4600, epoch #219, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4700, epoch #223, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4800, epoch #228, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4900, epoch #233, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5000, epoch #238, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5100, epoch #242, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5200, epoch #247, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5300, epoch #252, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5400, epoch #257, avg. train loss: 0.00589"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5500, epoch #261, avg. train loss: 0.00588"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5600, epoch #266, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5700, epoch #271, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5800, epoch #276, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5900, epoch #280, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6000, epoch #285, avg. train loss: 0.00587"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6100, epoch #290, avg. train loss: 0.00591"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6200, epoch #295, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6300, epoch #300, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6400, epoch #304, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6500, epoch #309, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6600, epoch #314, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6700, epoch #319, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6800, epoch #323, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6900, epoch #328, avg. train loss: 0.00585"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #7000, epoch #333, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #7100, epoch #338, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #7200, epoch #342, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #7300, epoch #347, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #7400, epoch #352, avg. train loss: 0.00586"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #7500, epoch #357, avg. train loss: 0.00585"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #7600, epoch #361, avg. train loss: 0.00585"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #7700, epoch #366, avg. train loss: 0.00585"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #7800, epoch #371, avg. train loss: 0.00585"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #7900, epoch #376, avg. train loss: 0.00585"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #8000, epoch #380, avg. train loss: 0.00584"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #8100, epoch #385, avg. train loss: 0.00584"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #8200, epoch #390, avg. train loss: 0.00584"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #8300, epoch #395, avg. train loss: 0.00584"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #8400, epoch #400, avg. train loss: 0.00584"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #8500, epoch #404, avg. train loss: 0.00584"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #8600, epoch #409, avg. train loss: 0.00583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #8700, epoch #414, avg. train loss: 0.00583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #8800, epoch #419, avg. train loss: 0.00583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #8900, epoch #423, avg. train loss: 0.00584"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #9000, epoch #428, avg. train loss: 0.00583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #9100, epoch #433, avg. train loss: 0.00583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #9200, epoch #438, avg. train loss: 0.00583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #9300, epoch #442, avg. train loss: 0.00583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #9400, epoch #447, avg. train loss: 0.00583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #9500, epoch #452, avg. train loss: 0.00583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #9600, epoch #457, avg. train loss: 0.00584"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #9700, epoch #461, avg. train loss: 0.00583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #9800, epoch #466, avg. train loss: 0.00584"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #9900, epoch #471, avg. train loss: 0.00583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #10000, epoch #476, avg. train loss: 0.00583"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.0212493882091\n"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib\n",
      "plot_figure(y_pred=ypred_defuzzy,y_true=y_actual_test, title='High Order Time Series with order %s, hidden nodes = %s: %s'%(sliding_number,n_hidden,score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: Qt4Agg\n"
       ]
      }
     ],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savez('fuzzy_neuro_%s_%s'%(sliding_number,score),y_pred=ypred_defuzzy,y_true=y_actual_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "BPNN Experiment with data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train_size = int(len(dat)*0.7)\n",
      "sliding = np.array(list(SlidingWindow(dat, sliding_number)))\n",
      "sliding = np.array(sliding)\n",
      "X_train = sliding[:X_train_size]\n",
      "y_train = dat[sliding_number:X_train_size+sliding_number]\n",
      "X_test = sliding[X_train_size:]\n",
      "y_test = dat[X_train_size+sliding_number-1:]\n",
      "y_actual_test = dat[X_train_size+sliding_number-1:].tolist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 460
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimator = NeuralFlowRegressor(learning_rate=0.01, hidden_nodes=[30], steps=4000,optimize='SGD')\n",
      "try:\n",
      "    estimator.fit(X_train,y_train)\n",
      "except:\n",
      "    print \"log\"\n",
      "y_pred = estimator.predict(X_test)\n",
      "score_nn = mean_absolute_error(y_pred,y_actual_test)\n",
      "print score_nn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialization\n",
        "Step #100, epoch #4, avg. train loss: 0.38317"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #200, epoch #9, avg. train loss: 0.00126"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #300, epoch #14, avg. train loss: 0.00069"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #400, epoch #19, avg. train loss: 0.00074"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #500, epoch #23, avg. train loss: 0.00074"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #600, epoch #28, avg. train loss: 0.00071"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #700, epoch #33, avg. train loss: 0.00074"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #800, epoch #38, avg. train loss: 0.00070"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #900, epoch #42, avg. train loss: 0.00072"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1000, epoch #47, avg. train loss: 0.00073"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1100, epoch #52, avg. train loss: 0.00071"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1200, epoch #57, avg. train loss: 0.00073"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1300, epoch #61, avg. train loss: 0.00072"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1400, epoch #66, avg. train loss: 0.00074"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1500, epoch #71, avg. train loss: 0.00072"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1600, epoch #76, avg. train loss: 0.00072"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1700, epoch #80, avg. train loss: 0.00072"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1800, epoch #85, avg. train loss: 0.00071"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1900, epoch #90, avg. train loss: 0.00072"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2000, epoch #95, avg. train loss: 0.00073"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2100, epoch #100, avg. train loss: 0.00071"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2200, epoch #104, avg. train loss: 0.00071"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2300, epoch #109, avg. train loss: 0.00074"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2400, epoch #114, avg. train loss: 0.00072"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2500, epoch #119, avg. train loss: 0.00069"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2600, epoch #123, avg. train loss: 0.00071"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2700, epoch #128, avg. train loss: 0.00077"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2800, epoch #133, avg. train loss: 0.00067"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2900, epoch #138, avg. train loss: 0.00072"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3000, epoch #142, avg. train loss: 0.00073"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3100, epoch #147, avg. train loss: 0.00068"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3200, epoch #152, avg. train loss: 0.00074"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3300, epoch #157, avg. train loss: 0.00070"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3400, epoch #161, avg. train loss: 0.00072"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3500, epoch #166, avg. train loss: 0.00071"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3600, epoch #171, avg. train loss: 0.00071"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3700, epoch #176, avg. train loss: 0.00071"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3800, epoch #180, avg. train loss: 0.00073"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3900, epoch #185, avg. train loss: 0.00069"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4000, epoch #190, avg. train loss: 0.00073"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.018723805457\n"
       ]
      }
     ],
     "prompt_number": 465
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib\n",
      "plot_figure(y_pred=y_pred,y_true=y_actual_test, title='BPNN with sliding window = %s: %s'%(sliding_number,score_nn))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: Qt4Agg\n"
       ]
      }
     ],
     "prompt_number": 466
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}