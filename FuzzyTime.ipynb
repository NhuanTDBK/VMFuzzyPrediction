{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.preprocessing import MinMaxScaler\n",
      "import math\n",
      "from estimators.NeuralFlow import *\n",
      "from utils.SlidingWindowUtil import SlidingWindow\n",
      "\n",
      "from sklearn import datasets, metrics\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "from utils.GraphUtil import *\n",
      "from estimators.GAEstimator import GAEstimator\n",
      "from estimators.OptimizerNNEstimator import OptimizerNNEstimator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
        "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Import Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaler = MinMaxScaler()\n",
      "dat = pd.read_csv('sampling_617685_metric_10min_datetime.csv',parse_dates=True,index_col=0)[:3000]\n",
      "dat = pd.Series(dat['cpu_rate'].round(3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distance = round(dat.max() / (dat.max() / 0.25 + 1),4)\n",
      "print distance"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.2489\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Preprocessing Fuzzy Time Series"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "partition_size = distance\n",
      "umin = math.floor(min(dat));\n",
      "umax = math.ceil(max(dat));\n",
      "# 2: Partition of universe\n",
      "# Method: Dividing in the half-thousands\n",
      "def get_midpoint(ptuple):\n",
      "    return 0.5*(ptuple[0]+ptuple[1])\n",
      "def get_midpoint_vector(tuple_vector):\n",
      "    return [get_midpoint(x) for x in tuple_vector];\n",
      "def get_fuzzy_class(point, partition_size):\n",
      "    return int(math.floor(point / partition_size))\n",
      "def get_fuzzy_dataset(data):\n",
      "    u_class = []\n",
      "    for item in data:\n",
      "        u_class.append(get_fuzzy_class(item,partition_size))\n",
      "    return u_class\n",
      "def mapping_class(u_class):\n",
      "    unique_class = np.unique(u_class)\n",
      "    index = np.arange(unique_class.shape[0])\n",
      "    inverted = {}\n",
      "    mapping = {}\n",
      "    for idx,val in enumerate(unique_class):\n",
      "        mapping[val] = idx\n",
      "        inverted[idx] = val\n",
      "    return mapping, inverted\n",
      "def defuzzy(index, inverted,midpoints):\n",
      "    f_class = inverted[index]\n",
      "    return midpoints[f_class]\n",
      "\n",
      "nIter = int((umax-umin)/partition_size)\n",
      "u_vectorized = []\n",
      "\n",
      "for i in range(nIter) :\n",
      "    u_vectorized.append((umin + i*partition_size,umin + (i+1)*partition_size));\n",
      "\n",
      "u_midpoints = get_midpoint_vector(u_vectorized)\n",
      "u_class = np.array(get_fuzzy_dataset(dat),dtype=np.int32)\n",
      "\n",
      "u_unique_inverted, u_unique_mapping = mapping_class(u_class)\n",
      "u_class_transform = [u_unique_inverted[item] for item in u_class]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sliding_number = 3\n",
      "# result = []\n",
      "X_train_size = int(len(u_class_transform)*0.7)\n",
      "sliding = np.array(list(SlidingWindow(u_class_transform, sliding_number)))\n",
      "sliding = np.array(sliding, dtype=np.int32)\n",
      "X_train = sliding[:X_train_size]\n",
      "y_train = u_class_transform[sliding_number:X_train_size+sliding_number]\n",
      "X_test = sliding[X_train_size:]\n",
      "y_test = u_class_transform[X_train_size+sliding_number-1:]\n",
      "y_actual_test = dat[X_train_size+sliding_number-1:].tolist()\n",
      "# # Define classifier\n",
      "n_hidden = len(X_train[0]) + sliding_number\n",
      "# "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# np.savez(\"fuzzy_train_direct\",X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# classifier = skflow.TensorFlowDNNClassifier(hidden_units=[n_hidden], n_classes=len(u_unique_inverted),steps=10000, \n",
      "#                                             learning_rate= 0.0001, optimizer='Adam', verbose=0)\n",
      "fit_params = {\n",
      "    'neural_shape':[len(X_train[0]),n_hidden,1]\n",
      "    }\n",
      "# ga_estimator = GAEstimator(cross_rate=0.5, mutation_rate=0.02, gen_size=50)\n",
      "# nn = NeuralFlowRegressor(hidden_nodes=[n_hidden],optimize='Adam'\n",
      "#                                  ,steps=7000,learning_rate=1E-03)\n",
      "# classifier = OptimizerNNEstimator(ga_estimator, nn)\n",
      "classifier = NeuralFlowRegressor(hidden_nodes=[15],optimize='Adam'\n",
      "                                 ,steps=7000,learning_rate=1E-03)\n",
      "a = classifier.fit(X_train, y_train, **fit_params)\n",
      "ypred = np.round(classifier.predict(X_test)).flatten()\n",
      "ypred_defuzzy = [defuzzy(item,u_unique_mapping,u_midpoints) for item in ypred]\n",
      "score = mean_absolute_error(ypred_defuzzy,y_actual_test)\n",
      "# result.append((sliding_number,score))\n",
      "print score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialization\n",
        "Step #100, epoch #4, avg. train loss: 40.87850"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #200, epoch #9, avg. train loss: 32.44432"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #300, epoch #14, avg. train loss: 25.05948"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #400, epoch #19, avg. train loss: 25.60771"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #500, epoch #23, avg. train loss: 24.85613"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #600, epoch #28, avg. train loss: 23.87231"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #700, epoch #33, avg. train loss: 24.38296"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #800, epoch #38, avg. train loss: 23.31014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #900, epoch #42, avg. train loss: 23.82384"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1000, epoch #47, avg. train loss: 23.75258"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1100, epoch #52, avg. train loss: 23.26185"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1200, epoch #57, avg. train loss: 23.53465"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1300, epoch #61, avg. train loss: 23.56798"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1400, epoch #66, avg. train loss: 23.35225"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1500, epoch #71, avg. train loss: 23.00694"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1600, epoch #76, avg. train loss: 23.24998"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1700, epoch #80, avg. train loss: 23.22961"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1800, epoch #85, avg. train loss: 22.77094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #1900, epoch #90, avg. train loss: 22.75731"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2000, epoch #95, avg. train loss: 23.29794"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2100, epoch #100, avg. train loss: 22.95372"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2200, epoch #104, avg. train loss: 22.56142"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2300, epoch #109, avg. train loss: 23.14172"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2400, epoch #114, avg. train loss: 23.40993"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2500, epoch #119, avg. train loss: 21.73920"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2600, epoch #123, avg. train loss: 22.42584"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2700, epoch #128, avg. train loss: 23.62050"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2800, epoch #133, avg. train loss: 21.81153"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #2900, epoch #138, avg. train loss: 22.43753"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3000, epoch #142, avg. train loss: 22.98982"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3100, epoch #147, avg. train loss: 21.83402"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3200, epoch #152, avg. train loss: 23.57281"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3300, epoch #157, avg. train loss: 22.09678"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3400, epoch #161, avg. train loss: 22.43047"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3500, epoch #166, avg. train loss: 22.32271"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3600, epoch #171, avg. train loss: 22.73786"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3700, epoch #176, avg. train loss: 22.26719"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3800, epoch #180, avg. train loss: 22.91298"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #3900, epoch #185, avg. train loss: 21.99343"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4000, epoch #190, avg. train loss: 22.93519"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4100, epoch #195, avg. train loss: 22.28525"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4200, epoch #200, avg. train loss: 22.38013"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4300, epoch #204, avg. train loss: 22.78572"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4400, epoch #209, avg. train loss: 21.76906"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4500, epoch #214, avg. train loss: 23.01782"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4600, epoch #219, avg. train loss: 21.83862"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4700, epoch #223, avg. train loss: 22.70331"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4800, epoch #228, avg. train loss: 22.05461"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #4900, epoch #233, avg. train loss: 22.28445"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5000, epoch #238, avg. train loss: 22.23366"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5100, epoch #242, avg. train loss: 21.78299"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5200, epoch #247, avg. train loss: 22.99884"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5300, epoch #252, avg. train loss: 21.71931"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5400, epoch #257, avg. train loss: 22.90325"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5500, epoch #261, avg. train loss: 22.29075"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5600, epoch #266, avg. train loss: 22.08167"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5700, epoch #271, avg. train loss: 22.97396"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5800, epoch #276, avg. train loss: 21.74319"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #5900, epoch #280, avg. train loss: 21.80512"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6000, epoch #285, avg. train loss: 22.55690"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6100, epoch #290, avg. train loss: 22.30904"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6200, epoch #295, avg. train loss: 21.43611"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6300, epoch #300, avg. train loss: 22.46538"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6400, epoch #304, avg. train loss: 22.62810"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6500, epoch #309, avg. train loss: 21.56954"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6600, epoch #314, avg. train loss: 21.80411"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6700, epoch #319, avg. train loss: 22.42869"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6800, epoch #323, avg. train loss: 21.88252"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #6900, epoch #328, avg. train loss: 23.08541"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step #7000, epoch #333, avg. train loss: 21.82328"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.74036714922\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib\n",
      "plot_figure(y_pred=ypred_defuzzy[:200],y_true=y_actual_test[:200], title='High Order Time Series with order %s, hidden nodes = %s: %s'%(sliding_number,n_hidden,score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: Qt4Agg\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savez('fuzzy_neuro_%s_%s'%(sliding_number,score),y_pred=ypred_defuzzy,y_true=y_actual_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "BPNN Experiment with data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dat_nn = np.asarray(scaler.fit_transform(dat))\n",
      "X_train_size = int(len(dat_nn)*0.7)\n",
      "sliding = np.array(list(SlidingWindow(dat_nn, sliding_number)))\n",
      "X_train_nn = sliding[:X_train_size]\n",
      "y_train_nn = dat_nn[sliding_number:X_train_size+sliding_number].reshape(-1,1)\n",
      "X_test_nn = sliding[X_train_size:]\n",
      "y_test_nn = dat_nn[X_train_size+sliding_number-1:].reshape(-1,1)\n",
      "y_actual_test = dat[X_train_size+sliding_number-1:].tolist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
        "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savez(\"bpnn_direct\",X_train=X_train_nn,y_train=y_train_nn, X_test=X_test_nn, y_test = y_test_nn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimator = NeuralFlowRegressor(learning_rate=0.001, hidden_nodes=[15], steps=5000,optimize='Adam')\n",
      "estimator.fit(X_train_nn,y_train_nn)\n",
      "y_pred = scaler.inverse_transform(estimator.predict(X_test_nn))\n",
      "score_nn = mean_absolute_error(y_pred,y_actual_test)\n",
      "print score_nn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib\n",
      "plot_figure(y_pred=y_pred,y_true=y_actual_test, title='BPNN with sliding window = %s: %s'%(sliding_number,score_nn))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using matplotlib backend: Qt4Agg\n"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.savez('neuro_%s_%s'%(sliding_number,score_nn),y_pred=y_pred,y_true=y_actual_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    }
   ],
   "metadata": {}
  }
 ]
}