node {
  name: "global_step/initial_value"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_step"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "global_step/Assign"
  op: "Assign"
  input: "global_step"
  input: "global_step/initial_value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "global_step/read"
  op: "Identity"
  input: "global_step"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "input"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
}
node {
  name: "output"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
}
node {
  name: "HistogramSummary/tag"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "X"
      }
    }
  }
}
node {
  name: "HistogramSummary"
  op: "HistogramSummary"
  input: "HistogramSummary/tag"
  input: "input"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "HistogramSummary_1/tag"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "y"
      }
    }
  }
}
node {
  name: "HistogramSummary_1"
  op: "HistogramSummary"
  input: "HistogramSummary_1/tag"
  input: "output"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "fully_connected/weights/Initializer/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 8
          }
          dim {
            size: 330
          }
        }
        tensor_content: "o\355\002\276.\311\002=\223\221\323\273h]A=\357d\"<\244\220\223\272\304hV=>\327\201\275\346\236\233\275\270\334\260\275\206\320\204=p\022\362\273\323\022G=k\213\002>+$\212=s\004\271\274_z\032\275\026\316\014\275\354\222\257=\2538\007\276\246\264\210\275:Y\375\275\340\2044=\223>\200\275\020\325\354\275\347\211n\275\325\200\330\2750\003\240\274\271\313\250=*\313\001\276\263}^\275\256\267\255=\316b\242<\303\202\234=\274\001\256\275j\177l=\013\002\266\275gi\376<\341\014/\275gg\222<\345\234\336\275R\221\001\276\253:\272\275\036)\030\273\254\244\253=\333\346\347\27597\360<\276\n\262<D\337\306\275\024\234\232=\213~\361\275\376\004,\275\024\317\272\272\231\006^\274sc\370=\345\3762\275\307\334\217=uRO\2755\013\257=\004\267\256=~M\030\275\r\202\372\27547+=\006o|\272CvR=\2722\371=$1\370\275}\337\377\274\255B*=\200\354\377\275\025\021~\275\210\305\367\275f\354\245=\312\n%\273\006}\326\275\322\335\250=\351\253\217=\325S\200=\203\311\356\274\202\r\353<\265J\006\276%)\005\275L1\350=\031\377O\275\016*\304\275H\376Q\275!*\004>\366\316\247\274\363\306@\275(\226\367\275\273\306\272=\2250\222=\317\000\226<\014\336\000\275Qy\002\276`\177\026\275]~\304=d\270\333\275\342LH\275@P\235\275\014%\243\274\204\303\370:2\374F\274\364I\205\275\003\254\005>\022\327\354\275\215\215\302=\344\300\007>\002L\367\274\037\226\247=\331\300\331\275\267\252\271\275\326\206P=<J\254\275\335\266\256\273\264.\001\276\t\035\343\275\231\316\357=S\023\314\275(\246\356<\232\245\024=\252\036\375=b\316\020=)\030\342\275\322\203\007>\225\270\001=U\356\365<\273n^<-z\031\274\375\020\255\274]B\236\275\325\242\265;\300\371\267\275\304{\270\275\316\210D\275/\336\240\275\215\362v\275\203\306\375=\210\225\326<pa\311</9\006>\323\204\303\274V\320\004>nr\275=\241\210\213=]\252\353=\215K\330=\376\277\341=2\242A=\t\3537\2753\303\331=\242\n\376\273\365\362\300\275\230\326-=\300\263\357\275\360\263\013=\225\314\342= \244\240\274\260\325\377<\372\215\327<u\222\341=x\246P\275T8\324\275=\242\251=<\014\342\275\026\275\250\274QR\000>\006\240\333:\361\t\332=H\256\274=\033\216\027\275-XN;%:\256\275\265!M\275%\204i\275\nC\356=h\001\000>X\307\370=\341\267\262\275\025\261\303=\216\247V\275\225\201\017\275\010\212\020<\264\245M=\017\344\000\2736O\"=s\352\003=4g\316\274\340`\\\275\310\001\367\274\310\263\023=8\r\005\275\023\311\020\275\304C\363\274it\275\271\003=\277\2755\371K=\210Q\242=\210\253 \275T\225\210=\270\017\347\275%\274\246=\3326\027<\231\231\261=\\\310\373\275bE\271=\030\033\221\271\023\3527=\030j\304\275Vj\322\275\217w\352=\331^\323=\304\372\334\274\033\024\301=^\311\037={\177\300:\243Nt<s\252\205\275\373\356x=\217\365N=\014\336\000\276A\337R\275/\034\356\275\244\354\247\275Ey\256\275#hc=\017\265\020=b>\264\275\266T\266<\023\342\010\275A\206\254=d\t5\275\230\020\251=\260E\224\275\375\375\256=\367\374\026=\3370\314\275VM\342=\327\033\031=]/\220=^\010\270\275\377\307\253=>\326\206\274\252\377Y<C\317\240\273\320\025\316\275@\3728\275.\274\221<\354E\376=\350(\000>\240\347\275\275\234\301\20496\026\237<x\345\314\275\256(M=E|\230=\237\265\340\275\355@\241\275\300.\202\275\306w\242=4M\317\274\357\336\214=/\022\203\273\201\214c=\226:\r=\315\300\335\275l\302\247=\374\303\000\275\363\324\323\275t\253\367\275\270\025\266\275\030\"\272\275uO\361\274\014<\274<\254O\374\275\004\207\276=\037\254\202\275\334\352\322\275f\036\353<[_\312=(c\202\275S\355\010\275n\363\351\275\331@Y\275\253~\325=L\336\234=\331\267>\275\375%\204\275ux\312\275\202\242\243=\206\010\367\275\361\301\355\274oY\330\275\263e\317<-\215\240=\364\014\275<{\0045=\260V\256\275U\224\233=\032\333\376=b\203\204=S\332\"=\214W\335=\343X\304=\375\001L\274\005\366\353\274\365=\001>\207\377H=\024\001\267=*R.=\311?\270=\305n%=\370\001\231=\222\377\316=\232F\214\275\257\3728\275\021\257Z\275\3665\232=>\000(\274\303\303\313\275\313\r \275\303I\320\275\270\215\234=\242\362\302\275\366\017\237\275\177\244+\275\312\000~\275\327\005\336\275\355X\272\275\024\032\364\275i\276\335\275\205\000\245=\346\307\301\275\304u|\274\331cv\275\233\374S\275\273C\245=\237\265\002>C\330\344\275\372A\264\272\316\264R=1\233k\275p\225\270=\010O\242\2752\226\375\275\177\246\341=\274\326\330\275k\303\330=\212\216\021\275h\221\357\275\377\277\376\274.-\316=b\307\301\275.\225\202\275d\321 =#z\306\275\006}\242\275\014\235\204=5\343E\275\266l\002\271M\264$\275NB\247\275\203\256\371\275G\256\334\274\276i\003\276\272\366\203=\340fz\275\303\371\361=\263\n\002\276W\013\300\275\"\321\021=-O\235=\275\242\273<\233\322\223=+\216\204\275\321\224F\275\353\255\351=\231\353\244=^\233\340<\374\335\000=\370\255}=\274\365X<\376Om=~S\305\275\264m\356=\2320\214\275\201VR\275\202\304\211=Q\006\247\275f)|<\236\336\275\275k9\232=\021r\355\275(\226\310\275\333\237\n\275>\212\003\276\243n\021\275\240!?=s\026\234\275\252\321\350=(\t\215\274\330\305\001\276\3105\303=1X\247\275chW\274\236D\237:)H\261\275{E\177=\235\333J=\347\365\257\275G\013\320=7A\375\2730;\251=\361\317\266=\326\325\366\274@\032\277=\275\211\311\275\373k\240\275(B\004>Bb\217\274\300\344\343\274h36\273ox\3159\372h\006>oD\220=e\000\004\276\305}\223\274\004\036\322<H\343O\275\342\330\305=\3578\277\275]\217\330=\017`\006\275`q.=\321M\205\275Y\226\251\275\376$7=\373\245c=-]\245=hY\307\275SU\000>\266;\325\274\325\032\000\276\312^\205\275D\253\226\275v\347@\274\263[\276\275@\024\325<\014v\367<\343w\267\275{\313\261=[~\265\275\345X\220\274\\\211\003\276\337\261\006\276\344B\346=hQ\207\274v2\341=,\t\373\275\023\234h\275\' \231:b\260\242=\233\247\357\275\262\202\260\274n\367u\275Uo\320=a\002\341\275?-L=rm\212\274%R\232\275\244\367\267=\204\332A\272\3615\243\2752b\372;\316\006:\275\227J\357=\266Vy=1v5=57\321\275\242X\243<b\013\257\274]\315\003>\313\275]=\272\331^\275.\025\003>\314f\005\276\306\027\237\275V\336\002>\275>-\274k\200\000>\233\000\362=\246q\321<m\375\345=\2357\244\275DJ\021=\3548\313=\036>\247\274VBX=\242\304\215=n2\200<\252\326\341\275\264\361\304\275\365P\001\276\353:\271=v\037\345=\335\337\253=i\273\375\275s\276P=\251\353\224=\006\363\311=\360\370\304=\372\307\243=\026+\317\275\224y\332=\201\306\363\275\264\004\237\274\215>\037\275\253\031\221\275\357\221C=wI@\273\005\340\216\275? \331\275/\204\335=\253!V=\262\350\263<\016\224\363=\\\333\276=\227F\332\275\"\0075=\n\275\251\2756j\257=9.\370=92\000\276@F\333=\244\234\225\274\251\253\266=\000\213\223\274\341/\207\275\266\342\231;\237\027\037=f\212x\273\312A7<[Y\362=\r\226-=.,\202\274,\301\305\274#\354\006>D\302\254=\311\363\351={ C\274\006\273\215\274\020m\023=\311\275\357\275\366\306\247\275n\303\323\275+\314\270\275\240\216\373=s\374&=\240\007;\275>\363\034<\0324\210\275\242\364}\275W\214\224=\355g\236\275\351\301\316\275W<\006\276\004\273\263\275\220\360\214\274%`X=\025\376?\275\214\316\270=\364\023\016\275\320\226,9\035\321\010=\235\261\263\275~3F<n\321\"=\347k>\275\225\245c\275\255\247\327=\200\207\357\275\353M\213\275<\344\354\274[P\334=\333`\226=\361\277\303\272\020X\313=\356Xl=zy\356\275WTI\275\331\346\246\274\276\376\226\275(!\225=\347\345\356\275\374I\003=\2534\226=\273l\204\273\204\330\311\275\312\211\352\274(\372\211=\000)~=\227\254\204=oB\003>\252o\372<\031\010\224\275A\001%\275\224\217\215=\370[\313\275f\250\277=w\000\230\275|;\255=:\253)\274\267!\034\275\252\254E<PR\207\275\263l\213\274\216\354\274=9C\243\275\2146\201=\n\222u\275tot=\001\230\264\275s\356\005\276\003\277k;|\250\231\274\002\204\320=\355\225\001\275\276\316^=d\352\334=(\250\325\2755F\200\274\230\321\020\274^NL;q\032\005\276\t\205\345\274\236b)\274N\n1<\245\274\257\275\025\036\203=j\276\004\275\205\302\213<\2322\276\275\177O\253=\305tg\274\226j\355\273\224O<\275A\346W<\354M\305\274\373\001\321=&,S=\036\033g=8\335g=9\360\000>\373\256\263\275F\020\361\274\212\324\013\275c\266\376\275c\021\245=i\177\271\275OF\376\275\361\200\363\275u\251X\275\200\341(\273\007\370r\275\205\266\007>F\341\315=\037\026\005\276\270\014d\275DJW\275\002&\365=\340\372\213=\245=,\275\365\177\331<P\323i=2H\224=~\030\212\275HW\007>\364\372\002\276\223[\216=\351l\312\275\305q\233\275&+\353\275#\276\317\275u\200\006>\331\215\003\276\006\006\263\275\371\343\225=m%\336=\330\\\362\275\320\3722=\250C\035<Ac\303\275\200\204\'=\324\324\311\275\311.\376<\363\374\320\274\030\364\236\273 b\263\275\361\035\214\275L\377\233=;T\274\275+\371\364=\361\376}\275j\310\022=ml\334<A$L=5i\324\275\351\370\252=\375\305P=\200\004\025=\314\'\321=\205\303I\275\235\206\231\275)\014\337\274&\226\346\275\221\343\033\274F\220\017\275g>\321:\225\366\372=\023\304\231=j~\331< F\t=\027\307\355\275cg\263\275\001\225*=\207\335\263\275\211\253\376=r\037\001\276\236i\007>\240\257\200\275p/\266=3\030\303\275\232I\006=%x\335=.\271\360=\233\217\335<\314y\362\275\310\241\227\275^\355\245=\225\205\000>\r\374\001>M\257k\275\234\275\264\275f\270\232=\314r\224\2756+\272\275\230!\314\275@,\270\274\330\302V\275N;\326;\3739\337\274\375\242\304=\020\265[<\r\306\013=\027k\346=\302\333\264\275QRm\2732\007\314\275\035D\210=\322\"b<\321\026\377=\327\177]< \025\361\275e\374S=\321\230\243=8\263r\275`\234\002>\271\004\004>\332d\300<\333X\323\273\376M\342\275\312\320\344\275\364<\'\275\345G\303;\235\230I=C\220\360=ye\205<\204\244\334\273\316\274\334=\340\227\022\275\026M=\275,\017\263<\233A\272=\226\304!\275\214\301R=\261\301\376=9m\336<\3116\245=\357#\266=\326\321\016=7\365\225=\247\322\000\275\207L#\275\325\r\247\275M\216j=\270\377\005\274k\337\361=\021\013\324=\204\226\344\275\206G\270\275\260%\370\275M.P=\343[\332\275\266\364\307\273\013l\223\273\352\360r=\257\007\342=D\240\007>\331\363\253\275\005\356\326\275R\321\313=\325m2\275\007\027\243\275\214\t\377\275\304\376\005\275\226\001\261\275\t\244\024\275m\261\257=R\021\003\276{\n\367=\031A\201\272y\203m\275|\345\354\275\3716y\275F\342\342=\301\270^:\326\"\236\275j\315\325\275XI\353<\231\225\004\275)\342\t\275\022\361s\275m\205\245\275E\t\352\273\242\007\234=\'\341\357=;91=o\272\235\274\260Z9=H\233F\274x\0307\275\350Y\342=\250W\376=q\212\340\275Wk\341=@\321o\275\373\'\203\275\327\230\270=\372\032 \275\331\n\373=\360:\224\275m\306\320\275Os\367\275\000\253\331\275\252\325g=Y\334\316\275\242\236\031=\367\014e\275\017\330\004=;\\9\275\221\220\250\275\324g\006>\256@\370\275i\245\226\275-}\221\275\014:\271=\274#\377<L+t=.\253_<}\253\375\275l\262\253=\005\304\264\275,u\270=]\304\330\275\351*\217=\22305<}\331\033=\315h\341\275\220M7\275\323\204\221\275\252Z\201\274\033q\221\275Kh\177\274\254-e\275\300\336\275\273o\347<\275\013\365\211=\372}\001>.\317\333<\337\016W=\2516\352\273/Y\262\275L\\\202\275\242A\020=KW\315<\'\311\260\275f\001\272\274\304\031\235=Z\021O=M%N=\245\367\344\275I\001\313\275\277\325\023=j\212\004\276\301\321\003<\205\371\370=\023<\306\275l\213\261=\353\223\243\275\362U<\275\025[\232;z\266\347=\231a\243\275\010\270\240<>\202\355\275\r\270\350\275q\231G\275\300\263m\275\031u7\275\323%\271=\372\206\004>\222\034\001>\204j\334\275/Ci\275\252\025\3669\265\367\367<\000!?\272\331\233\320=6\324\373<=A\006<\313\347\202\275\321\247\351=F\000s=\314\362X\274\305\211\036\275\n\337\276=2z\252\275\r\362\002\276l\233R\275u\226+<\237\230\201\275\356\021\n\275\377^\373\275.b\275\275\003\230b\275\206\304H\274g\275l\275$\0033=\276\271\252\275\226\221^= \275\356=0,\214=\264\005\t\274\035\331t=V\245\221\272\ta\205=nS\002\276&z\324\274\337\036\343=\243V\242\273t\023\342\275\315\312\326=\037J\317\275%\303\376=1\200\225<\231\207\370;\321x\344=\025\262\006>3^\325\275\261\245\367\273\025h\232\275l\222\307=\000\235\365=E\\\244=7E\321\275\323\322#\274\200\004\262=\236\225\304=\203\327\265<\207\n[=\274?\251\275.h\346\275\377^\274\275m\032A\275\210\264\255\275H%\231\275\367\327\366\275\026d\240\275\334\031\'\275\364Qa\275\324\355M=\355$=\274\201\365\205\275\347\333r=mq\007>\245\376\234\273\214\200(\274+\026t=\233\014\376\2754\000\231\275\221\261\307\275Y\265\247\275\300\3247\274F\347W=xZ\002>\307\"I<\235\234\247\275\255G\277=\"\221v=P\327\331=\0228<\2759b\004\275\007\031\235\275oLX=\237\025\037\275\240\350\263<\271\010\262\275\204/\210\275\177\375\206=lW\345=\237v\314=\221.\350\275\373\341]\275\004jr=\242$\262=o\226V<)6\206=\020n\363=\205D\360=\022i\203=p=l\275d\344\'=\025\373\321<Z\317\210=\272e\300=\216\207\316<\177`\220\275`\261\310=\250{\027\275\031\263\364=Ot\021\274\356x\254\275\337\217\026=\303u}\2751E5\275\365?\313=\334i\231\275C\024\013\275\200\236\302\275y\024\345=\rCq\275\314S\356\275T%\377=Sc\262\275\2458\030\275\375\307\324=\005Y\320=\003\206\010<R\205\\\275\261\033\222=/\216\262=( \241=\'\377\241\273\000af\274\345H[\275L\rR\275\374\333\303\274\206s\322\2758\367%<\324\245\255\275\036z\020=\326\214\312<\001R\205\275\315\242\214\274-p\360\275\2070\243:-]\226\275\207\032\301\275\341\003]\275\177\356\335=+\352\025=\306\376z<DZ\007>\032\313A<\313^\354\275\303\020\230<n?;=\275\325\273=\271l\313=\316\034\305\274\227\203\360=\3662\343\275\010\325\017\275Y\204\204=\025\215\326=\224\377\322=\316~\222=\223\345_;F\317\333\275r\225\232=\206\344`\274M\016u=+@\002>\326\020\000\276\313\\\023=NbK\274\276\031\345\275;s9=\373\241\002\275!.\261\2759s\256=I\375,\275\027\033\251\275%r\311\275\320\020\033\274\323\304w=\3671\276\275-\3317=\223\037\006=\202\356\263\275!\240Q=%\"\234=\031\014\327=o@\005>\370\017\023=sp\355\275=\213\022=\252\267\324\275\265\032\345=\310\000\005\275\205v6=\265a\007>L\252\252=\201\362}\275\304U\304\275^b\000\276\351W\244=\005\013\"\275\010\003M=\273\255\003\276[\276\214=\357\025\225=G+\213=h\213\234\274\264u\357\274\214\307d\275\010\002\365=5vW=\307U\344=\377\224\225\275\224\343\232\275O\237p<\335\213\201=\200\nn\275,\355\034\2747}]=0\333\363\272IB\242\274\365^\002\274I\345\031\275\270\014\177<})\312\275\245\331\234<\212\001\357=*\302\246\275\245R\346<\337\364\341=\006\257\334\275\030\343\260\275[a-=\014\322\247\275V\267\244\274\360\343\037\275\307\233\331=\032\200>\275m\370\265\275\302e\275:\211U\326=:\255U=\256\234\305=\247\307%\275\t\344\351<\274q\220=O\017U\275&\235\270\275\354J\242=\363g\250<\3563\006>\264\365\277;\300\266\375\275\305\224*=\2040P=eD\206=\251\242\242\275\332\303\\\275\3346_\275\022\027\205=\365$x=\025\225\001>\002k\360\274D\373\003=\344\3329=\337_\005\276nS\366=\271E\273\274\2623\020<\344\272\204=\301\264\304<\312\222\007\275\243YA=\364}\271=\340:B:m\266*\275\t\247\316=\352\245\206=\007\264\002\276C\004\276\275\262\217\337=\t\205\'=B\322S<3\223\227=\271\245\221=\234n\202=\330\302\330=wzN\275,\302\325:V?\255=i\232\274=u2\372\275y\014\242=@\310\320=\021\n\342\275#\271\344\274b\251\350\274,^\340=;\t\300\275\ti\007>\n\320.\275D\365\374=\360\312V\273\362@\375=\213\'\210\275\332\277==\017o\252\274\016\216\225\275]\230\344=V{\213=\014\356\226\275\0058b=\211=B=M\325\312\275 \206\375=r$H=\370f/=\\\240F;\014Z\323;\036/\340\275_\250\007\276\0235O\275\270\231\275<\207\252U\275\347\371\330=\273\370\225\274\013K\007>Eb\324=\035\243\322=\322\003\263;\345\361r=\016x\206\275\036{\350\275\242\214>\272\204\200\230\274\337(\331=\201\014D\274|\376\032\273<;\342=\001\207\373=\265\235\335=\316\017\025=>f\376\275Z\353\217\275^eU\275;\302\311\275\235)\364<\217\351\354\274\rr\365\275NU\204=zBk<%\010e=\013\022}\273\374\241\333<\t\203\222\274\275\201\212=K\245\276\275u\214^<\323\231Z\274\245\225\252\275\261p\356=\010\024\261=8Z\t\273\337\027\270\274\331\313\372=\264T\333<\321\241\230\275\266\370\375\275\0049\000>\256\033\331=\341J\326\275t5\377\274\275\r\204\275\r\273h\274\340Y\356=y\302H\275k\264\200=eL\210\275C\275\365=\313\027\306\273\227\305\360=+\221\311=^\037\006\276\3021p\274\264\377\243\274\300(\220\275J\232\357\275\007D$\274_\246\347=\311\010\022\271\003\313\327\275\300\325\267\275r\033\342\275\315,\010\276\262Do\275\340\033-=}\351==l\234:<\235\022H<\230^\334<\035\005e=W\200m=\275\026\374=k\271\271<\355\2323\275\274\007\240=0\007\373\275\020\262\373<2/\311=qQc\275\230\362\223<\tr3\274\265y\256\273\323;\363\2744\202\342:~\221{=\371\262\000=\266\367\341=\367\371K\2746-\207\275\030\007\303=f\275\341\275\351\276\255\274\3406I<\374\017.=\'\250\307\275\267Q\327\274\177p\337\275\366\224\211=\271\245P\275T\316\264=*:\000>\307\026\224;\031\221\377=\200\352C\275B\356\035\275E\004\357\2755Xf\275\370\231i=\317w|\274O\370\371\275|\312\250\275\000\2406\275G\237\032\2737=\251\274x\271\350\275\203\356\320\274&\364\312\275\037\202v=\302\020\332=\310X9\275Z\372I=\362\341\205\275\252e\200=??\374<W\310\322\275g\334\251\274fB\006=\232\2518\275\234\313\245=\007\364\225\275\n\200a\275\3528\352\275^*\306=\234\213\206\275 J\371=N2\217=\201\322\203<\207l\003\276\275h\010\276,\3425\275\337\204*<\220B\022=+\322\323=_<\357\275\343\351\003=\323\254t=\216\027\256\274/\"\317=\325W\342<\364kD=\365\224\263\274\231]/=\311\213\335\275\002\206\010=D\027\245\275\242\337\265=W\001\342\275\371Y,\274b\244\255=v_d<5\300\333=y\272\201\275\225\303,<\366j\227\275iN\240=\222m3<\013xZ=\307\210\340=\205\316\321=@;\326\275Z\350\002\275\310-\225\274\317\020\000\276\305U\227\274aZl\274{\r\322=`\357\000\276xF\372\275%\256]=4\325\002\276\276\017\334\275\370\306H=\013\003\025\273\340\306\321\275\253\362\347<$h\304;e\311\350\275\372\231\376\275\355\327\272\274\036\010\003\276\003\236\316=\001p\233=\322\013\265\275`\333N\275\206\027@\275\207u\256\275m\352s=\373V\251\2759\345\007>l\335}\275\236$\020\275a\232\026=\2227\212<3\230\203\275Z\025\004\276\345|7=\250\213\002>*\005\377\275a\316\360\275(q\264=\2638\213=:\307\305=\313-\316\275wW+=\204\235\237\275\007r\003\276}W3\275\361{\256=\301q\241=#\220\226=l.\217\274\316q\304=\226`\261:\327\037\004\276`=\255\275\355\316\355=\362\333\302=FQN\275d\236m\274L\014^=\244v\213\2758\273\013=\220\212\225\274\r\277#\275o\006\000=\363\346\305\275\022\217\263<\340I\250=\033u~=s\r\321\275\355T\377=_52\275)\322\367\275\231\336\264\275\020*\203\275\243\246\255\274}\235\377\275\274m\231\275F\251i\275\337.\317=\273\325.=\211I\304\275\261P\236\274\324\365\242=\270\272W\274\355\n\005>d*\221\275O\237<=XT\304\273b\350~\275\2243\322\275\342\240\006\276\027\005\022\275\004:\245=H\374,\274\366X\000>]\371\004>\271\320z\275\313\316r;\267~\357\2757\375\332<\337\n\265=H\222\257\274\303\021\023=\215_\204=\322\376#\275\312\234\340=\251\335\343=\265\010\233\275\225Q\007\276\232\341\306\275\'\356\244=\260 \237=A\0271<\223(\354\275&\303\361=\021|V\275\352\271\375\275\345\317\332<\316\365\274\275\005\3036\275E\026\231=\312\"\232=\303\363\004>>W\370\274\211\341\322;t\234\210\275,\344U\274\332\271\332\275\025\206\271<\202\275\267\274\227)\230=\304M*\275\344\022]<\3551V\275\210\334\033=\312\202\363\275\242\212&\275\355\270\264=\022:\366\275\013\013\214\275\324\213\273\275$,\202=\374\3673\275N\204\007>\027\223n\275q\251\340=\273\237\353<m\366\303\271\300\314};6\344\322\275\215Wd\275\010\3653\275Q@\215=\036.\307\275{\207\201<\271\033\313\275\3148\206=\243\355\221\275Oe\261<\030\273\r\274\256g\353<H\005\276\275U\\\317<\212\375$<\033\276@\275\323\276\006=\345dt=\275F\211=\253\340\306=5\250\314\275R\315\276=\334i^\273\305\256\324=2\266@\275\006\345\220\274d\311\266=\275\357\346\274)\000F\275\006#\007>\021U\010\276O\334\356\274\235X\241=\262i1=\025%\014\274i\244\373\275\0014\230\275\\L\020\275RY\200\2748\210\003>O\001\254\275!\323\326\275\377w\270=1A\356\275\016\204\371=|^\266\275i\027\344\274\246\252\003\276\262x\t\275\023\352\260\275q\242|=LH\375\275`\002\302\275\314\326\021=\373\0229=\334\n\337=U\333J=\036\362\257\275`B?=\313\312\311<\016\3331=-\350\207\273\325\325\356\275I>\307=\212\203\374=\014F\325<\367\226j=\2643(=c\271\274\274\t\027\321<M\242\346=c\001\364\275\271\373E\275l\267\277\275\216\370G\275q#\010=\350\265F\275\301x\200\275\355\224\324<\025\006\360=\313\274\263\275FP\213\275t!\330=\307v\332\275\343d^\271<\020\242={\364\216=\254r\311=(\236\312\275Cf\210\275\nD\267\275\036E\273=\301[f;\330\333\327\275\310d\327=\234\345\364\2741\234\364\275\303,\225=6\263\317\275\317Z\236\272\261\312\350\275\363\2377\275n<\336=`\217\376\2759\312\237={\"\237=\236\212\260=\312\356\305\275\201\200\253\273\355\353\237=\n\031\303\274\261\024\030=\346\307\032=\250!\002\276O\210k\273\225 \357=\222\266\331=\251\352\001\276<\t\205\275U\031\247\275zBA<<\023\212=\013\363\263\275\004R\357=\350\343\003>\227\204\367\275\03512<p\n\364\274Xd\223=T\230\335=l7a=r!S\275?S3\275\003\373\256=\244\003\303\275\005\256c=\304\005\037\275\277P\231<\270T\344=\375{\251;\334\333S\274F.\001=\240\324}\275\240\335i\275\3423\006\276\2477\230<)\211\305\275\225\2451;dW\002=\274n\300\275\300V\014\274.\245\227\275\322\177a<Ph\311=\017\260?=?\"\265\275a\277\272=ql\275\275\017\215(\2746gP\275\345I\266\274\005\214\350=\314\257\254\275Y\352`\274\320\375\200\274_\024x<9\324\346<4Z\347\274\214\032\306:\375(\201\275\242\205\267\272\024t\265\275\270Bh\275/\031\300=N<\350=\230\376\353=\272v\377=\\;\226=\025\335\347=\304\361\323=\364\374\360\2747\252\350=z\241\275\275\223\204\235\2751Q\351\275I\354\337\2755O\007>\275-\347\2751=?\273$\310\246<.z\310<\247p\230\274\031\370\203\275\365\361\277\275\356\237\"\275r%L\275\360\014+\275\334\236\210\274\323y\005>\264x2<\334\224\272\275y%\272\275\372j\210=\261U\270\273\310\212\232\275\350\"\004>\352\013\264\274\247tN\275\275\023G<`I\251=Y\2413\275 \347\302=U\035\331=\273\374\364=_\327\325\275u\372\205\275$\220R\275 ;\275\275(\016\374\2752\354)\275\304\2364\275A\333\360=\3245\031\275\242f\007=\307\346\007>\332\007\357\275\023\373\257\275\330\324t;\223.\363\275t_g\275\255I\353\275\030\213\372\275\367\332\027;B4\343=\001-\343\274\245~\2049\213\310\314\275BK<=y\374\332=\003zK=\212\302\252<+l\246\275\361\372\347= i\005\276\007\200k=\331t\037\275\\\210l\275\206\201\210\274\332\213\211=\226\264\313=#\023\333\275t\255\325<Q\372\367\274\216\230\307<\267\342\362\275\363\332\216\275\217\001\023\275\010U\275=\352|\356\275\225/\240\275\342x\320=\264K\014\275C\033N\274\307\235\216=\301\3324\275\334H\000\276Q\235\370\275\306e/==LC\272\231!y\275/\023~\275Nz\273\274yL\262=\337P\211<\375\373\301=4/-=\212\216\311\275\026\325\002>\333\304\247\275`\242\364=\351\342\r=\321\266\277=\243\335\357=\347\024W=\243I\351\275\223R\205<\257)\343\275d6\201\274\252\305\354\275\361\375\270\275\213\267\336<\272\006{=X?\037=\333Z\023=\342\032\035\275\252\362\320=w\0245=\326\302(\275X\306\230=;\033\240\275\301\017\204\2758j\330\273\2716\200;\265\312\325\275\025\372\226=&\265[=\331\321\250\275MZ\215\275%4\235\274\220\260\303\275\246\312\346\273g\352\004\276\004<2:0\266\313=_\316\340=\265\204\006\276\240\233\001\273\344\236\301\275k}q\275\274\365{\274q\231=\274D\321\301<\262\372\020=u\022\257=\027E\310\275\324H\332\275#\177\310=\010U\366\275\001\177\365\274d\315\374\275O\023\324=\237\0012\275\225\222\300\275\214~b=\277yo=\t\206.\275\005!\022\275\326S\376\275@x\362=\006I\310\275\372\n\317<\240\006-=\205\240\304\275\032\022\010>\'\001\234=%\032\245=\213\370\324=\326\357C=H\306E=\022\310\306=\3701{=\370\235$\274c\367\201<\307\004\256\275\375\347\000\275X\275\363\275,\373\253\275g)\224<\033\320\376\275\026\177j=\333\215\002\275\365\310\333=Jy2\274\236\020\263\2753\212\235\2758\005\254<\241\217\026=\253\220\252;\312\252\002\276\351(0\273\314\256:=/\261\307=R\261\201=\237P\277\274H\\\200\275&S9\275\203\020\374=Y^\326\275\224)\263\273\025\221\017\2754\300\243\275{\r\234\275HK\341\274\347[\007\275\347\242\321\275\345\215)\275\277\031<\275\020u\014\275\320i\306\275*\202\244=\\)\306<\245\250\310=\215H\313\274:\005\214\274m\000\002>\314\323\316\274\3243\210=\240\227\377=1\226k=V\236\243<\341E2\275\257i\367\275Dc\002>\317\346x<\352\321g\275\322b{<\352#\000>\205\242$=\025@\204=CC\261\2751\235]<\224:\002>\327a\023\275\362\333?\275l\305\235;w\257\005>W\242A=\024E\024=\326/\234\274\251\002\344\274\264\202\210\275\2642\244;\343\272\266\273\271G\002\275\245Y\350=m\263\225:\223\266\232\275)\226L\275\205\246\316\274|\300\343\275\027:\371\275\030\371\245\275K\016\217\275\215\030\254\275\232\323\307\274\365\254\255\275\203\t\327=\341\262\352=\013\003\334=L\000\244=$:\007>V\264$\275so\260=\027;\313=h\224\214:\245#\002>\346\266\255\275\215pp<\\9\261\275\300?\272=\272\376\210\275\347\241z\275\337gb=P\247><g\210q\273\231\255\335=\332\352\254=\264!\\<\207\332\323\275\222\223\336=H\377\247=\273\215A;\025:\202\274\357\356\330\274\016F\226<\223 \331\275\214\002\312=\344\252\252\273\243\300U\275\223V\361\275\016\313\006>\344\273\334\275-l\351\275\323\244>=&\006\230=T\331\234=3\307\305;\355bZ\275~\374><qZ\210<\316\010!\275}\307\371\274Al\216;r\017n\275\260h\315=\276\363\274\275s\t*\272\021\212\262\275s\2072=$\037\006\276\0149\217=p\304\261=\347ZL\274\342\212\315\275\304B\341;\203f3={?\275\274\373^\345=c\004v=\363\2071=\277\342\263\275\260Lx<\341\374\306\275R\254\371=Yn\277\275\302\241%\274\373\037\004\276\262\020u=\267\365\204\275\t\375\204=t\036\352:e\316\370\275r\350\262\274\225\305\360\275t\326\312\275\222\373\257\274\271\214\242=\\\237\351<4JZ=!\222%=\225!\325<\216\n\253\275}\225\327\275\026G\250\272\222\321\020\2753;\206=\237\221Y\275\026\207$\274\216+`\273|*\253\275\250\021\231=\236\267\370=nb\350\275\3339\257=\353\027\336\275\356\267\233=\000,\307\275\371T\216=\375U[\273D\216\226\274G\000e=[\327R=\034:\371<\243\371\366=u\002\301\274\303\222\206;\302\357\276\275\253\376\r\275ERN\275K\370\235=\002\205\250\275\016O\277\275\344\372\366\275\326:\214=D\216o\275\3064U=$9\240=\375\342\355\275\310\326\324<$1\362\275\006m\300:\230\0063\275\017v/\275\007\254\346\275v\034\273\275\373h\375=\316\350\006\276={\270\275\301l\274\275$\363p\2744\276Y<W\361y\274V\373\305\275\003 \006>\330\336\005\276\261\013`\275c\243\324\274\252j_\275\274\354(\275\303\334u=\317\250\034<\352\362\353\275K\221\254\275t\302\344=t\340^;\226\314#\275e\023\345=U,*\275\356\370B\275\016\232\300=\277S\307\275\025\253\254\275\2655>\274g\306b\273\250\'\311=\362\214\232\275\366\205-=y&7\273\356\200\212\275U\377\310\275\032s\307\2759^n\275I\253N\273\237\255\335<\202\301\002<\230d\360<\322\332\003\276\n\014\031=\017\334\334\275w1P=\273*L<\374\005I\275\245B\332\275?\'\310\275\244\277\007\276\312e\225=\035L\327=\320[\377</\004A\275\017\214\202\275\027\005\203=\034I\205\275\202\352\332\275\310E\301\275q\233\311\275\020\230\362=\215h\315=\351z\002\276\212\244\233<j\273\304=9\372\316=\364Z3=\315\276\346\275\276w\333\275\344\032\265<\"\025\310\275.\264c\275\247_\224<\327B\007>\277O\317=\316~V=\177W1=\277\315\333\275\334c\310\275\355~\250<b\330\332\275\354\356\274=\226-\371\275}^q=\375A\211\274b\335\262=8\225\222\275\242e\014\275\267\301\266<3\214\206\274\256x\003\275h\344\206=\240E\320\274\264\357\341\275(\3428=\035\301\311=\3466=\275\326N\215=\276\025\355=\2519\337=\311\303\245=\020\017\205=\350\346>=\350\276\203=\330e\211=\314\253\200<E\324\200\274\334z\316=\343\263\022\275\006[\256=g\007s\275,\274w=]\306\005>!\352\233\274|\266\247\271xn\242\274\347\t\002\276\327\233\302\275\255\303\271=a\022\322\275l\326\226\275\212\265I=/\025\366\275^\224I\275^rR<\265\"\317\274\010\370\002\276\276\251f\274\232\245\304=\317>\322\275C\247\375\274ws\365=8F#\275\3533[<ae\334\275\374`\357;f\370\237\275,[>\275\237c\321=S\346\037=\267\357\366\275G\362\216=\264\272=\274\356\252\300=\276f\341=\001\335\374==\350\365<\206\033\313=)u\330\275_\206\000\276\221\321\214<&\355\364<\274\361\207=\202x\216<\312\321\203\275\201\367\375=\374\325\006>\013\317\027<tK}=\361E\010=a\264\020=#@\256=\355\323\357\275(^\255=Jy<=/\331\216\275\245g\264;\345\205\247\275Q\246\220\2757t\271=\231\266\006>q\010\235=\371\250\342\275\235\352\245=\264\354\267=\272\330\221<\344\3526\275\210\021\234\273\356N\010>\323\224\214=W\312\206=\343\213\210=\234\237\223=\021v\000>\\\203\206\275\243\246l\275\225(\321=\332+\356\274\254\202.\275\326\325\344;\365\354\251=\355\261/=;\257\340=n\311\334=\365\016\002\276W\0268;[l(\275]F\253\274\305\213\244={\245\021=AD\371\272\350\334\343\274m\\\201=.B\356=\346=\310=\234z\\=\337X\203\275b\243\345=\276\216s=\225\\)=J\'\253\275v\243\203\274\347\242\325;\031\265\344\275K\032~;\362\033K=\"\356\200=Z\262\032\275\200\001\353\275\367\256\005>\332\237O\275|\310\332\275YHs\275M\304\315\275E\003\320=\333\233\240;}|\251<o\017\224\275\017\351\001\276,\002\377;\216+\373\275A\371\325\275w\030\217\275\307\366G\274Qv\330<C\210\242\275\232\237\347\275\347j\t\275\020\264\374\275\352\250\017=\341s\333<Gk\'\275\274\035\271\275\204\236\261=G#\006>\002F\210=fA\305\275<\333l=\005+\360=m:\036\275\246\026\241=\020ly\275%a\370<\233I\247\274\206k\314=\256\345\370=\n[\247\275\301z\370=m\361\353\275\204\035\003\276?yj\274\216*\371\275\257\351\277\274/\312\244=\243\342\247=\312\347C\275\345\020t\275\014\303r\275:\000\225=\371\345\310\275\270O\367\275x\357\323=\324\241h;\302\2132\275\323M\321\275\003?\306\275If\377\275K\327\336=\351\264s\275*\252\237\275\355\033\221=\266\304\230\275%\247\254\275\362=\272=!>\034=\224\036\343\275a|\375\274\364\236\212=\320\301V\275c\017l\275\305\033\323=\001\241\332\275f^\357\275\334G\334\274\326c\241<n_\346\275\017Z\210<\353)\335\275\004\213\031=)k\367\275\244M\177\2748\356\307\275\256\222\327\275\212,\375=m\323\253=\"\006\363\275\344\222\265=\346\252\257=\025\263\351\275Y^\014=\266\375\247=2(\323\273cX\207\275\n\224\335\275\251]\377\275\361\266\003>bX\235=\357\266\332\275\nJ\215\275k\205\250=\236\361b=\242b\000\276\312\300i:s<\273=b\036\234\274T\203\003\276\312<\226\274\315\230\275\274<\204\"=\351\210\004\276\206\252\300\274\n\371\277\275\220\025\003=o\275\266\273\271\252\263=p\313\235\275\310:\250\275\014\332\322\275\372\262\002=\371\366\267\274\341\260\277\274\241\177\360\27509A=\2048\373=\332\025\366\275\342\027\306=\037\3210=\350\2765\275\277\271\240\275\034}\367=u\023\256\275\271g\220=X\331\337=J\0231;m\373\315=\024\337\257=\252\277\254\275\206\'I=a\234\263\275!\261\325=\250!6=\343j,=\270\357\003\275\033\020o=\032\262\270=\265M\304\275\367\211\311\275\217i\303\274m\322\235=@9\002=\217h==^\245\251=|\272U\275a\032o=\t\0259\274W\327D\275\022\300M\275\020]\335\275- W=\260\030\225\275\r\305\306=\337\264c=\2703\017=g\177\035\275\374\363\337\275t\224^=\223\023\205=a\033s=$\333\\\275\347\245\357=\241\210\037=\233\203\207\274\204\277\035\275q\341\374=\032=\000\276\2408\225=\312\324>\274s\220\211\275\311\314J:J\304\367<-\223\035=\217\375\355\275Z\312\264<\206\365v=~\266\241\275#\362\201=\225\232\031=\267^\332=\266\326\224=&\351\317\275\224\212\022\275\256\270\362\273\357g\353\275G\201\323\275\353 \226\275|\017\243<_\3053\275A\340\276\273\321J6\275 \310\014\275\206<\302=[\021Y\274\355\236#=\223\252\312\275\021\263\222;\324\354\301\275p!\253=h\222\360<\254\0166\274\001\366>=[\363\374=\204#\330\275<\334\337<\205\rt\275\324\203\365\273\265\307h=\371?\260\275\350X\222=D!s\275(\244A\275\210\016E=J\242\351\275\023\206\222\275\302\254\251=\230\241=\275\026\024W<\304\311\310\275\320\315\003\276;\266\342\2744\243\303=\377\323\330\275\037O\023=\201?{\274Re\260\2754)\270\275\261\000_\273i\005\315\275Y\301\272=?\027\r=\017h\273\275f\367\255\275\005f\\=;\031\374\275\310\326\213\275\361\234\252\274\231\2350=:]\315\273\342{\351\275\036\221\221=\250 \263=\260,\376<\035t\206=H\314\031<\032\027\031\275\202&\202\275\315\370\240\275\030\007\325=\301\277t\275\017\351\367=\237\215e\2754\330?=\341\340y\275\200\214\262\274\013!\014\275]\214\003\276\314\226[\274f\312\004<"
      }
    }
  }
}
node {
  name: "fully_connected/weights"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 330
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected/weights/Assign"
  op: "Assign"
  input: "fully_connected/weights"
  input: "fully_connected/weights/Initializer/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected/weights/read"
  op: "Identity"
  input: "fully_connected/weights"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "fully_connected/MatMul"
  op: "MatMul"
  input: "input"
  input: "fully_connected/weights/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "fully_connected/bias/Initializer/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 330
          }
        }
        tensor_content: "\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "fully_connected/bias"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 330
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected/bias/Assign"
  op: "Assign"
  input: "fully_connected/bias"
  input: "fully_connected/bias/Initializer/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected/bias/read"
  op: "Identity"
  input: "fully_connected/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "fully_connected/BiasAdd"
  op: "BiasAdd"
  input: "fully_connected/MatMul"
  input: "fully_connected/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "fully_connected/Relu"
  op: "Relu"
  input: "fully_connected/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "fully_connected_1/weights/Initializer/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 330
          }
          dim {
            size: 4
          }
        }
        tensor_content: "\265\3602\274-y\353\275S\205\223\275\324\237\036\275p\022\254\275\310:\245\274*\201\225=y\2349\275$S\352\275\321\006\337;\000\314\245\275\001\337\272=H\006\004\276@\271\231\275\030Y\273\275\215o\245=\370o\376<W\'\365<,{\262=\257\317\271\275l\034s\274\017Q\200\275\'\232\343\275\364\213;\275\305\356\001\276\2307\365\274\342X\322=\031\217\243\275#\224\247<>r\002\276\217\303\316<\037\206 \275\271\016\005\276\020\233<=N\272\324=S\206\303\275\310Q#=\010\323\306=\315\277\257=o\034}=\334\026.=V\351\034=\202\354\220\273\253\271\242:T\317>\275E@\257\275\240\223~\275\364\005x=\266\303W<K\331\265<\023d\332=\315\003\265\2740\2052\275\341\306\202=!\225\216\274\333\300\005\276rJk\275\314\343\r<wI\345\2752kQ=Q\t\025\275\303O\313\275\016\315\321;F`\276<\337U\332=j;h\275\374\021\006\276\006\342\204<\207+(=\315\337\232=\351F\225\275\251\3507\275\325\233\237\275a\004\032\275\350\020#\275\026\352\321=P\244\241\275\242\203o=\214\344\342\275h\312\310\275\246!\242=s^\310=Dr\206\275\031\255\214<}\226\006>7\n\234\275.B\"\275\244n\306=\346\027\000=\217\377\213\275\037q\372=U\360u=-\357\262\275\232c\337=\177\366\312\275\233\010\006>\211:\310<\257Y\332<n\302\362={\210\253=\366\320\335\272D\033\272\275\007o\\\274\366 ;=\337\211\376=\220\364\034\275k\034\362;p\202\t=\003\310\325=B^\362\273\0141\323\275\222\213j\275\030vd<\363\267\275<tS\227\275\005]\257\275-\006\361\275\303\007\326=a\336\266\274\022\026\345\275\033\263\257=\017\364\241=gj\303=\210\002\316\275\276\3428\275\311\240\372=Z\277o<\245@\373\275\344\221\344<u\206G\2747x\347=\202\357\006>Q+\031<VGY\275\315\243:\275\304\002\254\275\222\256\252=\245\220w=\003\235x\275\226I\334=G\345U\275\234\317\313\275\341\206\276\275wM.=A\013\370=\231\r \274\3716/=g\032\344\275$\313\352=kS\327=\014\201b=\2311\026\275\311\324\203=\237\224\330\275\266i\237\275\206\200\247<\344]\005\276$\244\351=\377}\020\275\346\323\003\276\255\245\003=&\032<=\027,\216=z\362\346=\032\252\325=n\333\355<m\\\370\275\025\277\221=\313wC\274\214n\207\275#\007\036<08\374=+\247\347\274A\0202=\302\203\245<\035\252\343<\002\242\272\273\365\205\321=>G\007>&\330?\275\243`\312=\301#\275\274\\v\227=\006\200\266\275}1\215<P\272\032\275}\252\315\275-\276\347\274t\210\177\275\351\375\377\272t\337\320=\322I\312=\275R\262\275\032\033\227\275\340\331\\;6I\237\275,\372j\275\333\2651\275 \202C\275\327\335Y\275S\214\017=\360\232\353=9\270\346\275\t\314\377\275\242\264W=d<\244=\rK\354\275oK\000>\306\2434=\233\344\277=@\316\361=\025\026\005>6+?=\301\243\031=u\261\347\275\302\232\205<\215\017\322=;R\024\274\232\262\374<\371\264\331=W\247\256<\272Y\315;P\323\203\2758l\227\275\212\353L=\370C\001>\336\010\235<\270\271\223=I\346\270\275V`\232\2758\213h\275Q\316<\274\330\306A\274\027\377\310\275\353\342\230<\257\210\257=\235/L\274\030\234\224\274-\021\002>RS\305\275y\305\022\275X\261\276=?\214\211=\010\177\374=I\001$<\323^\260=\313E\233\274\354\317z=<\r\375=\253(\324=\301\006\231=Exu\275\254s\004>#n\264=O\314\023\275{\302*=\2701E=\377\257\363=\355\204\225\275M]\257=uy\367=\271\367\037\275v.\003>b*\217\2758\305g\275\251\313_=*:\220\275rB\326\275\240\231\026=\\l\276=\310\206\365=\306\272\266\275\266o\277<.k\205=\031\032\247<\023:\333\275\221\205\331=|\245\342\275J\377\345<\367\274\354\275Cn\002\276\3669\236=\010\315\356\274\260\335\230=\242\306\233\275\347\206\'\275\354\017\204\274\271\316\331=\006\000\354=o=\217=\252\3504\275\327\331\226=\235\037\273\273<-\352;\201\006\267\275\211\255E=\n;\233\275\374\324\330=i\254\"\275;\202\371\275\307\356\266\275\363l\323\275WE\005>,\226\n\274\261\271\002\276\267\332\303\275\\\337\327\2754\317\361<K\224\340<\017\204\237=\356\245\327<\310y\355\273\212N\334=\221C\264\275\'\027\333;\366\364\276=\r\223/\275\374y]\275\263\347\264\275Q\302F\275bY\261=\224\310\337<\312\272R=8\001P\274;\352\352\275E\222\304\275\241\232G\274ys\374=j\"\207\275\264\327\206\275\221\234\206\274e\277\304;m\350\340=\010\024\240\275\230\254\353=9\324\253=\306\245\357=\321V\275<\326\255\334=\262zf\275\213\025\351\275\000\221\371\275\037!\232=-\373\201\273\013\301\312\275\253\217\377=\315b\352=Yv\333\275g\375\253=\256\251\310=\331\367\220\275{\266z=\204B\246\275\333\023\022\275\351\376\334\275_\022H<\302X9=^\313\025=\322\307 =T[\007\276 \006f\2758\243\332\272G\342\022\274\211\263\343<\241\001\264<\212\273\346\275\034\235\234\275\232z\265\275;\013\322\275\323hC\275\344\275 =2X\350=\301\275A=M\305s=\024i\032=\364\207\260\274\347M\376\275\320\350\300=\264\231+\275+\021\t>\321c\267\275\231\336P=g\033\004>\337\261\373\275\362\267|\275~Y\334\274\344\233\306<\237\251\353\274\212\263\254\274\032\304\211\274\231\311M<\227r\254\275\224\303\374=\277\342Z=c\341V\273_\234\224\275\315\361\006\276-\215\310\275p\005\033=tl\005\275(H\342=\210\177\235=\247\225J\273\266\205\347<<\377\373\275\270\362\004\275\240\177\007>=\017\277=\r\267\177\274i\016\353=\374\202\214\275\362\034\002>%\347\317\275\225\013\352\271j\025b<\001\345\000\276\021Y9=\200ZN\273\224\344\010\276\374i\002\273B\354\354\274\375!\362\275\3765\353\275\365\366\371=\253\270\334<\026\361\340=s\266u={\355\216\275\204\215t\275\310\370b\275IF\367\275x\tQ=\250\000\264<YJ\n\2748\334\211<l\034\001\276\273\337\210<\323\340\343=\371\177\273=Up\006\275\n[\346\275\317\214\316=\223\017Q\275PM\355<\236I\267<\261\273\t=F3\260\275\356\331\344=Z,\023\275\016\273\345=\332\360\240\275\373\243\362=g\263\000>\317C\301=X\341G\275\274\360\207\275\004#\267=\370\334\006\276*\221\215\273O\263\005>\233\236L\275\212\255\006\276\274\264\001\276\330\217\017=\266\335d<\332\251]<\033\222\311\275=\355\254\274\304\377\007>K$n\274\346\215\262=\244,\324\272\204g\004\276\217\231\232\274F:{\275`\002\311\275-\203h\274\022\247\004>\231\n\224\275\263:\003\276[5L\275p\261\373=v\010r=\377\232\023=\rD\326=Y\014f<\023\237\253\274R\242.=\305\370o\275HVh;\324\365\373\275\032\200\000>4\322\300=`\272\001\276\255\262\341\275\231}G\275>\225\004>\273h\000\276Tg\267=u\325\323=\247(\365\273\204\214\254\275C\266\246=\311\233\207=3y\331<\317K\205=\217\3546\275} \217=b\356\210\275\257\212I\275c\230\027\275\016Q\013\274\345\034\205=\367\263\365=\320%\300\275\250\354\324\275z:\357=\374J\202<i+\217=\361\345\257\275\360^\347=\270\364\261<\014}Q\273\204\356\r=b\241\243=\272\016\345<\306\306\t\274}\3345=\0026n\274\303\372\362\274C\253\007>\252\375\354\275\261\261\345=\377\263\355\2758\377}=K\341\316\275?i\037=q7]<L[\276\274x\372\237\275?\031\214=\373d\003\276\310\333\307\275K\217r=&1\037\275\004\303j\275\241P\266=\240Y\343=S8<=S\324\003>\347\357\327\275\251\375\326=Al\256\275cC\300\275}|\264\275#*\342<\240\232\271\275\225/:\275\324z\263=\020\037 \275\240\3526\275\363\370\317=LW\016<\336\210\315\275%\301\361=\345\260\221<Z\301\376<\025\030\317\274i\226\333=\372/n\275\342\213<\275\211n\222\275-\317\232<\342\335\324<\214\177\302;\017T\247<;\235\263=\310\327\311\275\025\247T\2753\275\233=\355\"\022<-\257\210=\276\243\322=\333\032\260=V\304\336=O#\375\275\007\271\303\275\231\242\316\275\370\'\234\274S\221\360=\346\202r=\016\376\000\276\2311\371<p\353$\275\230\307N=\302\010\246\275jD\362=W\201\020=\275f\243=\230`3\275\017#\007<\007%\276\273vu\301\272n\275\315\275\300{\233\275\304h\032<\275\0265\273\232@\253<\232l\255\275c\274\265\275\335\214\021\274-\363\007\276\336s\023\275\337h\211\275\373\320\032=\305\270\273\275z\316\361\2746\271\302\274/B\372=\231\036\344\274\203\2267\274\362\337\022\275j\344\004\276+\246:=\017\347\001\276\263\245\227\275x\375Z=\373<Y\275tR\326\275\030\346\346\274GQ$\275\262\020\262=\350\371\321=\304U\311<\341\226\007>\325\032\250=\r\344\026<\366s\261\275\265\212~<V\r\017\273A\344\002>\244\237\301\275,J\313=\027<\010>\334AQ<@n/\2759\2546=\273\336\245=\304\234F\275&E\300\274k\036\005\276\216XI=b\361\244=O`\005\276\262/\376=\254\246\264\275\003T\251\274+3\336\273T\272\226\275\2245\305=r\022\020=B#}\275\351\233\221\275\327\023\376=D`\355=]2\224=TM\344\275\\x\004\276\013A\002\276Wb\355\274\331\020<=4\250\326=\240Z\243\275p7\327=\237\240\010>d\020*\273\013\333\305;\222\302\005\276\003\216\344\275\317\255\005\276\031\007t\274\n\216W\274\3716m\275\260)\001\276\302ql\275\361\257\336<\027\305\026=\355\025B=\273\024K=`\252\275=\217\346U=f_x\273\210\002\017=gj\250=\007K\016=9\202\030<\307\342\237\275\351\267\316\274qV\347\275\30104=}N#=6g\204=\202\037\305<\324b\202\275\n\375\237\275\230\010y=\221\347\243\274\335\351\203\275\237d@\275m\353\3008\256\331\344=\305.\237\275C7\021<%R_\275\211\033\271=\357b\367\274\312\220\223:>\234\375=\233?X\275\213\207\375\274\373\303\317\274uu\356\274/,\320=\352\'\303<A\373y=\341\311\327\270\344(\347\273\271\260\000\276S\371\265\275\336\316\360\275T\333\316\275<\332\322=\037F\304\274LMU\2757\344^=\034\027\261<\324\311\332=@\332\240\274N\016\240=zGg\275\251\354\310\275\345\263\002<7&\r=I+4\274\372\272\314=X\214B=Lt\217=,o\244\275AL\303=BC\212;{Np\275\322\031}=\205\374\302\274\372\370\334=vP\365\2756\004\334=\351\344\262=\000\354v\273\r\022X\275L<\227\274\265\340\202\275\211A\305\275\357\370\334=\022O\260\274\214fX;b\220\377=Q\013\320<\025h\310=\350\270\230\274L\234\202\275:\035\t>OA\213\275Ar\006\275g\317\007>!F\005>:\243\253\274\373\314,\274]l =\010\220\245\275\330\265\365<\227%\325\274\332\320a\273D\241\305\274^\265\264=\277\236\207=\220n#=\\\177\265\275\270\353\004>c\375\242\275\207Q\222\275Q\273\346=\337[\004\276\336i\245=\343\313\354\273\3135\261=\364k\005>\217\230\003\275M\302\004>\026\355\335<\377\271\353\273\304\262\030\275s4\305\274T\315\006\276|Xa\275u@\000>\016@\333\275s\306\013\274\223\346\203\275\200O\346<\342jt;\220\200\305\2731\275\201=\312\222\367=R\332\255<*\226\314\275\346\024\366=\367x\001=\3341\266=\321*\300=\031\220\235<\200\356\001\274\236x\010\276\033\331\345\275\254\323|\275\217\364\334\275\343\030\346<\035\024\242=\271\325\273=\2127q\275\365/\343\275\311\320(=w`\260<\014I}<\031\304\233=\2437\304=\335u\326\275\361\236F\273\t_\371\275\262\275\242\274\254\006@\275\232\307\370\275\276\363\206=\353\2006\275\351\240\357=\306\002\252\274\346\342\261\275\374 \207\275\025\2157=$2=\275T\273\372=\250\273 =\300\347\355;2\206\270\275\221B\244=\326\rc\275\0170\t\275\256\352h=\361M\221\275H\203\001\275\310Y\261\275$\215\373\274\203\363\244\275\364\375\005\275\222\325\362\275m\270\244=\305\332\377<M\0041\2747W\231\275\254\343\305\275\326t\213\274\225\312Q=\306\326\002>ip\270=\034\216\245\275\232\325@=\372\312\002\276\3531\322=\224\373\204\275c!\373=\232\214N87\324\035<\254G\256<0l\207\2752\227\303\272r\315\303=i\306*\275\034\244\332\273\177\230h=O\006\001>S\034\214\275\2362\317\275\243;\256\275\361#\022\275c\235\207\274;n\371<\207\026\246\275(IM\275M$)<\325\375\024=\364\354\345\275\340\006\305=\357\226\032\274\345J\237=X\003K= \235\202\274\002o\035\274}k\306\275J\2136=k;\017\275kD\360<\236\314\205\275\247I}\275a\340\317\275:\020\340\275Q\244\007\276\235\366O=\275C\322\275\266\'\001\275\000\017\007\276\031\354O;u^\007>\001*\263=\317\327\002\276\236\346%=A&\257=?x\332\275\330ai=!\252\261\275Y\371\232=.\\\270\274\313\007\206=\272\246\353\274dE\222<\020\267w\275\250;\360=\032lP<,\246\307\275\322(\232=\375\277\355<\356\342\361\275?,\276=o\253\207\274:`\230=\225\255\005>\"\021\324\275#\321x\275\326\2071<\346\331\340<\331\200\371;x\241\000=\300\302\\\275\263\245Y\274\372\320\220\273(\207\261=V\374\261\275\241\264\252=\310T\337\275\317\362a\275\260\315\307=\374}\020\274\211\324,\275\3364\254=s\264N;\005M\365=\243\245C\275\203\353V<\3279\321=\024\200y\275\237?t<\331\201\010>F\'\305=\374|-9us\264<\220\016H=\257O\306=f\027\315=\277 \000=\216\'\340=\026\377\330\273\372\'\351\275N&\227\275\252\261\220=#\251b\275\317\222\306=Q@\357\275Y\352\372\274\327D\034\274;\3155\275.\033\221\275_!\207=\313\367\002\276\200\013\221=\310\366\225\275\325R\370\2750\'\370=\354\r\006>\301\306\311\274\002\322\250\275\366;\351\275\326\276\213=;\375m\275p\317\231\273(j<=D\246\367\275a\320\267= F\263\275\014*\244=\233\335 \275t\325\272\275 \344\327\275\305\340)\275Ct\022\274\352_\233\273\324\206(<\006\212\351=w\001\243\274\010\361\254\274\002\276\221<\275\260\032=B\236\223\274\323\275 =\351\340\264=\364\003\255\275\245\270\260\275\315\366\376\275[!}\274\214\222\004>\250\214\303=\362q\270\274T\330\330\275\261\355\232\275\336\211\220\275\211\003\306=\340\346\220\274\265\313\214=\361\253\316;\252i\343\275\316\300\314=\n}|\274\233\002\357\275\215n\"=\207\214\210\275\203\347\325\275\025\t\326<2\261\311=?$n=J\374\205\275\227\017\026\275\3315X\275L{\337=.X\244=\345\002\214\275\345\333\023\274H\034\242=\370\214\017\274\213v\304=x\274\326<\177A =\244\027\034\275ZbF=\\\352\371\275,-\222\275i\344\364=\206\251\247\273\013X\004>U\255:\275r\222\340<\204\312\000\274m\000\307\273\313\271\255=\261\221\t=\200u\010\276U(\327\274\316,\003\276y\223\332=\332,\027=4\210\361\275!\257\274\275\001\002O<\252\362\n=\025\344\327=?|\377\275\372\306I<\023\323,<z\272\316\275Pz\346=\247\010C<\337~\377=\220\273\313;po\340\275vI\261\275\207R\266\2756.\377\275{X\035\275\276\306l=\212\302\341\275\264F\005>\251\352\006\275\207\\\222=\251RK=\341\306\003>\025\000\303=\361\262\366=\3423\253=\354\366\343<\306E\010\276\024@\023=+\2548<\211s\236=\013\033<=>\222\260\275\315\276)\275\226\312\273=[\353\225\274 \221K=@6\367=c\364\366;\207\027\232=4\324\201\275\t\001\002>\200K\321=\342\016\345<\365(q\274\265\315\261\271\211\204\272\2759\023\003=\022\316\372\275\341\361w=\000\244\257=\204\034\314=\335\222\000=\362\212\335<\222r\306\275u\317\310=\313\237\306=\022\030\213=/:\206=\203\275U<\316\370g=\342\202\357=B\274\326=9\230\343<\243\343\341\275^F<=\005\321n=\t7.\274\213\256e\274\301\367\257<9\351\210\274\014\216\364\275\271\351\340\275\302\217o\275\220\330\373=\275`7\275\370\247\376=\273y\372=\260\315C\275G!\363<\325\262\252\275\375\003\036\275\306\r0=}&\312<\327\344z\274\022\214\235=\212i\246=\373c\311\274\227\2432=:]\261=*\212\347=\273\356\260=A\303\240=\330\364x=\005\305\216\274}\240\344=\004\372z<\025f\357=kb\356=\261X\021\274.\223\363\274\243\364\257=^6:\274\026\314J=^\241N=\245\314J=_n\372\272\244i\255\275\347Oo=*_\365\275\3263\277<r\267\005>\336P\355=\217o\256\275&\255\007\276\212\347\t<\236\217\357\275\3137s=q\034\255=\212\034\231<\2778\004\275>\306y\275\354?=\275mb\322\273t2j<\000?\234=\201\217(=\366\206\317=GO\306\275\211\317R=\355\266\302\275\234\222==\260\230N\2757{.\274\357^\225<\214\366y=\017\335=\275\351\036\375=\375\246\343=|\345\232<\257@A=\264\362\311\275J\356\210\273\224\017\004>E\206\232=\"\206\005<\343\364\245\275\235\221\371\275\334r\317=\335?\305=2\210Z=\201\336\215\275a\344\006\276\376{\217\275\227\270\366=\242.\237\275pv\226=}\341\364=\375|\313=\307\022\301\274K\243\253\275\331\274\307\275\323\265U=/5B\274/h\014\275V@\021=\236\"\003\276\370\'\005>\017\2427\275\366\275\330\275\250\357\266\275\347\323\331\275\034E\315\275\253N\005>\nq\211\273\325\002\226\275\371k\344=\253\321\221\275\000M\305\275\2413i=#r\335<\004+R\272`FL<=\233E\275\207\266[\275s.\036\275>k\005>R\177\260\275\2222\324\275\0351\355\274\217\307\231\275\352S\210\275\353\370\323\273\305\007\301=\207\337\227\274\314\023\345=\301\252\346\275\324\243\350=\204\034\204\275dg\213\275\242\203\273\275\230\024\205=,\260\317=\322\212\246\275\223\215\004\276\227\373\201;\005\315\262\274\264\000\017;A\005\014=O\220\021\275\236\235\370<\352yG\275\203V\210\275\365\242\311=]Q\264\274l\236\350\275\\`\222<i\367\361=\264\220\337\275\032\365\212\275\245\240\212\275\214\331\244\2752\242M\275\355\222\007>c\007F\274\014a\253\275\305=\325\275{\301P\275\000+\213=D\022\313=b\341\254<\010\355\210<\037\006\007\276\373\t\006\276\252c\223<\375\314\277<F\'\244=c\275\234=h]\274=[\225\345=e\311f\274\332\221\266\275"
      }
    }
  }
}
node {
  name: "fully_connected_1/weights"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 330
        }
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected_1/weights/Assign"
  op: "Assign"
  input: "fully_connected_1/weights"
  input: "fully_connected_1/weights/Initializer/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected_1/weights/read"
  op: "Identity"
  input: "fully_connected_1/weights"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "fully_connected_1/MatMul"
  op: "MatMul"
  input: "fully_connected/Relu"
  input: "fully_connected_1/weights/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "fully_connected_1/bias/Initializer/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 4
          }
        }
        tensor_content: "\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000"
      }
    }
  }
}
node {
  name: "fully_connected_1/bias"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected_1/bias/Assign"
  op: "Assign"
  input: "fully_connected_1/bias"
  input: "fully_connected_1/bias/Initializer/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected_1/bias/read"
  op: "Identity"
  input: "fully_connected_1/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "fully_connected_1/BiasAdd"
  op: "BiasAdd"
  input: "fully_connected_1/MatMul"
  input: "fully_connected_1/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/HistogramSummary/tag"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression.X"
      }
    }
  }
}
node {
  name: "linear_regression/HistogramSummary"
  op: "HistogramSummary"
  input: "linear_regression/HistogramSummary/tag"
  input: "fully_connected_1/BiasAdd"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/HistogramSummary_1/tag"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression.y"
      }
    }
  }
}
node {
  name: "linear_regression/HistogramSummary_1"
  op: "HistogramSummary"
  input: "linear_regression/HistogramSummary_1/tag"
  input: "output"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/weights/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: "\004\000\000\000\004\000\000\000"
      }
    }
  }
}
node {
  name: "linear_regression/weights/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -0.866025388241
      }
    }
  }
}
node {
  name: "linear_regression/weights/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.866025388241
      }
    }
  }
}
node {
  name: "linear_regression/weights/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "linear_regression/weights/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 42
    }
  }
  attr {
    key: "seed2"
    value {
      i: 38
    }
  }
}
node {
  name: "linear_regression/weights/Initializer/random_uniform/sub"
  op: "Sub"
  input: "linear_regression/weights/Initializer/random_uniform/max"
  input: "linear_regression/weights/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/weights/Initializer/random_uniform/mul"
  op: "Mul"
  input: "linear_regression/weights/Initializer/random_uniform/RandomUniform"
  input: "linear_regression/weights/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/weights/Initializer/random_uniform"
  op: "Add"
  input: "linear_regression/weights/Initializer/random_uniform/mul"
  input: "linear_regression/weights/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/weights"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "linear_regression/weights/Assign"
  op: "Assign"
  input: "linear_regression/weights"
  input: "linear_regression/weights/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "linear_regression/weights/read"
  op: "Identity"
  input: "linear_regression/weights"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/bias/Initializer/random_uniform/shape"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 1
          }
        }
        int_val: 4
      }
    }
  }
}
node {
  name: "linear_regression/bias/Initializer/random_uniform/min"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: -1.73205077648
      }
    }
  }
}
node {
  name: "linear_regression/bias/Initializer/random_uniform/max"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.73205077648
      }
    }
  }
}
node {
  name: "linear_regression/bias/Initializer/random_uniform/RandomUniform"
  op: "RandomUniform"
  input: "linear_regression/bias/Initializer/random_uniform/shape"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "seed"
    value {
      i: 42
    }
  }
  attr {
    key: "seed2"
    value {
      i: 48
    }
  }
}
node {
  name: "linear_regression/bias/Initializer/random_uniform/sub"
  op: "Sub"
  input: "linear_regression/bias/Initializer/random_uniform/max"
  input: "linear_regression/bias/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/bias/Initializer/random_uniform/mul"
  op: "Mul"
  input: "linear_regression/bias/Initializer/random_uniform/RandomUniform"
  input: "linear_regression/bias/Initializer/random_uniform/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/bias/Initializer/random_uniform"
  op: "Add"
  input: "linear_regression/bias/Initializer/random_uniform/mul"
  input: "linear_regression/bias/Initializer/random_uniform/min"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/bias"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "linear_regression/bias/Assign"
  op: "Assign"
  input: "linear_regression/bias"
  input: "linear_regression/bias/Initializer/random_uniform"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "linear_regression/bias/read"
  op: "Identity"
  input: "linear_regression/bias"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/HistogramSummary_2/tag"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression.weights"
      }
    }
  }
}
node {
  name: "linear_regression/HistogramSummary_2"
  op: "HistogramSummary"
  input: "linear_regression/HistogramSummary_2/tag"
  input: "linear_regression/weights/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/HistogramSummary_3/tag"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression.bias"
      }
    }
  }
}
node {
  name: "linear_regression/HistogramSummary_3"
  op: "HistogramSummary"
  input: "linear_regression/HistogramSummary_3/tag"
  input: "linear_regression/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul"
  op: "MatMul"
  input: "fully_connected_1/BiasAdd"
  input: "linear_regression/weights/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/xw_plus_b"
  op: "BiasAdd"
  input: "linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul"
  input: "linear_regression/bias/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/sub"
  op: "Sub"
  input: "output"
  input: "linear_regression/mean_squared_error_regressor/xw_plus_b"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/Mul"
  op: "Mul"
  input: "linear_regression/mean_squared_error_regressor/sub"
  input: "linear_regression/mean_squared_error_regressor/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/Rank"
  op: "Rank"
  input: "linear_regression/mean_squared_error_regressor/Mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/range/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/range/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "linear_regression/mean_squared_error_regressor/range"
  op: "Range"
  input: "linear_regression/mean_squared_error_regressor/range/start"
  input: "linear_regression/mean_squared_error_regressor/Rank"
  input: "linear_regression/mean_squared_error_regressor/range/delta"
}
node {
  name: "linear_regression/mean_squared_error_regressor/Mean"
  op: "Mean"
  input: "linear_regression/mean_squared_error_regressor/Mul"
  input: "linear_regression/mean_squared_error_regressor/range"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "ScalarSummary/tags"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "loss"
      }
    }
  }
}
node {
  name: "ScalarSummary"
  op: "ScalarSummary"
  input: "ScalarSummary/tags"
  input: "linear_regression/mean_squared_error_regressor/Mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "MergeSummary/MergeSummary"
  op: "MergeSummary"
  input: "HistogramSummary"
  input: "HistogramSummary_1"
  input: "linear_regression/HistogramSummary"
  input: "linear_regression/HistogramSummary_1"
  input: "linear_regression/HistogramSummary_2"
  input: "linear_regression/HistogramSummary_3"
  input: "ScalarSummary"
  attr {
    key: "N"
    value {
      i: 7
    }
  }
}
node {
  name: "learning_rate/Initializer/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.10000000149
      }
    }
  }
}
node {
  name: "learning_rate"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "learning_rate/Assign"
  op: "Assign"
  input: "learning_rate"
  input: "learning_rate/Initializer/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "learning_rate/read"
  op: "Identity"
  input: "learning_rate"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/Shape"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/Mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "gradients/Fill"
  op: "Fill"
  input: "gradients/Shape"
  input: "gradients/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/Mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Rank"
  op: "Rank"
  input: "linear_regression/mean_squared_error_regressor/Mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_1"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/range"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range"
  op: "Range"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range/start"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Rank"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range/delta"
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Fill/value"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Fill"
  op: "Fill"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_1"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Fill/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/DynamicStitch"
  op: "DynamicStitch"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range"
  input: "linear_regression/mean_squared_error_regressor/range"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Fill"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/floordiv"
  op: "Div"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Reshape"
  op: "Reshape"
  input: "gradients/Fill"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/DynamicStitch"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Tile"
  op: "Tile"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Reshape"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/floordiv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_2"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/Mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_3"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/Mean"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Rank_1"
  op: "Rank"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_2"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_1/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_1/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_1"
  op: "Range"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_1/start"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Rank_1"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_1/delta"
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Prod"
  op: "Prod"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_2"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Rank_2"
  op: "Rank"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_3"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_2/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_2/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_2"
  op: "Range"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_2/start"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Rank_2"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_2/delta"
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Prod_1"
  op: "Prod"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Shape_3"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/range_2"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/floordiv_1"
  op: "Div"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Prod"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Prod_1"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Cast"
  op: "Cast"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/floordiv_1"
  attr {
    key: "DstT"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "SrcT"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/truediv"
  op: "Div"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Tile"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/Cast"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Shape"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Shape_1"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Shape"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Shape_1"
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/mul"
  op: "Mul"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/truediv"
  input: "linear_regression/mean_squared_error_regressor/sub"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Sum"
  op: "Sum"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/mul"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Reshape"
  op: "Reshape"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Sum"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/mul_1"
  op: "Mul"
  input: "linear_regression/mean_squared_error_regressor/sub"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mean_grad/truediv"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Sum_1"
  op: "Sum"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/mul_1"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Sum_1"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/AddN"
  op: "AddN"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Reshape"
  input: "gradients/linear_regression/mean_squared_error_regressor/Mul_grad/Reshape_1"
  attr {
    key: "N"
    value {
      i: 2
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Shape"
  op: "Shape"
  input: "output"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Shape_1"
  op: "Shape"
  input: "linear_regression/mean_squared_error_regressor/xw_plus_b"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/BroadcastGradientArgs"
  op: "BroadcastGradientArgs"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Shape"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Shape_1"
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Sum"
  op: "Sum"
  input: "gradients/AddN"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/BroadcastGradientArgs"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Reshape"
  op: "Reshape"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Sum"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Shape"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Sum_1"
  op: "Sum"
  input: "gradients/AddN"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/BroadcastGradientArgs:1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Neg"
  op: "Neg"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Sum_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Reshape_1"
  op: "Reshape"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Neg"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Shape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/Rank"
  op: "Rank"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/sub/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/sub"
  op: "Sub"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/Rank"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/sub/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/range/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/range/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/range"
  op: "Range"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/range/start"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/sub"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/range/delta"
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/Sum"
  op: "Sum"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Reshape_1"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/range"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Reshape_1"
  input: "linear_regression/weights/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "fully_connected_1/BiasAdd"
  input: "gradients/linear_regression/mean_squared_error_regressor/sub_grad/Reshape_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/fully_connected_1/BiasAdd_grad/Rank"
  op: "Rank"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/fully_connected_1/BiasAdd_grad/sub/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/fully_connected_1/BiasAdd_grad/sub"
  op: "Sub"
  input: "gradients/fully_connected_1/BiasAdd_grad/Rank"
  input: "gradients/fully_connected_1/BiasAdd_grad/sub/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/fully_connected_1/BiasAdd_grad/range/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/fully_connected_1/BiasAdd_grad/range/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/fully_connected_1/BiasAdd_grad/range"
  op: "Range"
  input: "gradients/fully_connected_1/BiasAdd_grad/range/start"
  input: "gradients/fully_connected_1/BiasAdd_grad/sub"
  input: "gradients/fully_connected_1/BiasAdd_grad/range/delta"
}
node {
  name: "gradients/fully_connected_1/BiasAdd_grad/Sum"
  op: "Sum"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul"
  input: "gradients/fully_connected_1/BiasAdd_grad/range"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/fully_connected_1/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul"
  input: "fully_connected_1/weights/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/fully_connected_1/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "fully_connected/Relu"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/fully_connected/Relu_grad/ReluGrad"
  op: "ReluGrad"
  input: "gradients/fully_connected_1/MatMul_grad/MatMul"
  input: "fully_connected/Relu"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/fully_connected/BiasAdd_grad/Rank"
  op: "Rank"
  input: "gradients/fully_connected/Relu_grad/ReluGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "gradients/fully_connected/BiasAdd_grad/sub/y"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/fully_connected/BiasAdd_grad/sub"
  op: "Sub"
  input: "gradients/fully_connected/BiasAdd_grad/Rank"
  input: "gradients/fully_connected/BiasAdd_grad/sub/y"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
}
node {
  name: "gradients/fully_connected/BiasAdd_grad/range/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "gradients/fully_connected/BiasAdd_grad/range/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "gradients/fully_connected/BiasAdd_grad/range"
  op: "Range"
  input: "gradients/fully_connected/BiasAdd_grad/range/start"
  input: "gradients/fully_connected/BiasAdd_grad/sub"
  input: "gradients/fully_connected/BiasAdd_grad/range/delta"
}
node {
  name: "gradients/fully_connected/BiasAdd_grad/Sum"
  op: "Sum"
  input: "gradients/fully_connected/Relu_grad/ReluGrad"
  input: "gradients/fully_connected/BiasAdd_grad/range"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "gradients/fully_connected/MatMul_grad/MatMul"
  op: "MatMul"
  input: "gradients/fully_connected/Relu_grad/ReluGrad"
  input: "fully_connected/weights/read"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: false
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: true
    }
  }
}
node {
  name: "gradients/fully_connected/MatMul_grad/MatMul_1"
  op: "MatMul"
  input: "input"
  input: "gradients/fully_connected/Relu_grad/ReluGrad"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: true
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/mul"
  op: "Mul"
  input: "gradients/fully_connected/MatMul_grad/MatMul_1"
  input: "gradients/fully_connected/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/Rank"
  op: "Rank"
  input: "global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/range/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/range/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "global_norm/range"
  op: "Range"
  input: "global_norm/range/start"
  input: "global_norm/Rank"
  input: "global_norm/range/delta"
}
node {
  name: "global_norm/Sum"
  op: "Sum"
  input: "global_norm/mul"
  input: "global_norm/range"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/mul_1"
  op: "Mul"
  input: "gradients/fully_connected/BiasAdd_grad/Sum"
  input: "gradients/fully_connected/BiasAdd_grad/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/Rank_1"
  op: "Rank"
  input: "global_norm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/range_1/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/range_1/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "global_norm/range_1"
  op: "Range"
  input: "global_norm/range_1/start"
  input: "global_norm/Rank_1"
  input: "global_norm/range_1/delta"
}
node {
  name: "global_norm/Sum_1"
  op: "Sum"
  input: "global_norm/mul_1"
  input: "global_norm/range_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/mul_2"
  op: "Mul"
  input: "gradients/fully_connected_1/MatMul_grad/MatMul_1"
  input: "gradients/fully_connected_1/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/Rank_2"
  op: "Rank"
  input: "global_norm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/range_2/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/range_2/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "global_norm/range_2"
  op: "Range"
  input: "global_norm/range_2/start"
  input: "global_norm/Rank_2"
  input: "global_norm/range_2/delta"
}
node {
  name: "global_norm/Sum_2"
  op: "Sum"
  input: "global_norm/mul_2"
  input: "global_norm/range_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/mul_3"
  op: "Mul"
  input: "gradients/fully_connected_1/BiasAdd_grad/Sum"
  input: "gradients/fully_connected_1/BiasAdd_grad/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/Rank_3"
  op: "Rank"
  input: "global_norm/mul_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/range_3/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/range_3/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "global_norm/range_3"
  op: "Range"
  input: "global_norm/range_3/start"
  input: "global_norm/Rank_3"
  input: "global_norm/range_3/delta"
}
node {
  name: "global_norm/Sum_3"
  op: "Sum"
  input: "global_norm/mul_3"
  input: "global_norm/range_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/mul_4"
  op: "Mul"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul_1"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/Rank_4"
  op: "Rank"
  input: "global_norm/mul_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/range_4/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/range_4/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "global_norm/range_4"
  op: "Range"
  input: "global_norm/range_4/start"
  input: "global_norm/Rank_4"
  input: "global_norm/range_4/delta"
}
node {
  name: "global_norm/Sum_4"
  op: "Sum"
  input: "global_norm/mul_4"
  input: "global_norm/range_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/mul_5"
  op: "Mul"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/Sum"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/Sum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/Rank_5"
  op: "Rank"
  input: "global_norm/mul_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/range_5/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/range_5/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "global_norm/range_5"
  op: "Range"
  input: "global_norm/range_5/start"
  input: "global_norm/Rank_5"
  input: "global_norm/range_5/delta"
}
node {
  name: "global_norm/Sum_5"
  op: "Sum"
  input: "global_norm/mul_5"
  input: "global_norm/range_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/pack"
  op: "Pack"
  input: "global_norm/Sum"
  input: "global_norm/Sum_1"
  input: "global_norm/Sum_2"
  input: "global_norm/Sum_3"
  input: "global_norm/Sum_4"
  input: "global_norm/Sum_5"
  attr {
    key: "N"
    value {
      i: 6
    }
  }
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/Rank_6"
  op: "Rank"
  input: "global_norm/pack"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "global_norm/range_6/start"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 0
      }
    }
  }
}
node {
  name: "global_norm/range_6/delta"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "global_norm/range_6"
  op: "Range"
  input: "global_norm/range_6/start"
  input: "global_norm/Rank_6"
  input: "global_norm/range_6/delta"
}
node {
  name: "global_norm/Sum_6"
  op: "Sum"
  input: "global_norm/pack"
  input: "global_norm/range_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "keep_dims"
    value {
      b: false
    }
  }
}
node {
  name: "global_norm/global_norm"
  op: "Sqrt"
  input: "global_norm/Sum_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/truediv/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 1.0
      }
    }
  }
}
node {
  name: "clip_by_global_norm/truediv"
  op: "Div"
  input: "clip_by_global_norm/truediv/x"
  input: "global_norm/global_norm"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.20000000298
      }
    }
  }
}
node {
  name: "clip_by_global_norm/Minimum"
  op: "Minimum"
  input: "clip_by_global_norm/truediv"
  input: "clip_by_global_norm/Const"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul/x"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 5.0
      }
    }
  }
}
node {
  name: "clip_by_global_norm/mul"
  op: "Mul"
  input: "clip_by_global_norm/mul/x"
  input: "clip_by_global_norm/Minimum"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul_1"
  op: "Mul"
  input: "gradients/fully_connected/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_0"
  op: "Identity"
  input: "clip_by_global_norm/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul_2"
  op: "Mul"
  input: "gradients/fully_connected/BiasAdd_grad/Sum"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_1"
  op: "Identity"
  input: "clip_by_global_norm/mul_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul_3"
  op: "Mul"
  input: "gradients/fully_connected_1/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_2"
  op: "Identity"
  input: "clip_by_global_norm/mul_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul_4"
  op: "Mul"
  input: "gradients/fully_connected_1/BiasAdd_grad/Sum"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_3"
  op: "Identity"
  input: "clip_by_global_norm/mul_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul_5"
  op: "Mul"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b/MatMul_grad/MatMul_1"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_4"
  op: "Identity"
  input: "clip_by_global_norm/mul_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/mul_6"
  op: "Mul"
  input: "gradients/linear_regression/mean_squared_error_regressor/xw_plus_b_grad/Sum"
  input: "clip_by_global_norm/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "clip_by_global_norm/clip_by_global_norm/_5"
  op: "Identity"
  input: "clip_by_global_norm/mul_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "beta1_power/initial_value"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.899999976158
      }
    }
  }
}
node {
  name: "beta1_power"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "beta1_power/Assign"
  op: "Assign"
  input: "beta1_power"
  input: "beta1_power/initial_value"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "beta1_power/read"
  op: "Identity"
  input: "beta1_power"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "beta2_power/initial_value"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.999000012875
      }
    }
  }
}
node {
  name: "beta2_power"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "beta2_power/Assign"
  op: "Assign"
  input: "beta2_power"
  input: "beta2_power/initial_value"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "beta2_power/read"
  op: "Identity"
  input: "beta2_power"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 8
          }
          dim {
            size: 330
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected/weights/Adam"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 330
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected/weights/Adam/Assign"
  op: "Assign"
  input: "fully_connected/weights/Adam"
  input: "zeros"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected/weights/Adam/read"
  op: "Identity"
  input: "fully_connected/weights/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 8
          }
          dim {
            size: 330
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected/weights/Adam_1"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 8
        }
        dim {
          size: 330
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected/weights/Adam_1/Assign"
  op: "Assign"
  input: "fully_connected/weights/Adam_1"
  input: "zeros_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected/weights/Adam_1/read"
  op: "Identity"
  input: "fully_connected/weights/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 330
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected/bias/Adam"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 330
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected/bias/Adam/Assign"
  op: "Assign"
  input: "fully_connected/bias/Adam"
  input: "zeros_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected/bias/Adam/read"
  op: "Identity"
  input: "fully_connected/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_3"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 330
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected/bias/Adam_1"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 330
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected/bias/Adam_1/Assign"
  op: "Assign"
  input: "fully_connected/bias/Adam_1"
  input: "zeros_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected/bias/Adam_1/read"
  op: "Identity"
  input: "fully_connected/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_4"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 330
          }
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected_1/weights/Adam"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 330
        }
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected_1/weights/Adam/Assign"
  op: "Assign"
  input: "fully_connected_1/weights/Adam"
  input: "zeros_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected_1/weights/Adam/read"
  op: "Identity"
  input: "fully_connected_1/weights/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_5"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 330
          }
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected_1/weights/Adam_1"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 330
        }
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected_1/weights/Adam_1/Assign"
  op: "Assign"
  input: "fully_connected_1/weights/Adam_1"
  input: "zeros_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected_1/weights/Adam_1/read"
  op: "Identity"
  input: "fully_connected_1/weights/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_6"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected_1/bias/Adam"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected_1/bias/Adam/Assign"
  op: "Assign"
  input: "fully_connected_1/bias/Adam"
  input: "zeros_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected_1/bias/Adam/read"
  op: "Identity"
  input: "fully_connected_1/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_7"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "fully_connected_1/bias/Adam_1"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "fully_connected_1/bias/Adam_1/Assign"
  op: "Assign"
  input: "fully_connected_1/bias/Adam_1"
  input: "zeros_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "fully_connected_1/bias/Adam_1/read"
  op: "Identity"
  input: "fully_connected_1/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_8"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 4
          }
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "linear_regression/weights/Adam"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "linear_regression/weights/Adam/Assign"
  op: "Assign"
  input: "linear_regression/weights/Adam"
  input: "zeros_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "linear_regression/weights/Adam/read"
  op: "Identity"
  input: "linear_regression/weights/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_9"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 4
          }
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "linear_regression/weights/Adam_1"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "linear_regression/weights/Adam_1/Assign"
  op: "Assign"
  input: "linear_regression/weights/Adam_1"
  input: "zeros_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "linear_regression/weights/Adam_1/read"
  op: "Identity"
  input: "linear_regression/weights/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_10"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "linear_regression/bias/Adam"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "linear_regression/bias/Adam/Assign"
  op: "Assign"
  input: "linear_regression/bias/Adam"
  input: "zeros_10"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "linear_regression/bias/Adam/read"
  op: "Identity"
  input: "linear_regression/bias/Adam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "zeros_11"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
          dim {
            size: 4
          }
        }
        float_val: 0.0
      }
    }
  }
}
node {
  name: "linear_regression/bias/Adam_1"
  op: "Variable"
  attr {
    key: "container"
    value {
      s: ""
    }
  }
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 4
        }
      }
    }
  }
  attr {
    key: "shared_name"
    value {
      s: ""
    }
  }
}
node {
  name: "linear_regression/bias/Adam_1/Assign"
  op: "Assign"
  input: "linear_regression/bias/Adam_1"
  input: "zeros_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "linear_regression/bias/Adam_1/read"
  op: "Identity"
  input: "linear_regression/bias/Adam_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "train/beta1"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.899999976158
      }
    }
  }
}
node {
  name: "train/beta2"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 0.999000012875
      }
    }
  }
}
node {
  name: "train/epsilon"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_FLOAT
        tensor_shape {
        }
        float_val: 9.99999993923e-09
      }
    }
  }
}
node {
  name: "train/update_fully_connected/weights/ApplyAdam"
  op: "ApplyAdam"
  input: "fully_connected/weights"
  input: "fully_connected/weights/Adam"
  input: "fully_connected/weights/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "learning_rate/read"
  input: "train/beta1"
  input: "train/beta2"
  input: "train/epsilon"
  input: "clip_by_global_norm/clip_by_global_norm/_0"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "train/update_fully_connected/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "fully_connected/bias"
  input: "fully_connected/bias/Adam"
  input: "fully_connected/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "learning_rate/read"
  input: "train/beta1"
  input: "train/beta2"
  input: "train/epsilon"
  input: "clip_by_global_norm/clip_by_global_norm/_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "train/update_fully_connected_1/weights/ApplyAdam"
  op: "ApplyAdam"
  input: "fully_connected_1/weights"
  input: "fully_connected_1/weights/Adam"
  input: "fully_connected_1/weights/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "learning_rate/read"
  input: "train/beta1"
  input: "train/beta2"
  input: "train/epsilon"
  input: "clip_by_global_norm/clip_by_global_norm/_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "train/update_fully_connected_1/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "fully_connected_1/bias"
  input: "fully_connected_1/bias/Adam"
  input: "fully_connected_1/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "learning_rate/read"
  input: "train/beta1"
  input: "train/beta2"
  input: "train/epsilon"
  input: "clip_by_global_norm/clip_by_global_norm/_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "train/update_linear_regression/weights/ApplyAdam"
  op: "ApplyAdam"
  input: "linear_regression/weights"
  input: "linear_regression/weights/Adam"
  input: "linear_regression/weights/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "learning_rate/read"
  input: "train/beta1"
  input: "train/beta2"
  input: "train/epsilon"
  input: "clip_by_global_norm/clip_by_global_norm/_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "train/update_linear_regression/bias/ApplyAdam"
  op: "ApplyAdam"
  input: "linear_regression/bias"
  input: "linear_regression/bias/Adam"
  input: "linear_regression/bias/Adam_1"
  input: "beta1_power/read"
  input: "beta2_power/read"
  input: "learning_rate/read"
  input: "train/beta1"
  input: "train/beta2"
  input: "train/epsilon"
  input: "clip_by_global_norm/clip_by_global_norm/_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "train/mul"
  op: "Mul"
  input: "beta1_power/read"
  input: "train/beta1"
  input: "^train/update_fully_connected/weights/ApplyAdam"
  input: "^train/update_fully_connected/bias/ApplyAdam"
  input: "^train/update_fully_connected_1/weights/ApplyAdam"
  input: "^train/update_fully_connected_1/bias/ApplyAdam"
  input: "^train/update_linear_regression/weights/ApplyAdam"
  input: "^train/update_linear_regression/bias/ApplyAdam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "train/Assign"
  op: "Assign"
  input: "beta1_power"
  input: "train/mul"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "train/mul_1"
  op: "Mul"
  input: "beta2_power/read"
  input: "train/beta2"
  input: "^train/update_fully_connected/weights/ApplyAdam"
  input: "^train/update_fully_connected/bias/ApplyAdam"
  input: "^train/update_fully_connected_1/weights/ApplyAdam"
  input: "^train/update_fully_connected_1/bias/ApplyAdam"
  input: "^train/update_linear_regression/weights/ApplyAdam"
  input: "^train/update_linear_regression/bias/ApplyAdam"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "train/Assign_1"
  op: "Assign"
  input: "beta2_power"
  input: "train/mul_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "train/update"
  op: "NoOp"
  input: "^train/update_fully_connected/weights/ApplyAdam"
  input: "^train/update_fully_connected/bias/ApplyAdam"
  input: "^train/update_fully_connected_1/weights/ApplyAdam"
  input: "^train/update_fully_connected_1/bias/ApplyAdam"
  input: "^train/update_linear_regression/weights/ApplyAdam"
  input: "^train/update_linear_regression/bias/ApplyAdam"
  input: "^train/Assign"
  input: "^train/Assign_1"
}
node {
  name: "train/value"
  op: "Const"
  input: "^train/update"
  attr {
    key: "dtype"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 1
      }
    }
  }
}
node {
  name: "train"
  op: "AssignAdd"
  input: "global_step"
  input: "train/value"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "use_locking"
    value {
      b: false
    }
  }
}
node {
  name: "group_deps"
  op: "NoOp"
  input: "^train"
}
node {
  name: "init"
  op: "NoOp"
  input: "^global_step/Assign"
  input: "^fully_connected/weights/Assign"
  input: "^fully_connected/bias/Assign"
  input: "^fully_connected_1/weights/Assign"
  input: "^fully_connected_1/bias/Assign"
  input: "^linear_regression/weights/Assign"
  input: "^linear_regression/bias/Assign"
  input: "^learning_rate/Assign"
  input: "^beta1_power/Assign"
  input: "^beta2_power/Assign"
  input: "^fully_connected/weights/Adam/Assign"
  input: "^fully_connected/weights/Adam_1/Assign"
  input: "^fully_connected/bias/Adam/Assign"
  input: "^fully_connected/bias/Adam_1/Assign"
  input: "^fully_connected_1/weights/Adam/Assign"
  input: "^fully_connected_1/weights/Adam_1/Assign"
  input: "^fully_connected_1/bias/Adam/Assign"
  input: "^fully_connected_1/bias/Adam_1/Assign"
  input: "^linear_regression/weights/Adam/Assign"
  input: "^linear_regression/weights/Adam_1/Assign"
  input: "^linear_regression/bias/Adam/Assign"
  input: "^linear_regression/bias/Adam_1/Assign"
}
node {
  name: "save/Const"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "model"
      }
    }
  }
}
node {
  name: "save/save/tensor_names"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 22
          }
        }
        string_val: "beta1_power"
        string_val: "beta2_power"
        string_val: "fully_connected/bias"
        string_val: "fully_connected/bias/Adam"
        string_val: "fully_connected/bias/Adam_1"
        string_val: "fully_connected/weights"
        string_val: "fully_connected/weights/Adam"
        string_val: "fully_connected/weights/Adam_1"
        string_val: "fully_connected_1/bias"
        string_val: "fully_connected_1/bias/Adam"
        string_val: "fully_connected_1/bias/Adam_1"
        string_val: "fully_connected_1/weights"
        string_val: "fully_connected_1/weights/Adam"
        string_val: "fully_connected_1/weights/Adam_1"
        string_val: "global_step"
        string_val: "learning_rate"
        string_val: "linear_regression/bias"
        string_val: "linear_regression/bias/Adam"
        string_val: "linear_regression/bias/Adam_1"
        string_val: "linear_regression/weights"
        string_val: "linear_regression/weights/Adam"
        string_val: "linear_regression/weights/Adam_1"
      }
    }
  }
}
node {
  name: "save/save/shapes_and_slices"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
          dim {
            size: 22
          }
        }
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
        string_val: ""
      }
    }
  }
}
node {
  name: "save/save"
  op: "SaveSlices"
  input: "save/Const"
  input: "save/save/tensor_names"
  input: "save/save/shapes_and_slices"
  input: "beta1_power"
  input: "beta2_power"
  input: "fully_connected/bias"
  input: "fully_connected/bias/Adam"
  input: "fully_connected/bias/Adam_1"
  input: "fully_connected/weights"
  input: "fully_connected/weights/Adam"
  input: "fully_connected/weights/Adam_1"
  input: "fully_connected_1/bias"
  input: "fully_connected_1/bias/Adam"
  input: "fully_connected_1/bias/Adam_1"
  input: "fully_connected_1/weights"
  input: "fully_connected_1/weights/Adam"
  input: "fully_connected_1/weights/Adam_1"
  input: "global_step"
  input: "learning_rate"
  input: "linear_regression/bias"
  input: "linear_regression/bias/Adam"
  input: "linear_regression/bias/Adam_1"
  input: "linear_regression/weights"
  input: "linear_regression/weights/Adam"
  input: "linear_regression/weights/Adam_1"
  attr {
    key: "T"
    value {
      list {
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_INT32
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
        type: DT_FLOAT
      }
    }
  }
}
node {
  name: "save/control_dependency"
  op: "Identity"
  input: "save/Const"
  input: "^save/save"
  attr {
    key: "T"
    value {
      type: DT_STRING
    }
  }
}
node {
  name: "save/restore_slice/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "beta1_power"
      }
    }
  }
}
node {
  name: "save/restore_slice/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice/tensor_name"
  input: "save/restore_slice/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign"
  op: "Assign"
  input: "beta1_power"
  input: "save/restore_slice"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_1/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "beta2_power"
      }
    }
  }
}
node {
  name: "save/restore_slice_1/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_1"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_1/tensor_name"
  input: "save/restore_slice_1/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_1"
  op: "Assign"
  input: "beta2_power"
  input: "save/restore_slice_1"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_2/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected/bias"
      }
    }
  }
}
node {
  name: "save/restore_slice_2/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_2"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_2/tensor_name"
  input: "save/restore_slice_2/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_2"
  op: "Assign"
  input: "fully_connected/bias"
  input: "save/restore_slice_2"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_3/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected/bias/Adam"
      }
    }
  }
}
node {
  name: "save/restore_slice_3/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_3"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_3/tensor_name"
  input: "save/restore_slice_3/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_3"
  op: "Assign"
  input: "fully_connected/bias/Adam"
  input: "save/restore_slice_3"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_4/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected/bias/Adam_1"
      }
    }
  }
}
node {
  name: "save/restore_slice_4/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_4"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_4/tensor_name"
  input: "save/restore_slice_4/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_4"
  op: "Assign"
  input: "fully_connected/bias/Adam_1"
  input: "save/restore_slice_4"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_5/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected/weights"
      }
    }
  }
}
node {
  name: "save/restore_slice_5/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_5"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_5/tensor_name"
  input: "save/restore_slice_5/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_5"
  op: "Assign"
  input: "fully_connected/weights"
  input: "save/restore_slice_5"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_6/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected/weights/Adam"
      }
    }
  }
}
node {
  name: "save/restore_slice_6/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_6"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_6/tensor_name"
  input: "save/restore_slice_6/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_6"
  op: "Assign"
  input: "fully_connected/weights/Adam"
  input: "save/restore_slice_6"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_7/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected/weights/Adam_1"
      }
    }
  }
}
node {
  name: "save/restore_slice_7/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_7"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_7/tensor_name"
  input: "save/restore_slice_7/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_7"
  op: "Assign"
  input: "fully_connected/weights/Adam_1"
  input: "save/restore_slice_7"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_8/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected_1/bias"
      }
    }
  }
}
node {
  name: "save/restore_slice_8/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_8"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_8/tensor_name"
  input: "save/restore_slice_8/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_8"
  op: "Assign"
  input: "fully_connected_1/bias"
  input: "save/restore_slice_8"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_9/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected_1/bias/Adam"
      }
    }
  }
}
node {
  name: "save/restore_slice_9/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_9"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_9/tensor_name"
  input: "save/restore_slice_9/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_9"
  op: "Assign"
  input: "fully_connected_1/bias/Adam"
  input: "save/restore_slice_9"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_10/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected_1/bias/Adam_1"
      }
    }
  }
}
node {
  name: "save/restore_slice_10/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_10"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_10/tensor_name"
  input: "save/restore_slice_10/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_10"
  op: "Assign"
  input: "fully_connected_1/bias/Adam_1"
  input: "save/restore_slice_10"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_11/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected_1/weights"
      }
    }
  }
}
node {
  name: "save/restore_slice_11/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_11"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_11/tensor_name"
  input: "save/restore_slice_11/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_11"
  op: "Assign"
  input: "fully_connected_1/weights"
  input: "save/restore_slice_11"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_12/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected_1/weights/Adam"
      }
    }
  }
}
node {
  name: "save/restore_slice_12/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_12"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_12/tensor_name"
  input: "save/restore_slice_12/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_12"
  op: "Assign"
  input: "fully_connected_1/weights/Adam"
  input: "save/restore_slice_12"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_13/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "fully_connected_1/weights/Adam_1"
      }
    }
  }
}
node {
  name: "save/restore_slice_13/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_13"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_13/tensor_name"
  input: "save/restore_slice_13/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_13"
  op: "Assign"
  input: "fully_connected_1/weights/Adam_1"
  input: "save/restore_slice_13"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_14/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "global_step"
      }
    }
  }
}
node {
  name: "save/restore_slice_14/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_14"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_14/tensor_name"
  input: "save/restore_slice_14/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_14"
  op: "Assign"
  input: "global_step"
  input: "save/restore_slice_14"
  attr {
    key: "T"
    value {
      type: DT_INT32
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_15/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "learning_rate"
      }
    }
  }
}
node {
  name: "save/restore_slice_15/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_15"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_15/tensor_name"
  input: "save/restore_slice_15/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_15"
  op: "Assign"
  input: "learning_rate"
  input: "save/restore_slice_15"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_16/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression/bias"
      }
    }
  }
}
node {
  name: "save/restore_slice_16/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_16"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_16/tensor_name"
  input: "save/restore_slice_16/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_16"
  op: "Assign"
  input: "linear_regression/bias"
  input: "save/restore_slice_16"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_17/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression/bias/Adam"
      }
    }
  }
}
node {
  name: "save/restore_slice_17/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_17"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_17/tensor_name"
  input: "save/restore_slice_17/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_17"
  op: "Assign"
  input: "linear_regression/bias/Adam"
  input: "save/restore_slice_17"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_18/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression/bias/Adam_1"
      }
    }
  }
}
node {
  name: "save/restore_slice_18/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_18"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_18/tensor_name"
  input: "save/restore_slice_18/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_18"
  op: "Assign"
  input: "linear_regression/bias/Adam_1"
  input: "save/restore_slice_18"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_19/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression/weights"
      }
    }
  }
}
node {
  name: "save/restore_slice_19/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_19"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_19/tensor_name"
  input: "save/restore_slice_19/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_19"
  op: "Assign"
  input: "linear_regression/weights"
  input: "save/restore_slice_19"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_20/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression/weights/Adam"
      }
    }
  }
}
node {
  name: "save/restore_slice_20/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_20"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_20/tensor_name"
  input: "save/restore_slice_20/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_20"
  op: "Assign"
  input: "linear_regression/weights/Adam"
  input: "save/restore_slice_20"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_slice_21/tensor_name"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: "linear_regression/weights/Adam_1"
      }
    }
  }
}
node {
  name: "save/restore_slice_21/shape_and_slice"
  op: "Const"
  attr {
    key: "dtype"
    value {
      type: DT_STRING
    }
  }
  attr {
    key: "value"
    value {
      tensor {
        dtype: DT_STRING
        tensor_shape {
        }
        string_val: ""
      }
    }
  }
}
node {
  name: "save/restore_slice_21"
  op: "RestoreSlice"
  input: "save/Const"
  input: "save/restore_slice_21/tensor_name"
  input: "save/restore_slice_21/shape_and_slice"
  attr {
    key: "dt"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "preferred_shard"
    value {
      i: -1
    }
  }
}
node {
  name: "save/Assign_21"
  op: "Assign"
  input: "linear_regression/weights/Adam_1"
  input: "save/restore_slice_21"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "use_locking"
    value {
      b: true
    }
  }
  attr {
    key: "validate_shape"
    value {
      b: true
    }
  }
}
node {
  name: "save/restore_all"
  op: "NoOp"
  input: "^save/Assign"
  input: "^save/Assign_1"
  input: "^save/Assign_2"
  input: "^save/Assign_3"
  input: "^save/Assign_4"
  input: "^save/Assign_5"
  input: "^save/Assign_6"
  input: "^save/Assign_7"
  input: "^save/Assign_8"
  input: "^save/Assign_9"
  input: "^save/Assign_10"
  input: "^save/Assign_11"
  input: "^save/Assign_12"
  input: "^save/Assign_13"
  input: "^save/Assign_14"
  input: "^save/Assign_15"
  input: "^save/Assign_16"
  input: "^save/Assign_17"
  input: "^save/Assign_18"
  input: "^save/Assign_19"
  input: "^save/Assign_20"
  input: "^save/Assign_21"
}
versions {
  producer: 8
}
